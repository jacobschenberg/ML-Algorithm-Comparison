{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "guilty-equilibrium",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns; sns.set_style('white') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improving-magnitude",
   "metadata": {},
   "source": [
    "## Predictive Maintenance Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "figured-mathematics",
   "metadata": {},
   "source": [
    "https://archive.ics.uci.edu/ml/datasets/AI4I+2020+Predictive+Maintenance+Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "abandoned-worker",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>H</th>\n",
       "      <th>L</th>\n",
       "      <th>M</th>\n",
       "      <th>Machine failure</th>\n",
       "      <th>TWF</th>\n",
       "      <th>HDF</th>\n",
       "      <th>PWF</th>\n",
       "      <th>OSF</th>\n",
       "      <th>RNF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        H    L    M  Machine failure  TWF  HDF  PWF  OSF  RNF\n",
       "0     0.0  0.0  1.0                0    0    0    0    0    0\n",
       "1     0.0  1.0  0.0                0    0    0    0    0    0\n",
       "2     0.0  1.0  0.0                0    0    0    0    0    0\n",
       "3     0.0  1.0  0.0                0    0    0    0    0    0\n",
       "4     0.0  1.0  0.0                0    0    0    0    0    0\n",
       "...   ...  ...  ...              ...  ...  ...  ...  ...  ...\n",
       "9995  0.0  0.0  1.0                0    0    0    0    0    0\n",
       "9996  1.0  0.0  0.0                0    0    0    0    0    0\n",
       "9997  0.0  0.0  1.0                0    0    0    0    0    0\n",
       "9998  1.0  0.0  0.0                0    0    0    0    0    0\n",
       "9999  0.0  0.0  1.0                0    0    0    0    0    0\n",
       "\n",
       "[10000 rows x 9 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loads the dataset\n",
    "predictive_maintenance = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/00601/ai4i2020.csv')\n",
    "\n",
    "# drops some unnecessary columns\n",
    "predictive_maintenance = predictive_maintenance.drop(columns = ['UDI', 'Product ID'])\n",
    "\n",
    "# One hot encoding categorical features\n",
    "encoder = OneHotEncoder().fit(predictive_maintenance[['Type']])\n",
    "encoder.categories_\n",
    "\n",
    "transformed = encoder.transform(predictive_maintenance[['Type']] ).toarray() \n",
    "transformed\n",
    "\n",
    "for index, category in enumerate( np.concatenate(encoder.categories_) ):\n",
    "    predictive_maintenance[category] = transformed[:,index] \n",
    "\n",
    "# Drops columns\n",
    "predictive_maintenance = predictive_maintenance.drop(columns = ['Type','Air temperature [K]','Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]'])\n",
    "\n",
    "# Moves columns to the front\n",
    "cols = predictive_maintenance.columns.tolist()\n",
    "cols = cols[-3:] + cols[:-3]\n",
    "predictive_maintenance = predictive_maintenance[cols]\n",
    "\n",
    "predictive_maintenance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "mineral-cornwall",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stores all columns except Machine Failure in X and Machine Failure in Y\n",
    "X_p = predictive_maintenance.drop(['Machine failure'], axis = 1)\n",
    "Y_p = predictive_maintenance['Machine failure']\n",
    "\n",
    "# Gets 5000 random samples\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_p, Y_p, train_size = 5000, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "universal-solution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "pipe = Pipeline([('classifier', LogisticRegression())])\n",
    "\n",
    "search_space = [{'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['saga'],\n",
    "                 'classifier__penalty': ['l1', 'l2'],\n",
    "                 'classifier__C': np.logspace(-4, 4, 9)},\n",
    "                {'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['lbfgs'],\n",
    "                 'classifier__penalty': ['l2'],\n",
    "                 'classifier__C': np.logspace(-4, 4, 9)},\n",
    "                {'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['lbfgs','saga'],\n",
    "                 'classifier__penalty': ['none']}]\n",
    "                \n",
    "clf = GridSearchCV(pipe, search_space, cv=StratifiedKFold(n_splits=5), \n",
    "                   scoring=['accuracy', 'roc_auc_ovr', 'f1_micro'], refit=False,\n",
    "                   verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "searching-idaho",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "eastern-chrome",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([8.73217583e-03, 1.48085594e-02, 3.93505096e-03, 1.25985146e-02,\n",
       "        5.50675392e-03, 1.20497704e-02, 1.46453857e-02, 1.30670547e-02,\n",
       "        2.07205296e-02, 2.28023529e-02, 8.56017590e-02, 8.98850441e-02,\n",
       "        3.30595064e-01, 3.93773270e-01, 6.43287468e-01, 2.36050320e-01,\n",
       "        6.70819569e-01, 4.99674225e-01, 7.82075238e+00, 5.17470646e+00,\n",
       "        6.61056056e+00, 9.03301535e+00, 1.24118055e+01, 1.40310344e+01,\n",
       "        2.15291192e+01, 3.28871756e+01, 3.95746841e+01, 1.80694236e+01,\n",
       "        5.88468266e-01]),\n",
       " 'std_fit_time': array([9.40382268e-04, 4.35265670e-03, 1.93065471e-05, 8.86803563e-04,\n",
       "        9.37554245e-04, 4.91459860e-04, 1.38588226e-03, 5.70623506e-04,\n",
       "        1.02530301e-03, 1.79310377e-03, 1.98359006e-02, 5.32165376e-03,\n",
       "        5.00375193e-02, 3.81673322e-02, 6.97760987e-02, 7.57179719e-03,\n",
       "        2.35208006e-02, 9.20236049e-03, 3.16791198e-01, 5.68911507e-01,\n",
       "        3.76315230e-01, 6.74330474e-01, 5.92710960e-01, 1.51667433e+00,\n",
       "        2.54229079e+00, 3.99145753e+00, 9.94910408e+00, 1.43973809e+00,\n",
       "        2.29771142e-02]),\n",
       " 'mean_score_time': array([0.01080174, 0.00615811, 0.00512404, 0.00535469, 0.00516529,\n",
       "        0.00533328, 0.00524468, 0.00526791, 0.00557199, 0.00545168,\n",
       "        0.00536361, 0.005478  , 0.00601182, 0.00717883, 0.00743046,\n",
       "        0.0057869 , 0.00614228, 0.00586691, 0.04734311, 0.06492229,\n",
       "        0.04758301, 0.08682737, 0.08474712, 0.0292243 , 0.05240979,\n",
       "        0.06765475, 0.06563039, 0.06839981, 0.00558348]),\n",
       " 'std_score_time': array([1.00301336e-03, 1.11844187e-03, 1.29568159e-05, 1.58422384e-04,\n",
       "        2.86441443e-05, 1.49863296e-04, 2.03019545e-05, 2.79840449e-05,\n",
       "        5.20999175e-04, 1.09235785e-04, 3.86498799e-05, 3.05285010e-04,\n",
       "        5.47684553e-04, 9.68832094e-04, 1.92557353e-03, 5.25838692e-04,\n",
       "        6.60406667e-04, 6.04464041e-04, 4.31654499e-02, 4.68134235e-02,\n",
       "        4.72278893e-02, 3.57714523e-02, 3.56076761e-02, 3.87643181e-02,\n",
       "        4.65985162e-02, 4.61557497e-02, 4.69715988e-02, 4.40856443e-02,\n",
       "        1.36241681e-04]),\n",
       " 'param_classifier': masked_array(data=[LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000)],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__C': masked_array(data=[0.0001, 0.0001, 0.001, 0.001, 0.01, 0.01, 0.1, 0.1,\n",
       "                    1.0, 1.0, 10.0, 10.0, 100.0, 100.0, 1000.0, 1000.0,\n",
       "                    10000.0, 10000.0, 0.0001, 0.001, 0.01, 0.1, 1.0, 10.0,\n",
       "                    100.0, 1000.0, 10000.0, --, --],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False,  True,  True],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__penalty': masked_array(data=['l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1',\n",
       "                    'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'none', 'none'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__solver': masked_array(data=['saga', 'saga', 'saga', 'saga', 'saga', 'saga', 'saga',\n",
       "                    'saga', 'saga', 'saga', 'saga', 'saga', 'saga', 'saga',\n",
       "                    'saga', 'saga', 'saga', 'saga', 'lbfgs', 'lbfgs',\n",
       "                    'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs',\n",
       "                    'lbfgs', 'lbfgs', 'saga'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__penalty': 'none',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__penalty': 'none',\n",
       "   'classifier__solver': 'saga'}],\n",
       " 'split0_test_accuracy': array([0.967, 0.967, 0.967, 0.967, 0.967, 0.967, 0.993, 0.97 , 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.967, 0.967, 0.967, 0.97 , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split1_test_accuracy': array([0.966, 0.966, 0.966, 0.966, 0.966, 0.966, 0.999, 0.966, 0.999,\n",
       "        0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999,\n",
       "        0.966, 0.966, 0.966, 0.966, 0.999, 0.999, 0.999, 0.999, 0.999,\n",
       "        0.999, 0.999]),\n",
       " 'split2_test_accuracy': array([0.966, 0.966, 0.966, 0.966, 0.966, 0.966, 0.991, 0.966, 0.998,\n",
       "        0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998,\n",
       "        0.966, 0.966, 0.966, 0.966, 0.998, 0.998, 0.998, 0.998, 0.998,\n",
       "        0.998, 0.998]),\n",
       " 'split3_test_accuracy': array([0.966, 0.966, 0.966, 0.966, 0.966, 0.966, 1.   , 0.971, 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.966, 0.966, 0.966, 0.971, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split4_test_accuracy': array([0.966, 0.966, 0.966, 0.966, 0.966, 0.966, 0.992, 0.969, 0.998,\n",
       "        0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998,\n",
       "        0.966, 0.966, 0.966, 0.969, 0.998, 0.998, 0.998, 0.998, 0.998,\n",
       "        0.998, 0.998]),\n",
       " 'mean_test_accuracy': array([0.9662, 0.9662, 0.9662, 0.9662, 0.9662, 0.9662, 0.995 , 0.9684,\n",
       "        0.999 , 0.999 , 0.999 , 0.999 , 0.999 , 0.999 , 0.999 , 0.999 ,\n",
       "        0.999 , 0.999 , 0.9662, 0.9662, 0.9662, 0.9684, 0.999 , 0.999 ,\n",
       "        0.999 , 0.999 , 0.999 , 0.999 , 0.999 ]),\n",
       " 'std_test_accuracy': array([0.0004    , 0.0004    , 0.0004    , 0.0004    , 0.0004    ,\n",
       "        0.0004    , 0.00374166, 0.00205913, 0.00089443, 0.00089443,\n",
       "        0.00089443, 0.00089443, 0.00089443, 0.00089443, 0.00089443,\n",
       "        0.00089443, 0.00089443, 0.00089443, 0.0004    , 0.0004    ,\n",
       "        0.0004    , 0.00205913, 0.00089443, 0.00089443, 0.00089443,\n",
       "        0.00089443, 0.00089443, 0.00089443, 0.00089443]),\n",
       " 'rank_test_accuracy': array([21, 21, 21, 21, 21, 21, 18, 19,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1, 21, 21, 21, 19,  1,  1,  1,  1,  1,  1,  1], dtype=int32),\n",
       " 'split0_test_roc_auc_ovr': array([0.5, 1. , 0.5, 1. , 0.5, 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. ,\n",
       "        1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. ,\n",
       "        1. , 1. , 1. ]),\n",
       " 'split1_test_roc_auc_ovr': array([0.5       , 0.92184265, 0.5       , 0.92184265, 0.5       ,\n",
       "        0.9749117 , 0.98529412, 0.97798685, 0.97644928, 0.97798685,\n",
       "        0.97798685, 0.97798685, 0.97798685, 0.97798685, 0.97798685,\n",
       "        0.97798685, 0.97798685, 0.97798685, 0.92184265, 0.92184265,\n",
       "        0.9749117 , 0.97798685, 0.97798685, 0.97798685, 0.97798685,\n",
       "        0.97804774, 0.97804774, 0.97804774, 0.97798685]),\n",
       " 'split2_test_roc_auc_ovr': array([0.5       , 0.98173182, 0.5       , 0.98173182, 0.5       ,\n",
       "        0.98173182, 0.97058824, 0.98173182, 0.97058824, 0.98173182,\n",
       "        0.96504689, 0.96504689, 0.96504689, 0.96504689, 0.96504689,\n",
       "        0.96504689, 0.96504689, 0.96504689, 0.98173182, 0.98173182,\n",
       "        0.98173182, 0.98173182, 0.98173182, 0.96504689, 0.96504689,\n",
       "        0.96504689, 0.96504689, 0.96504689, 0.96504689]),\n",
       " 'split3_test_roc_auc_ovr': array([0.5, 1. , 0.5, 1. , 0.5, 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. ,\n",
       "        1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. ,\n",
       "        1. , 1. , 1. ]),\n",
       " 'split4_test_roc_auc_ovr': array([0.5       , 0.96644745, 0.5       , 0.96644745, 0.5       ,\n",
       "        0.9694008 , 0.97058824, 0.9694008 , 0.97058824, 0.9694008 ,\n",
       "        0.97354159, 0.9694008 , 0.96938558, 0.96943125, 0.96943125,\n",
       "        0.96943125, 0.96943125, 0.96943125, 0.96644745, 0.96644745,\n",
       "        0.9694008 , 0.9694008 , 0.9694008 , 0.9694008 , 0.96943125,\n",
       "        0.96943125, 0.96943125, 0.96943125, 0.96943125]),\n",
       " 'mean_test_roc_auc_ovr': array([0.5       , 0.97400438, 0.5       , 0.97400438, 0.5       ,\n",
       "        0.98520887, 0.98529412, 0.98582389, 0.98352515, 0.98582389,\n",
       "        0.98331507, 0.98248691, 0.98248386, 0.982493  , 0.982493  ,\n",
       "        0.982493  , 0.982493  , 0.982493  , 0.97400438, 0.97400438,\n",
       "        0.98520887, 0.98582389, 0.98582389, 0.98248691, 0.982493  ,\n",
       "        0.98250518, 0.98250518, 0.98250518, 0.982493  ]),\n",
       " 'std_test_roc_auc_ovr': array([0.        , 0.0289455 , 0.        , 0.0289455 , 0.        ,\n",
       "        0.01269308, 0.01315334, 0.01224587, 0.01362084, 0.01224587,\n",
       "        0.01424367, 0.01489341, 0.01489608, 0.01488806, 0.01488806,\n",
       "        0.01488806, 0.01488806, 0.01488806, 0.0289455 , 0.0289455 ,\n",
       "        0.01269308, 0.01224587, 0.01224587, 0.01489341, 0.01488806,\n",
       "        0.01488439, 0.01488439, 0.01488439, 0.01488806]),\n",
       " 'rank_test_roc_auc_ovr': array([27, 23, 27, 23, 27,  6,  5,  1,  8,  1,  9, 20, 22, 13, 13, 13, 13,\n",
       "        13, 23, 23,  6,  1,  1, 20, 13, 10, 10, 10, 13], dtype=int32),\n",
       " 'split0_test_f1_micro': array([0.967, 0.967, 0.967, 0.967, 0.967, 0.967, 0.993, 0.97 , 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.967, 0.967, 0.967, 0.97 , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split1_test_f1_micro': array([0.966, 0.966, 0.966, 0.966, 0.966, 0.966, 0.999, 0.966, 0.999,\n",
       "        0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999,\n",
       "        0.966, 0.966, 0.966, 0.966, 0.999, 0.999, 0.999, 0.999, 0.999,\n",
       "        0.999, 0.999]),\n",
       " 'split2_test_f1_micro': array([0.966, 0.966, 0.966, 0.966, 0.966, 0.966, 0.991, 0.966, 0.998,\n",
       "        0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998,\n",
       "        0.966, 0.966, 0.966, 0.966, 0.998, 0.998, 0.998, 0.998, 0.998,\n",
       "        0.998, 0.998]),\n",
       " 'split3_test_f1_micro': array([0.966, 0.966, 0.966, 0.966, 0.966, 0.966, 1.   , 0.971, 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.966, 0.966, 0.966, 0.971, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split4_test_f1_micro': array([0.966, 0.966, 0.966, 0.966, 0.966, 0.966, 0.992, 0.969, 0.998,\n",
       "        0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998,\n",
       "        0.966, 0.966, 0.966, 0.969, 0.998, 0.998, 0.998, 0.998, 0.998,\n",
       "        0.998, 0.998]),\n",
       " 'mean_test_f1_micro': array([0.9662, 0.9662, 0.9662, 0.9662, 0.9662, 0.9662, 0.995 , 0.9684,\n",
       "        0.999 , 0.999 , 0.999 , 0.999 , 0.999 , 0.999 , 0.999 , 0.999 ,\n",
       "        0.999 , 0.999 , 0.9662, 0.9662, 0.9662, 0.9684, 0.999 , 0.999 ,\n",
       "        0.999 , 0.999 , 0.999 , 0.999 , 0.999 ]),\n",
       " 'std_test_f1_micro': array([0.0004    , 0.0004    , 0.0004    , 0.0004    , 0.0004    ,\n",
       "        0.0004    , 0.00374166, 0.00205913, 0.00089443, 0.00089443,\n",
       "        0.00089443, 0.00089443, 0.00089443, 0.00089443, 0.00089443,\n",
       "        0.00089443, 0.00089443, 0.00089443, 0.0004    , 0.0004    ,\n",
       "        0.0004    , 0.00205913, 0.00089443, 0.00089443, 0.00089443,\n",
       "        0.00089443, 0.00089443, 0.00089443, 0.00089443]),\n",
       " 'rank_test_f1_micro': array([21, 21, 21, 21, 21, 21, 18, 19,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1, 21, 21, 21, 19,  1,  1,  1,  1,  1,  1,  1], dtype=int32)}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "loved-silly",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21, 21, 21, 21, 21, 21, 18, 19,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1, 21, 21, 21, 19,  1,  1,  1,  1,  1,  1,  1], dtype=int32)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.cv_results_['rank_test_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "measured-chapter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 1.0,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for accuracy\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_accuracy']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "strange-switch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 0.1,\n",
       " 'classifier__penalty': 'l2',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for roc auc\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_roc_auc_ovr']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "standard-internet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 1.0,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for f1\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_f1_micro']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "sustainable-topic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best accuracy model\n",
    "acc_model = LogisticRegression(penalty = 'l1', C = 1.0, solver = 'saga', max_iter = 5000)\n",
    "\n",
    "# best roc auc model\n",
    "roc_model = LogisticRegression(penalty = 'l2', C = 0.1, solver = 'saga', max_iter = 5000)\n",
    "\n",
    "# best f1 model\n",
    "f1_model = LogisticRegression(penalty = 'l1', C = 1.0, solver = 'saga', max_iter = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "hairy-stream",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=5000, penalty='l1', solver='saga')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# models the data\n",
    "acc_model.fit(X_train, Y_train)\n",
    "roc_model.fit(X_train, Y_train)\n",
    "f1_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "nervous-kelly",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>C</th>\n",
       "      <th>penalty</th>\n",
       "      <th>solver</th>\n",
       "      <th>score_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           classifier           C penalty solver  score_acc\n",
       "0   LogisticRegression(max_iter=5000)      0.0001      l1   saga     0.0338\n",
       "1   LogisticRegression(max_iter=5000)      0.0001      l2   saga     0.0338\n",
       "2   LogisticRegression(max_iter=5000)      0.0010      l1   saga     0.0338\n",
       "3   LogisticRegression(max_iter=5000)      0.0010      l2   saga     0.0338\n",
       "4   LogisticRegression(max_iter=5000)      0.0100      l1   saga     0.0338\n",
       "5   LogisticRegression(max_iter=5000)      0.0100      l2   saga     0.0338\n",
       "6   LogisticRegression(max_iter=5000)      0.1000      l1   saga     0.0050\n",
       "7   LogisticRegression(max_iter=5000)      0.1000      l2   saga     0.0316\n",
       "8   LogisticRegression(max_iter=5000)      1.0000      l1   saga     0.0010\n",
       "9   LogisticRegression(max_iter=5000)      1.0000      l2   saga     0.0010\n",
       "10  LogisticRegression(max_iter=5000)     10.0000      l1   saga     0.0010\n",
       "11  LogisticRegression(max_iter=5000)     10.0000      l2   saga     0.0010\n",
       "12  LogisticRegression(max_iter=5000)    100.0000      l1   saga     0.0010\n",
       "13  LogisticRegression(max_iter=5000)    100.0000      l2   saga     0.0010\n",
       "14  LogisticRegression(max_iter=5000)   1000.0000      l1   saga     0.0010\n",
       "15  LogisticRegression(max_iter=5000)   1000.0000      l2   saga     0.0010\n",
       "16  LogisticRegression(max_iter=5000)  10000.0000      l1   saga     0.0010\n",
       "17  LogisticRegression(max_iter=5000)  10000.0000      l2   saga     0.0010\n",
       "18  LogisticRegression(max_iter=5000)      0.0001      l2  lbfgs     0.0338\n",
       "19  LogisticRegression(max_iter=5000)      0.0010      l2  lbfgs     0.0338\n",
       "20  LogisticRegression(max_iter=5000)      0.0100      l2  lbfgs     0.0338\n",
       "21  LogisticRegression(max_iter=5000)      0.1000      l2  lbfgs     0.0316\n",
       "22  LogisticRegression(max_iter=5000)      1.0000      l2  lbfgs     0.0010\n",
       "23  LogisticRegression(max_iter=5000)     10.0000      l2  lbfgs     0.0010\n",
       "24  LogisticRegression(max_iter=5000)    100.0000      l2  lbfgs     0.0010\n",
       "25  LogisticRegression(max_iter=5000)   1000.0000      l2  lbfgs     0.0010\n",
       "26  LogisticRegression(max_iter=5000)  10000.0000      l2  lbfgs     0.0010\n",
       "27  LogisticRegression(max_iter=5000)         NaN    none  lbfgs     0.0010\n",
       "28  LogisticRegression(max_iter=5000)         NaN    none   saga     0.0010"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEGCAYAAABYV4NmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAA6IklEQVR4nO3deVyU5fr48c+AUO4mMAwguQR+tcRdk45KoYCGBIpIZn7L3I6WS/6y1MoMFVs0c2mRrI6ZGi4JymiRdA6iJ3NJcSXTRAFhQHFPBYb5/eHXyZFtVIZ5ZrzevZ5XPjPXxdzP/cou7ue+57lVBoPBgBBCCFHNHKzdACGEEPZJCowQQgiLkAIjhBDCIqTACCGEsAgpMEIIISyilrUbIISwnFrOXtZuwn2hpCjnnvKLz/xpdqyTa4t7+qyaJCMYIYQQFiEjGCGEsLZSvbVbYBFSYIQQwtr0JdZugUVIgRFCCCszGEqt3QSLkAIjhBDWVioFRgghhCXY6QhGVpEJISwmJPhJDh3cSsbhbbw++eVyY+Z/FEPG4W38tucnOrRvU2VuZGQ/0vf9TNG1LDp1bGvxa6gRpXrzDxsiBUYIYREODg4sXDCbfmHP49fuKaKjI2jd2tckpm+fQHx9mtPq0e6MGfMGnyyeU2XuoUMZRA0aSVrajhq/JosxlJp/2BC5RSaEsIiuXTpw/HgmJ06cAmD16kSeCQvhyJE/jDFhYSEsX7EWgF93/kbDRg3RaNQ0a+pdYW5GxrGavxgLM8gqMuXIzs5m5MiRdOrUib179+Lu7s6nn37Khg0biI+Pp7i4mKZNm/LBBx9Qu3ZtpkyZQr169Th48CAFBQVMnjyZPn36WPsyhLBrnl4asrJPG8+zc3Lp2qWDSYyXp4bsrL9jcrJz8fLUmJVrV+x0kt9mb5GdPHmSIUOGoNVqqV+/Pj/++CNBQUGsW7eODRs20KJFC9auXWuMz8/PZ+XKlSxZsoR58+ZZseVC3B9UKlWZ127f37CiGHNy7YrcIlOWJk2a0Lp1awAee+wxcnJy+OOPP/j444+5dOkSV65coXv37sb43r174+DggI+PD2fOnLFWs4W4b+Rk5+LdxNN43sTLg9xcnUlMdk4uTbz/jvFq4sHpXB3Ozs5V5toVG5u8N5fNjmCcnZ2Nf3Z0dESv1zNlyhSmT5/Oxo0beeWVVygqKio3Xghhebt278PHpznNmnnj5OTEoEHhbExKNolJSkpm6JCBADzetSMXL1wkLy/frFy7IiMY5bty5Qpubm4UFxezceNG3N3drd0kIe5ber2eCRPfYpN2JY4ODvxrWTyHDx9l1MihAMR9sZxNm1Po0yeQ349s56+rVxkxYlKluQDh4X1YMH8Wbm6N2ZD4Denph3i63xCrXWe1kEl+5ZswYQJRUVF4eXnRsmVLrly5Yu0mCXFf2/zDz2z+4WeT1+K+WG5yPn7Cm2bnAiQm/kBi4g/V10glsNNJfpXBrmfOhLi/yX4wNeNe94O5lr7J7NgH2z19T59Vk+xqBCOEEDbJxuZWzCUFRgghrM1Ob5FJgRFCCGuTEYwQQgiL0BdbuwUWIQVGCCGsTW6R3V+Kz/xp7SYIcc+unk6jtmcPazdDVKWab5Ft3bqV2bNnU1paSlRUFKNGjTL9OIOB2bNnk5qayoMPPsh7773HY489xvXr1xkyZAhFRUXo9XpCQkIYP348AOfPn+fVV18lJycHLy8vPv74Yxo2bFhpO6TACGHn7nUJragB1TiC0ev1xMTE8PXXX+Pu7s7AgQMJDAzEx8fHGLN161YyMzNJTk4mPT2dGTNmsGbNGpydnVm2bBl169aluLiY5557jp49e9K+fXvi4uLw9/dn1KhRxMXFERcXx+TJkytti80+KkYIIexGaan5RxX2799P06ZN8fb2xtnZmdDQUFJSUkxiUlJSiIiIQKVS0b59ey5evEh+fj4qlYq6desCUFJSQklJifHBozdzACIiItiyZUuVbZECI4QQVmbQF5t9VEWn06HRaIzn7u7u6HS6SmM0Go0xRq/XEx4ezhNPPMETTzxBu3btADh79ixqtRoAtVpNYWFhlW2RW2RCCGFtdzAHEx8fT3x8vPE8Ojqa6Ojov39UOQ9nuX37g8piHB0dSUxM5OLFi7z88sscPXqUli1bmt2+W0mBEUIIa7uDOZjbC8rtNBoNeXl5xnOdTmcceVQUk5eXVyamQYMGPP7446SlpdGyZUtcXFzIz89HrVaTn59P48aNq2yr3CITQghrq8bH9fv5+ZGZmUlWVhZFRUVotVoCAwNNYgIDA0lISMBgMLBv3z7q169vvO118eJFAK5du8Z///tfWrRoYZIDkJCQQK9evapsi4xgFGrbjt289/Hn6EtLiQzrw4ihg0zeNxgMzPn4c9J+2cWDDz7A7Df/H4/+jw/XrxfxwsuTKSouRl+iJ+ip7rwyYqhJ7tcr1zLvky9J037HQ40qX2Zoz6SPhWJU4yqyWrVqMX36dEaMGIFerycyMhJfX19WrVoFwODBgwkICCA1NZWgoCBq165NbGwscGPn3ylTpqDX6zEYDPTp04ennnoKgFGjRjFx4kTWrl2Lh4cHCxYsqLot1XZVd+Bu12hXllvRGu1z584xfvx4Dh48SP/+/Zk+fXqNX++d0uv1zJr3CV98HItG7Ur0iAk81f1xHmne1BiT9ssuTmWfZlP8l+w/lMHMuYtZ9cXHODs78dXC96hTpzbFJSX875jX6NGtM+3a3Nj9M1dXwC+79uLhrq7o4+8L0sdCUar5ezABAQEEBASYvDZ48GDjn1UqFe+8806ZvFatWhlHKbd76KGHWLZs2R21o8Zvkd1co7106VK0Wi1JSUkcO3bMJObWNdozZ85kxowZVebeXKOdnJyMv78/cXFxADzwwANMmDCB119/vUav814cOHKUh5t44u3lgZOTE317BfBz2g6TmH9v28EzfXqhUqlo16Y1ly5dpuBMISqVijp1agNllxkCfLBwCZPGDqecLc/vK9LHQlFKSsw/bEiNF5h7WaNdWW5Fa7Tr1KlD586deeCBB2r0Ou9FfsEZNGo347m72pX8grMmMbqCs2jUriYxuoIzwI1CHPnCy/TsNxj/Lh1o+1grAP6dtgO1myutfFvUwFUom/SxUBQ73TK5xgvMvazRriz3btZoK1V5W8Dd/ttwVcsM1y37hJT1yzlw+Ch//JnJ1WvXiPvmuzJzBfcr6WOhKNX4RUslqfECcy9rtM3JtQfualfy8guM57r8M7i5upjEaNSu5OWfMYlR3xbToH49unRsy7Ydu8nKySXndB6RL4wlOPIFdAVniHppHGfO2m4hvhfSx0JRZARTPe5ljXZluTfXaANmr9FWqjatWnIq+zTZp/MoLi5mc0oqT3XvZhLzZPdubPghBYPBQPrBI9SrVxc318YUnjvPxUuXAbh2/To7du2leVNvWj7SnK3a70het4zkdctwd3NlzVeLcHWx3X66F9LHQlHsdART46vIbl2j7e7ujlarZd68eSYxgYGBfPvtt4SGhpKenm5co924ceMKc2+u0R41apTZa7SVqlYtR6a9OobRk95Cr9fTv18wPi2aEr9eC0B0/1B6+nch7Zdd9B30ErUffJCZ014FoODsOd6cNRd9aSmGUgMhgT148h+PW/NyFEn6WCiKjY1MzKUylHffycJSU1OJjY01rtEeM2aMyRptg8FATEwMaWlpxjXafn5+FeYCnDt3jokTJ5Kbm2tco92oUSPgRvG5fPkyxcXF1K9fn6+++srkyaLlkcf1C3vh5CoLDpTu6uoYs2NrD1L+Vy1uskqBsQVSYIS9kAKjfFfj3zU7tnZ02e+vKJV8k18IIazNxuZWzCUFRgghrE0KjBBCCIuw00l+KTBCCGFter21W2ARUmCEEMLa5BaZEEIIi5ACI4QQwiJkDkYIIYQlGErt8+uIUmCEEMLa5BaZEEIIi5BVZEIIISxCRjBCCCEswk4LTI3vByPMs23Hbvo9O4K+g15i6fLVZd43GAzEzv+MvoNeov//juHw78cAuH69iGdHTGDAC2MJHzKaxUuXl8n9euVa2vyjL+fOX7D4dSiZ9LFQDIPB/MOGKK7AbN26lZCQEIKCgoiLiyvzvsFgYNasWQQFBREWFsahQ4eqzN28eTOhoaG0atWKAwcO1Mh13Au9Xs+seZ/w2byZbFixhE1b/sPxEydNYtJ+2cWp7NNsiv+SGa+PZ+bcxQA4Ozvx1cL3+H7Zp6xd9gnbf91D+sEjxrxcXQG/7NqLh7vpJm/3G+ljoSh2uuGYogqMXq8nJiaGpUuXotVqSUpK4tixYyYxW7duJTMzk+TkZGbOnMmMGTOqzG3ZsiWLFi2iS5cuNX1Jd+XAkaM83MQTby8PnJyc6NsrgJ/TdpjE/HvbDp7p0wuVSkW7Nq25dOkyBWcKUalU1KlTG4CSkhJKSkpMtpX+YOESJo0dXmb/+fuN9LFQlFKD+YcNUVSB2b9/P02bNsXb2xtnZ2dCQ0NJSUkxiUlJSSEiIgKVSkX79u25ePEi+fn5leY+8sgjtGhhO3ti5BecQaN2M567q13JLzhrEqMrOItG7WoSoyu4sX+8Xq8n8oWX6dlvMP5dOtD2sVYA/DttB2o3V1r52k5fWIr0sVAUvd78w4YoqsDodDo0Go3x3N3dHZ1OV2mMRqNBp9OZlWsryrvNevtvw+XtE3fzt2hHR0fWLfuElPXLOXD4KH/8mcnVa9eI++Y7Xhkx1BJNtjnSx0JJDKWlZh+2RFEFprK/0FXFmJNrK9zVruTlFxjPdflncHN1MYnRqF3Jyz9jEqO+LaZB/Xp06diWbTt2k5WTS87pPCJfGEtw5AvoCs4Q9dI4zpwttOzFKJT0sVCUar5Fdrdz2bm5uQwdOpS+ffsSGhrKsmXLjDmLFi2iR48ehIeHEx4eTmpqapXtUFSB0Wg05OXlGc91Oh1qtbrSmLy8PNRqtVm5tqJNq5acyj5N9uk8iouL2ZySylPdu5nEPNm9Gxt+SMFgMJB+8Aj16tXFzbUxhefOc/HSZQCuXb/Ojl17ad7Um5aPNGer9juS1y0jed0y3N1cWfPVIlxdGlvjEq1O+lgoiqHU/KMK9zKX7ejoyJQpU9i8eTPx8fGsXLnSJPfFF18kMTGRxMREAgICqmyLor4H4+fnR2ZmJllZWbi7u6PVapk3b55JTGBgIN9++y2hoaGkp6dTv3591Go1jRs3rjLXVtSq5ci0V8cwetJb6PV6+vcLxqdFU+LXawGI7h9KT/8upP2yi76DXqL2gw8yc9qrABScPcebs+aiLy3FUGogJLAHT/7jcWtejiJJHwtFqcbJ+1vnowHjfLSPj48xpqK5bLVabfzFvF69erRo0QKdTmeSeydUhvLuLVlRamoqsbGxNyZRIyMZM2YMq1atAmDw4MEYDAZiYmJIS0ujdu3axMbG4ufnV2EuwE8//cTMmTMpLCykQYMGtG7dmi+//LLSdhSf+dOyFypEDXFylQUHSndl+rNmxyY91p/4+HjjeXR0NNHR0cbzH374gbS0NGbPng1AQkIC+/fvZ/r06caY0aNHM3LkSDp37gzACy+8wGuvvWb8fylAdnY2zz//PElJSdSrV49Fixaxfv166tatS5s2bZgyZQoNGzastK2KGsEABAQElBl6DR482PhnlUrFO++8Y3YuQFBQEEFBQdXbUCGEqC538Lj+2wtKmR91D3PZN125coXx48czbdo06tWrB9z4//DYsWNRqVQsWLCA9957jzlz5lTaVkXNwQghxH2pGif572UuG6C4uJjx48cTFhZGcHCwMcbV1RVHR0ccHByIiooy60vrUmCEEMLKqnOZ8q1z2UVFRWi1WgIDA01iAgMDSUhIwGAwsG/fPuNctsFg4M0336RFixYMGzbMJCc/P9/45y1btuDr61tlWxR3i0wIIe471TjJX6tWLaZPn86IESOM89G+vr4mc9kBAQGkpqYSFBRknMsG2LNnD4mJibRs2ZLw8HAAJk2aREBAAB9++CEZGRkAeHl5ERMTU2VbFDfJrxQyyS/shUzyK9/lyf3Njq334XoLtqR6yQhGCCGszcYeAWMuKTBCCGFlBht7iKW5pMAIIYS1SYERQghhETb2EEtzSYERQghrkxGMEEIIi5ACI4QQwhIMevu8RSbf5FeobTt20+/ZEfQd9BJLl68u877BYCB2/mf0HfQS/f93DId/v/FI7evXi3h2xAQGvDCW8CGjWbx0eZncr1eupc0/+nLu/AWLX4eSSR8LxZAtk63rbjfQAZg6dSr+/v7069evJpt81/R6PbPmfcJn82ayYcUSNm35D8dPnDSJSftlF6eyT7Mp/ktmvD6emXMXA+Ds7MRXC9/j+2WfsnbZJ2z/dQ/pB48Y83J1Bfyyay8e7ra5V051kT4WSmIoNZh92BKbKDD3soEOwIABA1i6dGkNt/ruHThylIebeOLt5YGTkxN9ewXwc9oOk5h/b9vBM316oVKpaNemNZcuXabgTCEqlYo6dWoDUFJSQklJiclTUj9YuIRJY4eX2R74fiN9LBRFRjDWc+sGOs7OzsYNdG5V0QY6AF26dKly3wIlyS84g0btZjx3V7uSX3DWJEZXcBaN2tUkRldwY3tfvV5P5Asv07PfYPy7dKDtY60A+HfaDtRurrTylUeHSB8LRSm9g8OG2ESB0el0aDQa47m7uzs6na7SGI1GUybGVpT3dLjbfxuubD8HR0dH1i37hJT1yzlw+Ch//JnJ1WvXiPvmO14ZMdQSTbY50sdCSQwlpWYftsQmCkx1bKBjS9zVruTlFxjPdflncHN1MYnRqF3Jyz9jEqO+LaZB/Xp06diWbTt2k5WTS87pPCJfGEtw5AvoCs4Q9dI4zpwttOzFKJT0sVAUGcFYz71uoGNr2rRqyans02SfzqO4uJjNKak81b2bScyT3bux4YcUDAYD6QePUK9eXdxcG1N47jwXL10G4Nr16+zYtZfmTb1p+Uhztmq/I3ndMpLXLcPdzZU1Xy3C1aWxNS7R6qSPhZLY6yS/TXwP5tYNdNzd3dFqtcybN88kJjAwkG+//ZbQ0FDS09ONG+jYolq1HJn26hhGT3oLvV5P/37B+LRoSvx6LQDR/UPp6d+FtF920XfQS9R+8EFmTnsVgIKz53hz1lz0paUYSg2EBPbgyX88bs3LUSTpY6EoNjYyMZfN7AeTmppKbGyscQOdMWPGmGygYzAYiImJIS0tzbiBjp+fH3Bjw5ydO3dy7tw5XFxcGDduHFFRUZV+nuwHI+yF7AejfIX9A8yObbw+1YItqV42U2BqmhQYYS+kwChfYfgdFJhE2ykwNnGLTAgh7JmhxNotsAwpMEIIYWUGO52DkQIjhBDWJgVGCCGEJcgIRgghhEVIgbnPdG7zvLWbYNd2Jr9j7SbcP2QVmeIZ9Lb51JGqSIERQggrs9cRjE08KkYIIeyZoVRl9mGOu90/Kzc3l6FDh9K3b19CQ0NZtmyZMef8+fMMGzaM4OBghg0bxoULVW+mJwVGCCGszFBq/lGVe9k/y9HRkSlTprB582bi4+NZuXKlMTcuLg5/f3+Sk5Px9/cvt3DdTgqMEEJYmcGgMvuoyr3sn6VWq3nssccAqFevHi1atDBue3IzByAiIoItW7ZU2RaZgxFCCCu7kzmY+Ph44uPjjefR0dFER0cbz8vbP2v//v0mP6Oi/bNufUBwdnY2R44coV27dgCcPXvW+L5araawsOptKKTACCGElZXewSqy2wvK7apj/6wrV64wfvx4pk2bRr169cxu2+2kwCjUE089zhszJ+Lg6Mj6FRv5avHyMjFvzHqV7r38uXb1Gm9PmEXGgaOV5v7zteFEDnmGwrPnAFg0ZwnbUn6puYtSmG17D/P+199TWlrKgF7+DO8fZPK+wWDg/a/XkfbbYR58wJmZLw/h0RbeXC8qZtj0BRSVlKDXl9K7W3tejn4agHnfJJC65yBOtWrh7e5KzMvP0aBuHWtcnrAh5k7em+Ne988qLi5m/PjxhIWFERwcbIxxcXEx3kbLz8+nceOq9zmy+TmYqlZLHD9+nOjoaNq0acOXX35phRbeOQcHB6bNeY2xz/0/+vd8jj79e9OiZTOTmO69/Hm4RRPC/AcR89r7vPX+ZLNyl8d9R3TvF4nu/eJ9XVz0+lJiv1zDZ2/+k4T509i8fQ/Hs3JNYrbtPczJ3AKSFr3N9NHRzPpiNQDOTrVY+s441s6dwuoP32D7viOkHz0BgH+7/+H7j6aybt4Umnq68eX6n2r82oTtqc5VZLfun1VUVIRWqyUwMNAkJjAwkISEBAwGA/v27TPun2UwGHjzzTdp0aIFw4YNKzcHICEhgV69elXZFpsuMOaslmjUqBFvvvkmw4cPt1Ir71ybDo+SdSKbnFOnKSku4YeELTwZ0sMk5qmQHmxc/QMAB347RP0G9XBVu5iVK+DgsZM8rHGjibsrTk616POPjvx79wGTmH/vOkBYQFdUKhXtWjbn0pWrFJy7gEqlok7tBwAo0esp0euNtxeeaNeaWo6OALT1bYbu7PkavS5hmwwG84+q1KpVi+nTpzNixAiefvpp+vbti6+vL6tWrTLuoRUQEIC3tzdBQUG8/fbbvPPOjS8+79mzh8TERHbs2EF4eDjh4eGkpt7YHmDUqFFs376d4OBgtm/fzqhRo6puy913ifXduloCMK6W8PHxMca4uLjg4uJi7CRboPZwI++0znien1uAX8dHy8TobonR5Rag9nCrMvfZlwYSFtWXw+kZzJ2xiEsXLlnwSpRLV3ged5dGxnP3xo048MdJk5j8wgtobo1xaUR+4QXcHmqIXl/Ks298yKm8Ap7t04O2vs3KfMb6f++gzxMdLXQFwp5U5y0yuFFAAgJM95gZPHiw8c8qlcpYVG7VuXNnfv/993J/5kMPPWTyvRhz2PQIprzVEjeX1NkyVTn/rZWZlCsnyGAwVJq7+l/f0+/xKAb1eoEC3VlemzGuOpprN8yaCP2/fzs6OrBm7hv8tCSGg8dO8sep0yZxcet+pJaDI6E9OluqucKOVOcyZSWx6QJjzmoJW6Q7XYDG0914rvZwIz/vjElM/ul83G+JcfdwoyDvTKW5hWfOUVpaisFg4PsVibTpYDoqup+4N25kcvtKV3get8YNTGNcGpF3a8zZ87g1bmgS06BuHTo/5sv2fUeMryX+51e27jnEnAn/axf/PQrL0+tVZh+2xKYLjDmrJWzRoX1HeLhFE7we9qCWUy36RPQmNXmbScx/krcRNqgPAH4dH+PypSucyT9baa6r2sWYH9g3gGMZ9++20I/5PMzJ3AKydWcpLi7hh+2/8WRnP5OYJzv7sTF1JwaDgfSjJ6hf50HcHmpI4YVLXLzyFwDXrhexY//vNPe6UdS37T3M1wlbWPjGSGo/4Fzj1yVsk72OYGx6DubW1RLu7u5otVrmzZtn7WbdM71ez5xpH/HZqvk4ODqSsCqJ47+fIOp/IwBY800CaVv+S/de/iTtWMO1q9eYPnF2pbkAr779Mv/TxheDwcDprFxmTv7AWpdodbUcHZk2fCBjZn+KvrSUiKe64ePtwer/K8aDgrvTo+OjpO09ROi4GB50vrFMGeDM+Yu8tfhb9KUGSg0GQvzbE9CpDQBzvlxLUUkJo2d+CkDbls14e1TF31kQAqp/DkYpVIby7jPZkNTUVGJjY9Hr9URGRjJmzBjjSonBgwdTUFBAZGQkly9fxsHBgTp16rBp06YqvzzUTvNETTT/viWP6685D7QNsXYTRBWO+D5tdmzrPzZZsCXVy+YLjKVIgbEsKTA1RwqM8h1+JNTs2EePay3Ykupl07fIhBDCHuhLbXo6vEJSYIQQwsrs9T6SFBghhLCyUhtbHWauSsdlJ0+eZM+ePWVe3717N6dOnbJYo4QQ4n5ir8uUKy0wsbGx1K1bt8zrDzzwALGxsRZrlBBC3E+q81lkSlLpLbKcnBxatWpV5nU/Pz9ycnIs1iglOFR4suogcdfqdn7J2k24b5QU2fffVXtgr7fIKi0w169fr/C9a9euVXtjhBDifmSvq8gqvSo/Pz9Wr15d5vU1a9YY920WQghxbwx3cNiSSr9oeebMGV555RWcnJyMBeXgwYMUFxezePFi3NzcaqyhNa2Ws5e1myBEtZBbZMr3X49Is2OfyF1nwZZUr0pvkbm6uvLdd9+xY8cO/vjjD+DGPgP+/v410jghhLgf2NrqMHOZ9T2Ybt260a1bN0u3RQgh7kul1m6AhcgXLYUQwsoM2OcIxj6XLtiBkOAnOXRwKxmHt/H65JfLjZn/UQwZh7fx256f6NC+TZW5kZH9SN/3M0XXsujUsa3Fr0HppI+FUpQYVGYftsTmC8zUqVPx9/enX79+5b5vMBiYNWsWQUFBhIWFcejQoRpu4Z1zcHBg4YLZ9At7Hr92TxEdHUHr1r4mMX37BOLr05xWj3ZnzJg3+GTxnCpzDx3KIGrQSNLSdtT4NSmN9LFQEgMqsw9bYvMFZsCAASxdurTC97du3UpmZibJycnMnDmTGTNm1Fzj7lLXLh04fjyTEydOUVxczOrViTwTZvrI9bCwEJavWAvArzt/o2Gjhmg06kpzMzKOcfTo8Rq/HiWSPhZKUnoHhy2x+QLTpUsXGjZsWOH7KSkpREREoFKpaN++PRcvXiQ/P78GW3jnPL00ZGWfNp5n5+Ti6akxifHy1JCd9XdMTnYuXp4as3KF9LFQFhnB2CidTodG8/dffo1Gg06ns2KLqqZSlf2P6PavK1UUY06ukD4WymKvIxi7X0VW3l/88v4HoSQ52bl4N/E0njfx8iA317QoZufk0sT77xivJh6cztXh7OxcZa6QPhbKorexkYm57H4Eo9FoyMvLM57n5eWhVqut2KKq7dq9Dx+f5jRr5o2TkxODBoWzMSnZJCYpKZmhQwYC8HjXjly8cJG8vHyzcoX0sVCWUpX5hzm2bt1KSEgIQUFBxMXFlXm/ssVPFS2cWrRoET169CA8PJzw8HBSU1OrbIfdj2ACAwP59ttvCQ0NJT09nfr16yu+wOj1eiZMfItN2pU4Ojjwr2XxHD58lFEjhwIQ98VyNm1OoU+fQH4/sp2/rl5lxIhJleYChIf3YcH8Wbi5NWZD4jekpx/i6X5DrHad1iR9LJSktBpHMHq9npiYGL7++mvc3d0ZOHAggYGB+Pj4GGNuXfyUnp7OjBkzWLNmDXBj4dTzzz/PG2+8UeZnv/jiiwwfPtzstlT6LDJbMGnSJHbu3Mm5c+dwcXFh3LhxlJSUADB48GAMBgMxMTGkpaVRu3ZtYmNj8fPzq/LnyrPIhL2QZ5EpX4LmObNjI/JWVvr+3r17Wbx4MV9++SUAS5YsAWD06NHGmOnTp9O1a1fjKCUkJITly5cbf/nOzs7mn//8J0lJScacRYsWUadOnTsqMDY/gvnoo48qfV+lUvHOO+/UUGuEEOLO3cnkfXx8PPHx8cbz6OhooqOjjee3L2xyd3dn//79Jj+josVPVd3dWbFiBQkJCbRp04YpU6ZUuoIX7KDACCGErSu9g4VHtxeU25mzsOluFj8NHjyYsWPHolKpWLBgAe+99x5z5sypNMfuJ/mFEELp9HdwVOX2hU3ljUzuZvGTq6srjo6OODg4EBUVxYEDB6psixQYIYSwsupcRebn50dmZiZZWVkUFRWh1WoJDAw0iQkMDCQhIQGDwcC+ffvMWvx06xfUt2zZgq+vbyXRN8gtMiGEsLLqXEVWq1Ytpk+fzogRI9Dr9URGRuLr68uqVauAG7e6AgICSE1NJSgoyLj46aZbF0717NmTcePGERUVxYcffkhGRgYAXl5exMTEVNkWm19FZimyikzYC1lFpnzfej5vduzzp7+1YEuql4xghBDCysz9AqWtkQIjhBBWZmvPGDOXFBghhLAyvYxghBBCWIKMYIQQQliEFBghhBAWYZBbZEIIISzBXkcw8k1+hQoJfpJDB7eScXgbr09+udyY+R/FkHF4G7/t+YkO7dtUmRsZ2Y/0fT9TdC2LTh3bWvwalE76WChFdT4qRklsosCUtwHO+fPnGTZsGMHBwQwbNowLFy6Um1vVxjtK5ODgwMIFs+kX9jx+7Z4iOjqC1q1NH8vQt08gvj7NafVod8aMeYNPFs+pMvfQoQyiBo0kLW1HjV+T0kgfCyWp7g3HlMImCsyAAQNYunSpyWtxcXH4+/uTnJyMv79/ucXj5sY7S5cuRavVkpSUxLFjx2qq2Xeta5cOHD+eyYkTpyguLmb16kSeCQsxiQkLC2H5irUA/LrzNxo2aohGo640NyPjGEePHq/x61Ei6WOhJKV3cNgSmygwXbp0KbPvQEpKChEREQBERESwZcuWMnn79++nadOmeHt74+zsTGhoKCkpKTXR5Hvi6aUhK/u08Tw7JxdPT41JjJenhuysv2NysnPx8tSYlSukj4WySIFRmLNnzxqf/qlWqyksLCwTU97GOzqdrsbaeLfK25fh9kfGVRRjTq6QPhbKYriDw5bY9Sqyu9lURwlysnPxbuJpPG/i5UFurmlhzM7JpYn33zFeTTw4navD2dm5ylwhfSyUxdbmVsxlsyMYFxcX4/4E+fn5NG7cuEyMORvvKNGu3fvw8WlOs2beODk5MWhQOBuTkk1ikpKSGTpkIACPd+3IxQsXycvLNytXSB8LZZFVZApzc8McgISEBHr16lUmxpyNd5RIr9czYeJbbNKu5OD+/7B27UYOHz7KqJFDGTVyKACbNqfw54lT/H5kO59//gGvjJtWaS5AeHgfMv/cTbdundiQ+A2bklZY7RqtTfpYKEkpBrMPW2IT+8HcugGOi4sL48aNo3fv3kycOJHc3Fw8PDxYsGABjRo1QqfT8dZbb/HFF18AkJqaSmxsrHHjnTFjxpj1mbIfjLAXsh+M8s1sOsTs2LdP2s4vLTZRYKxBCoywF1JglC/mDgrMdBsqMHY9yS+EELbA1pYfm0sKjBBCWFmJyj5vJEmBEUIIK7PP8iIFRgghrE5ukQkhhLAIW1t+bC4pMEIIYWX2WV6kwAghhNXZ6y0ym/0mvxBC2As9BrMPc1S1D5bBYGDWrFkEBQURFhbGoUOHjO+Vt/8WmL8H162kwAghhJVV5+P6zdkHa+vWrWRmZpKcnMzMmTOZMWOG8b3y9t8C8/bgup0UGCGEsDLDHfxTFXP2wbq5n5ZKpaJ9+/ZcvHjR+PDg8vbfujUHKt6D63YyByOEEFZ2J3Mw8fHxxMfHG8+jo6OJjo42npe3D9b+/ftNfsbtMRqNpsqnzZuzB9ftZASjUCHBT3Lo4FYyDm/j9ckvlxsz/6MYMg5v47c9P9GhfZsqcyMj+5G+72eKrmXRqWNbi1+D0kkfC6W4k6cpR0dH8/333xuPW4sLmLcPVk3tlaWoAlPe5FJlE0tLliwhKCiIkJAQ0tLSyv2ZdzMxZW0ODg4sXDCbfmHP49fuKaKjI2jd2tckpm+fQHx9mtPq0e6MGfMGnyyeU2XuoUMZRA0aSVrajhq/JqWRPhZKUp07WpqzD9btMXl5eVXulWXOHly3U1SBKW9yqaKJpWPHjqHVatFqtSxdupR3330Xvb7sdjx3MzFlbV27dOD48UxOnDhFcXExq1cn8kxYiElMWFgIy1esBeDXnb/RsFFDNBp1pbkZGcc4evR4jV+PEkkfCyUpwWD2URVz9sG6uZ+WwWBg37591K9fv8oCY84eXLdTVIEpb3KpoomllJQUQkNDb2xf6+1N06ZNy9xnrCxfyTy9NGRlnzaeZ+fk4umpMYnx8tSQnfV3TE52Ll6eGrNyhfSxUJbqnOSvVasW06dPZ8SIETz99NP07dsXX19fVq1axapVqwAICAjA29uboKAg3n77bd555x1j/qRJk3j22Wc5ceIEPXv2ZM2aNQCMGjWK7du3ExwczPbt2xk1alTVbbnL/qgxFU0s6XQ62rVrZ4xzd3dHpyu7L/rdTExZW3n3Qm+/Z1pRjDm5QvpYKEt1f9EyICCAgIAAk9cGDx5s/LNKpTIpKrf66KOPyn39oYceYtmyZXfUDsUXmIrU1CSVNeRk5+LdxNN43sTLg9xc0+KZnZNLE++/Y7yaeHA6V3djRFdFrpA+FspizsjEFinqFll5KppYMmciq7J8Jdu1ex8+Ps1p1swbJycnBg0KZ2NSsklMUlIyQ4cMBODxrh25eOEieXn5ZuUK6WOhLNX5RUslUXyBqWhiKTAwEK1WS1FREVlZWWRmZtK2bdlloXczMWVter2eCRPfYpN2JQf3/4e1azdy+PBRRo0cyqiRQwHYtDmFP0+c4vcj2/n88w94Zdy0SnMBwsP7kPnnbrp168SGxG/YlGQ7W69WN+ljoSR6g8Hsw5aoDAq6eTxp0iR27tzJuXPncHFxYdy4cfTu3ZuJEyeSm5uLh4cHCxYsoFGjRgB89tlnrFu3DkdHR6ZNm2a85/jmm2/y7LPP4ufnx7lz5yrMr0wtZy8LXqkQNaekKMfaTRBVeK5pf7NjV55cb8GWVC9FFRglkQIj7IUUGOUb3DTC7NhVJxMs1o7qZrOT/EIIYS9sbW7FXFJghBDCymRHSyGEEBZhr8uUpcAIIYSV2drqMHNJgRFCCCuTW2RCCCEsQib5hRBCWITMwQghhLAIuUUmhBDCIuz1++5SYIQQwsr0MoIRQghhCXKLTAghhEXY6y0yxT+u/34VEvwkhw5uJePwNl6f/HK5MfM/iiHj8DZ+2/MTHdq3qTI3MrIf6ft+puhaFp06lt3a4H4jfSyUohSD2YctsUqBmTp1Kv7+/vTr18/42vnz5xk2bBjBwcEMGzaMCxcuGN9bsmQJQUFBhISEkJaWZnz94MGDhIWFERQUxKxZsyr8LaCifKVycHBg4YLZ9At7Hr92TxEdHUHr1r4mMX37BOLr05xWj3ZnzJg3+GTxnCpzDx3KIGrQSNLSdtT4NSmN9LFQEsMd/GNLrFJgBgwYwNKlS01ei4uLw9/fn+TkZPz9/YmLiwPg2LFjaLVatFotS5cu5d1330Wv1wMwY8YMYmJiSE5OJjMzk61bt5b5rMrylaprlw4cP57JiROnKC4uZvXqRJ4JCzGJCQsLYfmKtQD8uvM3GjZqiEajrjQ3I+MYR48er/HrUSLpY6Ek9rrhmFUKTJcuXWjYsKHJaykpKURERAAQERHBli1bjK+Hhobe2Afd25umTZuyf/9+8vPzuXz5Mh06dEClUhEREUFKSkqZz6ooX8k8vTRkZZ82nmfn5OLpqTGJ8fLUkJ31d0xOdi5enhqzcoX0sVAWuUVmYWfPnkWtVgOgVqspLCwEQKfTodH8/ZfX3d0dnU5X5nWNRoNOpyvzcyvKVzKVSlXmtdtv/1UUY06ukD4WymKvBUbxq8jK+4urUqkqfN3cfCXLyc7Fu4mn8byJlwe5uaZFMTsnlybef8d4NfHgdK7uxkitilwhfSyUxV5/QVHMCMbFxYX8/HwA8vPzady4MXBjZJKXl2eM0+l0qNXqMq/n5eUZR0C3qihfyXbt3oePT3OaNfPGycmJQYPC2ZiUbBKTlJTM0CEDAXi8a0cuXrhIXl6+WblC+lgoi72OYBRTYAIDA0lISAAgISGBXr16GV/XarUUFRWRlZVFZmYmbdu2Ra1WU7duXfbt24fBYDDJuf3nlpevZHq9ngkT32KTdiUH9/+HtWs3cvjwUUaNHMqokUMB2LQ5hT9PnOL3I9v5/PMPeGXctEpzAcLD+5D55266devEhsRv2JS0wmrXaG3Sx0JJqnsV2datWwkJCSEoKMi4YMrk8wwGZs2aRVBQEGFhYRw6dKjK3EWLFtGjRw/Cw8MJDw8nNTW1ynaoDFYYm02aNImdO3dy7tw5XFxcGDduHL1792bixInk5ubi4eHBggULaNSoEQCfffYZ69atw9HRkWnTphEQEADAgQMHmDp1KteuXaNnz568/fbbqFQqUlJSOHjwIBMmTKg0vzK1nL0sdv1C1KSSohxrN0FUoaNHd7Njf8vdVun7er2ekJAQvv76a9zd3Rk4cCAfffQRPj4+xpjU1FSWL1/OF198QXp6OrNnz2bNmjWV5i5atIg6deowfPhws9tqlQJjC6TACHshBUb5Omj+YXbs3rztlb+/dy+LFy/myy+/BG58DxBg9OjRxpjp06fTtWtX43cRQ0JCWL58OTk5ORXm3k2BUcwtMiGEuF/dyRxMfHw8AwYMMB7x8fEmP8uclbMVrcKtKnfFihWEhYUxdepUky/DV0Txq8iEEMLe3ck39KOjo4mOjq74Z5mxcvZuVucOHjyYsWPHolKpWLBgAe+99x5z5syptK0yghFCCCsrNRjMPqpizsrZilbhVpbr6uqKo6MjDg4OREVFceDAgSrbIgVGCCGsrDpXkfn5+ZGZmUlWVhZFRUVotVoCAwNNYm6u2jUYDOzbt4/69eujVqsrzb35NRKALVu24Otr+uy+8sgtMiGEsDK9obTaflatWrWYPn06I0aMQK/XExkZia+vL6tWrQJu3OoKCAggNTWVoKAgateuTWxsbKW5AB9++CEZGRkAeHl5ERMTU2VbZBVZBWQVmbAXsopM+Vq6dTY79mjBbgu2pHrJCEYIIazM1h7Dby4pMEIIYWXmTN7bIikwQghhZTKCEUIIYRF6g7I3QbxbUmCEEMLK7HWtlRQYIYSwMlt7DL+55IuWChUS/CSHDm4l4/A2Xp/8crkx8z+KIePwNn7b8xMd2repMjcysh/p+36m6FoWnToqe8uCmiB9LJTCYDCYfdgSixWYqVOn4u/vb3xaJ8D58+cZNmwYwcHBDBs2zORhaUuWLCEoKIiQkBDS0tKMrx88eJCwsDCCgoKYNWuWsYOLioqYOHEiQUFBREVFkZ2dXW47KspXMgcHBxYumE2/sOfxa/cU0dERtG5t+q3Zvn0C8fVpTqtHuzNmzBt8snhOlbmHDmUQNWgkaWk7avyalEb6WChJdT4qRkksVmAGDBjA0qVLTV6Li4vD39+f5ORk/P39jZvZHDt2DK1Wi1arZenSpbz77rvo9TcmvWbMmEFMTAzJyclkZmaydetWANasWUODBg346aefePHFF5k7d2657agoX8m6dunA8eOZnDhxiuLiYlavTuSZsBCTmLCwEJavWAvArzt/o2Gjhmg06kpzMzKOcfTo8Rq/HiWSPhZKUt0bjimFxQpMly5daNiwoclrKSkpREREABAREcGWLVuMr4eGht7Y69zbm6ZNm7J//37y8/O5fPkyHTp0QKVSERERQUpKCgA///wz/fv3B27sZfDLL7+UGZ1Ulq9knl4asrJPG8+zc3Lx9NSYxHh5asjO+jsmJzsXL0+NWblC+lgoi95QavZhS2p0Dubs2bPGJ3Oq1WoKCwuBivcvqGjPgps5Hh4ewI3n59SvX59z586ZfF5l+Up2+6O1oewqk4pizMkV0sdCWex1DkYRq8juZm+Ce9nzQOlysnPxbuJpPG/i5UFurmlhzM7JpYn33zFeTTw4nau7MQqsIldIHwtlsbW5FXPV6AjGxcXF+Mjn/Px8GjduDFS8f0FFexbczMnNzQWgpKSES5cu0ahRI5PPqyxfyXbt3oePT3OaNfPGycmJQYPC2ZiUbBKTlJTM0CEDAXi8a0cuXrhIXl6+WblC+lgoi72OYGq0wNzcgwAgISGBXr16GV/XarUUFRWRlZVFZmYmbdu2Ra1WU7duXfbt24fBYCiTs379egB+/PFHunXrVmZ0Ulm+kun1eiZMfItN2pUc3P8f1q7dyOHDRxk1ciijRg4FYNPmFP48cYrfj2zn888/4JVx0yrNBQgP70Pmn7vp1q0TGxK/YVPSCqtdo7VJHwsluZMtk22JxR7XP2nSJHbu3Mm5c+dwcXFh3Lhx9O7dm4kTJ5Kbm4uHhwcLFiwwjjo+++wz1q1bh6OjI9OmTSMgIACAAwcOMHXqVK5du0bPnj15++23UalUXL9+ncmTJ3PkyBEaNmzI/Pnz8fb2BiA8PJzExMRK86sij+sX9kIe1698Deq2MDv24pU/LdiS6iX7wVRACoywF1JglK9unWZmx175K9Ni7ahuipjkF0KI+5m9TvJLgRFCCCuz1xtJUmCEEMLKbO0b+uaSAiOEEFYmIxghhBAWYa9zMLKKTAghhEXIfjBCCCEsQgqMEEIIi5ACI4QQwiKkwAghhLAIKTBCCCEsQgqMEEIIi5ACI4QQwiKkwNiwDh06GP88fPhwOnfuzOjRo63YIvtzs4+PHDlCdHQ0oaGhhIWFsWnTJiu3TAjlk2/y24kRI0Zw9epV4uPjrd0Uu/Tggw/y/vvv06xZM3Q6HZGRkXTv3p0GDRpYu2lCKJYUGDvh7+/Pr7/+au1m2K3mzZsb/+zu7k7jxo0pLCyUAmOG7OxsRo4cSadOndi7dy/u7u58+umnnDhxgnfeeYerV6/y8MMPExsbS8OGDRk6dCht27bl119/5dKlS8yePZvOnTuj1+uZO3cuO3fupKioiCFDhvDss89a+/JEJeQWmRB3aP/+/RQXF/Pwww9buyk24+TJkwwZMgStVkv9+vX58ccfef3113nttdfYuHEjLVu2ZPHixcZ4vV7P2rVrmTZtmvH1tWvXUr9+fdatW8e6detYvXo1WVlZ1rokYQYZwQhxB/Lz85k8eTLvv/8+Dg7y+5m5mjRpQuvWrQF47LHHyMrK4tKlS3Tt2hWA/v37M2HCBGN8UFCQMTYn58aOnNu3b+f333/nxx9/BODSpUucPHnSuFW6UB4pMEKY6fLly4wePZqJEyfSvn17azfHpjg7Oxv/7OjoyMWLF82Kd3BwQK/XAzceaf/WW2/Ro0cPyzVUVCv5FUwIMxQVFfHyyy8THh5O3759rd0cm1e/fn0aNGjA7t27AUhMTKRLly6V5nTv3p1Vq1ZRXFwMwIkTJ/jrr78s3lZx92QEYyeee+45/vzzT/766y969uzJ7Nmz5Te9arR582Z2797N+fPnWb9+PQDvvfee8baPuHPvv/++cZLf29ubOXPmVBofFRVFTk4OAwYMwGAw8NBDD/Hpp5/WUGvF3ZD9YIQQQliE3CITQghhEVJghBBCWIQUGCGEEBYhBUYIIYRFSIERQghhEVJghKgG2dnZ9OvXD7jx5OXU1FQrt0gI65MCI0Q1kwIjxA1SYMR9ITs7mz59+vDGG28QFhbG+PHjuXr1KgcPHuT5559nwIABDB8+nPz8fACGDh3Khx9+yMCBAwkJCTF+4zw7O5vnnnuO/v37079/f3777TeTzykqKmLhwoVs2rSJ8PBwNm3aRHBwMIWFhQCUlpYSFBRkPBfCnkmBEfeNEydOMGjQIDZu3EjdunVZsWIFs2bNYuHChXz//fdERkYyf/58Y3x5T/R1cXHh66+/Zv369cyfP59Zs2aZfIazszPjx4/n6aefJjExkaeffppnnnmGDRs2APDf//6XVq1a0bhx45q7cCGsRB4VI+4bHh4edOrUCYBnnnmGJUuWcPToUYYNGwbcGF24ubkZ48t7om9JSQkxMTFkZGTg4OBAZmZmlZ8bGRnJ2LFjefHFF1m3bh0DBgyo5isTQpmkwIj7hkqlMjmvW7cuvr6+Fe4CWt4Tff/1r3/h6upKYmIipaWltG3btsrP9fDwwMXFhV9++YX09HTmzp17j1cihG2QW2TivnH69Gn27t0LgFarpV27dhQWFhpfKy4u5o8//qj0Z1y6dAk3NzccHBxITEw0Fp5b1a1blytXrpi8FhUVxeTJk+nbty+Ojo7VdEVCKJsUGHHfeOSRR1i/fj1hYWFcuHCBoUOHsnDhQubOncszzzxDRESEsdhU5LnnnmP9+vUMGjSIzMxM6tSpUybm8ccf59ixY8ZJfoDAwED++usvuT0m7ivyNGVxX8jOzuaf//wnSUlJVvn8AwcOMGfOHFauXGmVzxfCGmQORggLi4uLY9WqVXz44YfWbooQNUpGMEIIISxC5mCEEEJYhBQYIYQQFiEFRgghhEVIgRFCCGERUmCEEEJYxP8H/s3gTWenGv8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# takes best parameters from model and stores in results\n",
    "results = pd.DataFrame( best_model.cv_results_['params'] )\n",
    "\n",
    "results['score_acc'] = 1 - best_model.cv_results_['mean_test_accuracy']\n",
    "\n",
    "cols = results.columns.to_series().str.split('__').apply(lambda x: x[-1])\n",
    "results.columns = cols\n",
    "\n",
    "# Heat map\n",
    "sns.heatmap( results.query('solver==\"saga\"').pivot('C','penalty','score_acc'),\n",
    "             annot=True, fmt='.3f')\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "careful-capitol",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets another 5000 random samples\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_p, Y_p, train_size = 5000, random_state = 2)\n",
    "\n",
    "# Grid Search\n",
    "pipe = Pipeline([('classifier', LogisticRegression())])\n",
    "\n",
    "search_space = [{'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['saga'],\n",
    "                 'classifier__penalty': ['l1', 'l2'],\n",
    "                 'classifier__C': np.logspace(-4, 4, 9)},\n",
    "                {'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['lbfgs'],\n",
    "                 'classifier__penalty': ['l2'],\n",
    "                 'classifier__C': np.logspace(-4, 4, 9)},\n",
    "                {'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['lbfgs','saga'],\n",
    "                 'classifier__penalty': ['none']}]\n",
    "                \n",
    "clf = GridSearchCV(pipe, search_space, cv=StratifiedKFold(n_splits=5), \n",
    "                   scoring=['accuracy', 'roc_auc_ovr', 'f1_micro'], refit=False,\n",
    "                   verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "committed-contractor",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "south-newman",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([7.29956627e-03, 1.40727043e-02, 4.58426476e-03, 1.45000935e-02,\n",
       "        6.58988953e-03, 1.26875877e-02, 1.60831451e-02, 1.26404285e-02,\n",
       "        1.92502499e-02, 2.48710155e-02, 1.08905411e-01, 9.44427490e-02,\n",
       "        3.14712954e-01, 3.11866093e-01, 5.21699190e-01, 2.14859629e-01,\n",
       "        5.68522120e-01, 4.25639057e-01, 7.60827408e+00, 4.99142694e+00,\n",
       "        6.29541774e+00, 8.75341964e+00, 1.24310036e+01, 1.42726592e+01,\n",
       "        2.06522368e+01, 3.25507079e+01, 2.93468446e+01, 1.85749039e+01,\n",
       "        5.42206144e-01]),\n",
       " 'std_fit_time': array([3.35227425e-03, 1.19815357e-03, 3.01163245e-04, 1.48633157e-03,\n",
       "        8.82584001e-04, 1.28617187e-04, 2.70622984e-03, 4.68317268e-04,\n",
       "        2.09653701e-03, 2.67543253e-03, 1.89410332e-02, 6.52419097e-03,\n",
       "        3.36281607e-02, 3.29874255e-02, 1.04263931e-01, 3.13402825e-02,\n",
       "        9.42194377e-02, 7.47077723e-02, 2.77823122e-01, 2.30796070e-01,\n",
       "        2.83515744e-01, 4.75912939e-01, 5.97344341e-01, 6.03182035e-01,\n",
       "        1.40233754e+00, 1.20130082e+00, 9.06331107e+00, 1.50722215e+00,\n",
       "        1.16998460e-01]),\n",
       " 'mean_score_time': array([0.00827608, 0.00613918, 0.00588818, 0.00587664, 0.00547376,\n",
       "        0.00568099, 0.00548396, 0.00563011, 0.00545831, 0.00605955,\n",
       "        0.00832157, 0.00590568, 0.0059989 , 0.00590649, 0.0057025 ,\n",
       "        0.00541115, 0.00635052, 0.00557003, 0.02827435, 0.06615553,\n",
       "        0.06383748, 0.02682629, 0.04747901, 0.06612749, 0.06574745,\n",
       "        0.05001092, 0.02798514, 0.04705067, 0.00682898]),\n",
       " 'std_score_time': array([3.03392209e-03, 3.32090979e-05, 4.44291660e-04, 2.90076062e-04,\n",
       "        3.17226778e-04, 1.68275651e-04, 5.67339292e-04, 3.23734106e-04,\n",
       "        3.98829102e-04, 4.59801183e-04, 4.54823540e-03, 3.30594658e-04,\n",
       "        5.36124398e-04, 6.41590423e-04, 2.46963213e-04, 1.96190243e-04,\n",
       "        6.59114826e-04, 2.63309833e-04, 3.78802628e-02, 4.65229335e-02,\n",
       "        4.55686141e-02, 3.70809878e-02, 4.65594681e-02, 4.65659330e-02,\n",
       "        4.70128671e-02, 4.54666652e-02, 3.77501402e-02, 4.68820936e-02,\n",
       "        9.24254638e-04]),\n",
       " 'param_classifier': masked_array(data=[LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000)],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__C': masked_array(data=[0.0001, 0.0001, 0.001, 0.001, 0.01, 0.01, 0.1, 0.1,\n",
       "                    1.0, 1.0, 10.0, 10.0, 100.0, 100.0, 1000.0, 1000.0,\n",
       "                    10000.0, 10000.0, 0.0001, 0.001, 0.01, 0.1, 1.0, 10.0,\n",
       "                    100.0, 1000.0, 10000.0, --, --],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False,  True,  True],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__penalty': masked_array(data=['l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1',\n",
       "                    'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'none', 'none'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__solver': masked_array(data=['saga', 'saga', 'saga', 'saga', 'saga', 'saga', 'saga',\n",
       "                    'saga', 'saga', 'saga', 'saga', 'saga', 'saga', 'saga',\n",
       "                    'saga', 'saga', 'saga', 'saga', 'lbfgs', 'lbfgs',\n",
       "                    'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs',\n",
       "                    'lbfgs', 'lbfgs', 'saga'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__penalty': 'none',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__penalty': 'none',\n",
       "   'classifier__solver': 'saga'}],\n",
       " 'split0_test_accuracy': array([0.965, 0.965, 0.965, 0.965, 0.965, 0.965, 0.998, 0.968, 0.998,\n",
       "        0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998,\n",
       "        0.965, 0.965, 0.965, 0.968, 0.998, 0.998, 0.998, 0.998, 0.998,\n",
       "        0.998, 0.998]),\n",
       " 'split1_test_accuracy': array([0.965, 0.965, 0.965, 0.965, 0.965, 0.965, 0.992, 0.969, 0.999,\n",
       "        0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999,\n",
       "        0.965, 0.965, 0.965, 0.969, 0.999, 0.999, 0.999, 0.999, 0.999,\n",
       "        0.999, 0.999]),\n",
       " 'split2_test_accuracy': array([0.965, 0.965, 0.965, 0.965, 0.965, 0.965, 0.999, 0.967, 0.999,\n",
       "        0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999,\n",
       "        0.965, 0.965, 0.965, 0.967, 0.999, 0.999, 0.999, 0.999, 0.999,\n",
       "        0.999, 0.999]),\n",
       " 'split3_test_accuracy': array([0.965, 0.965, 0.965, 0.965, 0.965, 0.965, 0.991, 0.969, 0.999,\n",
       "        0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999,\n",
       "        0.965, 0.965, 0.965, 0.969, 0.999, 0.999, 0.999, 0.999, 0.999,\n",
       "        0.999, 0.999]),\n",
       " 'split4_test_accuracy': array([0.965, 0.965, 0.965, 0.965, 0.965, 0.965, 0.999, 0.967, 0.999,\n",
       "        0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999,\n",
       "        0.965, 0.965, 0.965, 0.967, 0.999, 0.999, 0.999, 0.999, 0.999,\n",
       "        0.999, 0.999]),\n",
       " 'mean_test_accuracy': array([0.965 , 0.965 , 0.965 , 0.965 , 0.965 , 0.965 , 0.9958, 0.968 ,\n",
       "        0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "        0.9988, 0.9988, 0.965 , 0.965 , 0.965 , 0.968 , 0.9988, 0.9988,\n",
       "        0.9988, 0.9988, 0.9988, 0.9988, 0.9988]),\n",
       " 'std_test_accuracy': array([1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 3.54400903e-03, 8.94427191e-04,\n",
       "        4.00000000e-04, 4.00000000e-04, 4.00000000e-04, 4.00000000e-04,\n",
       "        4.00000000e-04, 4.00000000e-04, 4.00000000e-04, 4.00000000e-04,\n",
       "        4.00000000e-04, 4.00000000e-04, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 8.94427191e-04, 4.00000000e-04, 4.00000000e-04,\n",
       "        4.00000000e-04, 4.00000000e-04, 4.00000000e-04, 4.00000000e-04,\n",
       "        4.00000000e-04]),\n",
       " 'rank_test_accuracy': array([21, 21, 21, 21, 21, 21, 18, 19,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1, 21, 21, 21, 19,  1,  1,  1,  1,  1,  1,  1], dtype=int32),\n",
       " 'split0_test_roc_auc_ovr': array([0.5       , 0.96663212, 0.5       , 0.96663212, 0.5       ,\n",
       "        0.98333087, 0.97142857, 0.98333087, 0.95955588, 0.98333087,\n",
       "        0.95955588, 0.95958549, 0.95955588, 0.95958549, 0.95958549,\n",
       "        0.95958549, 0.95958549, 0.95958549, 0.96663212, 0.96663212,\n",
       "        0.98333087, 0.98333087, 0.98333087, 0.95958549, 0.95958549,\n",
       "        0.95958549, 0.95958549, 0.95958549, 0.95958549]),\n",
       " 'split1_test_roc_auc_ovr': array([0.5       , 0.92800888, 0.5       , 0.92800888, 0.5       ,\n",
       "        0.97958549, 0.98571429, 0.97958549, 0.98571429, 0.97958549,\n",
       "        0.99184308, 0.99184308, 0.99184308, 0.99184308, 0.99184308,\n",
       "        0.99184308, 0.99184308, 0.99184308, 0.92800888, 0.92800888,\n",
       "        0.97958549, 0.97958549, 0.97958549, 0.99184308, 0.99184308,\n",
       "        0.99184308, 0.99184308, 0.99184308, 0.99184308]),\n",
       " 'split2_test_roc_auc_ovr': array([0.5       , 0.97819393, 0.5       , 0.97819393, 0.5       ,\n",
       "        0.97819393, 0.98571429, 0.97819393, 0.98571429, 0.97819393,\n",
       "        0.99323464, 0.99323464, 0.99323464, 0.99323464, 0.99323464,\n",
       "        0.99323464, 0.99323464, 0.99323464, 0.97819393, 0.97819393,\n",
       "        0.97819393, 0.97819393, 0.97819393, 0.99323464, 0.99323464,\n",
       "        0.99323464, 0.99323464, 0.99323464, 0.99323464]),\n",
       " 'split3_test_roc_auc_ovr': array([0.5       , 0.95549963, 0.5       , 0.95549963, 0.5       ,\n",
       "        0.97284974, 0.98571429, 0.97284974, 0.9815248 , 0.97284974,\n",
       "        0.97284974, 0.97284974, 0.97284974, 0.97284974, 0.97284974,\n",
       "        0.97284974, 0.97284974, 0.97284974, 0.95549963, 0.95549963,\n",
       "        0.97284974, 0.97284974, 0.97284974, 0.97284974, 0.97284974,\n",
       "        0.97284974, 0.97284974, 0.97284974, 0.97284974]),\n",
       " 'split4_test_roc_auc_ovr': array([0.5       , 0.94118431, 0.5       , 0.94411547, 0.5       ,\n",
       "        0.97857883, 0.98571429, 0.97857883, 0.98571429, 0.97857883,\n",
       "        0.99284974, 0.99284974, 0.99284974, 0.99287935, 0.99287935,\n",
       "        0.99287935, 0.99287935, 0.99287935, 0.94118431, 0.94411547,\n",
       "        0.97857883, 0.97857883, 0.97857883, 0.99284974, 0.99287935,\n",
       "        0.99287935, 0.99287935, 0.99287935, 0.99287935]),\n",
       " 'mean_test_roc_auc_ovr': array([0.5       , 0.95390377, 0.5       , 0.95449001, 0.5       ,\n",
       "        0.97850777, 0.98285714, 0.97850777, 0.97964471, 0.97850777,\n",
       "        0.98206662, 0.98207254, 0.98206662, 0.98207846, 0.98207846,\n",
       "        0.98207846, 0.98207846, 0.98207846, 0.95390377, 0.95449001,\n",
       "        0.97850777, 0.97850777, 0.97850777, 0.98207254, 0.98207846,\n",
       "        0.98207846, 0.98207846, 0.98207846, 0.98207846]),\n",
       " 'std_test_roc_auc_ovr': array([0.        , 0.01781516, 0.        , 0.01743105, 0.        ,\n",
       "        0.00336275, 0.00571429, 0.00336275, 0.01017462, 0.00336275,\n",
       "        0.01362544, 0.01361566, 0.01362544, 0.01362035, 0.01362035,\n",
       "        0.01362035, 0.01362035, 0.01362035, 0.01781516, 0.01743105,\n",
       "        0.00336275, 0.00336275, 0.00336275, 0.01361566, 0.01362035,\n",
       "        0.01362035, 0.01362035, 0.01362035, 0.01362035]),\n",
       " 'rank_test_roc_auc_ovr': array([27, 25, 27, 23, 27, 17,  1, 17, 16, 17, 14, 12, 14,  2,  2,  2,  2,\n",
       "         2, 25, 23, 17, 17, 17, 12,  2,  2,  2,  2,  2], dtype=int32),\n",
       " 'split0_test_f1_micro': array([0.965, 0.965, 0.965, 0.965, 0.965, 0.965, 0.998, 0.968, 0.998,\n",
       "        0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998,\n",
       "        0.965, 0.965, 0.965, 0.968, 0.998, 0.998, 0.998, 0.998, 0.998,\n",
       "        0.998, 0.998]),\n",
       " 'split1_test_f1_micro': array([0.965, 0.965, 0.965, 0.965, 0.965, 0.965, 0.992, 0.969, 0.999,\n",
       "        0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999,\n",
       "        0.965, 0.965, 0.965, 0.969, 0.999, 0.999, 0.999, 0.999, 0.999,\n",
       "        0.999, 0.999]),\n",
       " 'split2_test_f1_micro': array([0.965, 0.965, 0.965, 0.965, 0.965, 0.965, 0.999, 0.967, 0.999,\n",
       "        0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999,\n",
       "        0.965, 0.965, 0.965, 0.967, 0.999, 0.999, 0.999, 0.999, 0.999,\n",
       "        0.999, 0.999]),\n",
       " 'split3_test_f1_micro': array([0.965, 0.965, 0.965, 0.965, 0.965, 0.965, 0.991, 0.969, 0.999,\n",
       "        0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999,\n",
       "        0.965, 0.965, 0.965, 0.969, 0.999, 0.999, 0.999, 0.999, 0.999,\n",
       "        0.999, 0.999]),\n",
       " 'split4_test_f1_micro': array([0.965, 0.965, 0.965, 0.965, 0.965, 0.965, 0.999, 0.967, 0.999,\n",
       "        0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999,\n",
       "        0.965, 0.965, 0.965, 0.967, 0.999, 0.999, 0.999, 0.999, 0.999,\n",
       "        0.999, 0.999]),\n",
       " 'mean_test_f1_micro': array([0.965 , 0.965 , 0.965 , 0.965 , 0.965 , 0.965 , 0.9958, 0.968 ,\n",
       "        0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "        0.9988, 0.9988, 0.965 , 0.965 , 0.965 , 0.968 , 0.9988, 0.9988,\n",
       "        0.9988, 0.9988, 0.9988, 0.9988, 0.9988]),\n",
       " 'std_test_f1_micro': array([1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 3.54400903e-03, 8.94427191e-04,\n",
       "        4.00000000e-04, 4.00000000e-04, 4.00000000e-04, 4.00000000e-04,\n",
       "        4.00000000e-04, 4.00000000e-04, 4.00000000e-04, 4.00000000e-04,\n",
       "        4.00000000e-04, 4.00000000e-04, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 8.94427191e-04, 4.00000000e-04, 4.00000000e-04,\n",
       "        4.00000000e-04, 4.00000000e-04, 4.00000000e-04, 4.00000000e-04,\n",
       "        4.00000000e-04]),\n",
       " 'rank_test_f1_micro': array([21, 21, 21, 21, 21, 21, 18, 19,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1, 21, 21, 21, 19,  1,  1,  1,  1,  1,  1,  1], dtype=int32)}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "judicial-evening",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21, 21, 21, 21, 21, 21, 18, 19,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1, 21, 21, 21, 19,  1,  1,  1,  1,  1,  1,  1], dtype=int32)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.cv_results_['rank_test_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "cross-newton",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 1.0,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for accuracy\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_accuracy']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "alien-webmaster",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 0.1,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for roc auc\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_roc_auc_ovr']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "unable-forwarding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 1.0,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for f1\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_f1_micro']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "specific-genome",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best accuracy model\n",
    "acc_model = LogisticRegression(penalty = 'l1', C = 1.0, solver = 'saga', max_iter = 5000)\n",
    "\n",
    "# best roc auc model\n",
    "roc_model = LogisticRegression(penalty = 'l1', C = 0.1, solver = 'saga', max_iter = 5000)\n",
    "\n",
    "# best f1 model\n",
    "f1_model = LogisticRegression(penalty = 'l1', C = 1.0, solver = 'saga', max_iter = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "legitimate-costs",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=5000, penalty='l1', solver='saga')"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# models the data\n",
    "acc_model.fit(X_train, Y_train)\n",
    "roc_model.fit(X_train, Y_train)\n",
    "f1_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "induced-roller",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>C</th>\n",
       "      <th>penalty</th>\n",
       "      <th>solver</th>\n",
       "      <th>score_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           classifier           C penalty solver  score_acc\n",
       "0   LogisticRegression(max_iter=5000)      0.0001      l1   saga     0.0350\n",
       "1   LogisticRegression(max_iter=5000)      0.0001      l2   saga     0.0350\n",
       "2   LogisticRegression(max_iter=5000)      0.0010      l1   saga     0.0350\n",
       "3   LogisticRegression(max_iter=5000)      0.0010      l2   saga     0.0350\n",
       "4   LogisticRegression(max_iter=5000)      0.0100      l1   saga     0.0350\n",
       "5   LogisticRegression(max_iter=5000)      0.0100      l2   saga     0.0350\n",
       "6   LogisticRegression(max_iter=5000)      0.1000      l1   saga     0.0042\n",
       "7   LogisticRegression(max_iter=5000)      0.1000      l2   saga     0.0320\n",
       "8   LogisticRegression(max_iter=5000)      1.0000      l1   saga     0.0012\n",
       "9   LogisticRegression(max_iter=5000)      1.0000      l2   saga     0.0012\n",
       "10  LogisticRegression(max_iter=5000)     10.0000      l1   saga     0.0012\n",
       "11  LogisticRegression(max_iter=5000)     10.0000      l2   saga     0.0012\n",
       "12  LogisticRegression(max_iter=5000)    100.0000      l1   saga     0.0012\n",
       "13  LogisticRegression(max_iter=5000)    100.0000      l2   saga     0.0012\n",
       "14  LogisticRegression(max_iter=5000)   1000.0000      l1   saga     0.0012\n",
       "15  LogisticRegression(max_iter=5000)   1000.0000      l2   saga     0.0012\n",
       "16  LogisticRegression(max_iter=5000)  10000.0000      l1   saga     0.0012\n",
       "17  LogisticRegression(max_iter=5000)  10000.0000      l2   saga     0.0012\n",
       "18  LogisticRegression(max_iter=5000)      0.0001      l2  lbfgs     0.0350\n",
       "19  LogisticRegression(max_iter=5000)      0.0010      l2  lbfgs     0.0350\n",
       "20  LogisticRegression(max_iter=5000)      0.0100      l2  lbfgs     0.0350\n",
       "21  LogisticRegression(max_iter=5000)      0.1000      l2  lbfgs     0.0320\n",
       "22  LogisticRegression(max_iter=5000)      1.0000      l2  lbfgs     0.0012\n",
       "23  LogisticRegression(max_iter=5000)     10.0000      l2  lbfgs     0.0012\n",
       "24  LogisticRegression(max_iter=5000)    100.0000      l2  lbfgs     0.0012\n",
       "25  LogisticRegression(max_iter=5000)   1000.0000      l2  lbfgs     0.0012\n",
       "26  LogisticRegression(max_iter=5000)  10000.0000      l2  lbfgs     0.0012\n",
       "27  LogisticRegression(max_iter=5000)         NaN    none  lbfgs     0.0012\n",
       "28  LogisticRegression(max_iter=5000)         NaN    none   saga     0.0012"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEKCAYAAAAvlUMdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAA8IUlEQVR4nO3df1xUVd7A8c+Akr9QAxwGkCgDn1zFX2VKa1IYoiGCIrLa8hRPamvlj9y1VSvXUNHWrLQfW2RbbpkP/khQRoukXcDKzArwF5kmCQgzKipqKTDc5w8fx0aBGZNh7ozf977u69Wd+Z6Zc86q3zn33nOORlEUBSGEEKKZuTm6AkIIIVyTJBghhBB2IQlGCCGEXUiCEUIIYReSYIQQQtiFJBghhBB2IQlGCCFcTF5eHlFRUURGRpKWlnbV+4qisHDhQiIjI4mJiWHv3r0AXLhwgbFjxzJq1Ciio6NZsWKFucyrr77KvffeS2xsLLGxseTm5lqtR6vma5IQQghHM5lMpKSk8O677+Lr68vYsWOJiIggODjYHJOXl0dJSQnZ2dkUFhYyf/581q1bh4eHB6tWraJ9+/bU1tYyYcIEhgwZQt++fQF45JFHePTRR22ui4xghBDChRQVFREUFERgYCAeHh5ER0eTk5NjEZOTk0NcXBwajYa+fftSXV2N0WhEo9HQvn17AOrq6qirq0Oj0fzmusgIRggX1sojwNFVuCHU1ZRfV/na4z/aHPtRztekp6ebzxMTE0lMTDSfGwwGdDqd+dzX15eioiKLz7gyRqfTYTAY0Gq1mEwmxowZw5EjR5gwYQJ9+vQxx61evZqMjAx69erF7Nmz6dSpU5N1lQQjhBBO5MqEcqWGVv+6chTSVIy7uzuZmZlUV1fzxBNPcODAAbp378748eN5/PHH0Wg0LF++nCVLlrB48eIm6yqXyIQQwtHqTbYfVuh0OiorK83nl0YmTcVUVlZeFdOxY0cGDhxIfn4+AD4+Pri7u+Pm5kZCQgK7d++2WhdJMEII4WimOtsPK0JDQykpKaG0tJSamhr0ej0REREWMREREWRkZKAoCgUFBXh6eqLVaqmqqqK6uhqA8+fP88UXX9CtWzcAjEajufy2bdsICQmxWhe5RCaEEA6mKPXN9lmtWrVi3rx5TJw4EZPJRHx8PCEhIaxZswaA8ePHEx4eTm5uLpGRkbRt25bU1FTgYhKZPXs2JpMJRVEYPnw4999/PwBLly6luLgYgICAAFJSUqzWRSPL9QvhuuQmf8u43pv8NWXWLzdd4tE19Lq+qyXJCEYIIRytGUcwaiL3YIQQdhM17D727smjeN92np71RIMxL7+UQvG+7Xz7zaf069vLatn4+JEUFnxGzflS7uzf2+5taBHNeJNfTSTBCCHsws3NjRXLFzEy5o+E9rmfxMQ4evSwvDE8YngEIcG3ccfvBjNlyl95/bXFVsvu3VtMwrhJ5OfvaPE22Y1Sb/vhROQSmRDCLu4e0I9Dh0o4fPgIAGvXZjIqJor9+38wx8TERPH+6vUAfLXzWzp17oROp+XWoMBGyxYXH2z5xtiZYsPTYc7IKRNMWVkZkyZN4s477+S7777D19eXN954g02bNpGenk5tbS1BQUH8/e9/p23btsyePZsOHTqwZ88ejh07xqxZsxg+fLijmyGES/MP0FFadtR8XlZewd0D+lnEBPjrKCu9HFNeVkGAv86msi6l3rlGJrZy2ktkP/30Ew899BB6vR5PT08++eQTIiMj2bBhA5s2baJbt26sX7/eHG80Gvnwww956623WLZsmQNrLsSNoaE1rK58aLWxGFvKuhS5RKYuXbt2pUePHgD07NmT8vJyfvjhB1555RXOnDnDuXPnGDx4sDn+gQcewM3NjeDgYI4fP+6oagtxwygvqyCwq7/5vGuAHxUVBouYsvIKugZejgno6sfRCgMeHh5Wy7oUJ7t5byunHcF4eHiY/9vd3R2TycTs2bOZN28emzdv5sknn6SmpqbBeCGE/X29q4Dg4Nu49dZAWrduzbhxsWzOyraIycrKJumhsQAMvLs/1aerqaw02lTWpcgIRv3OnTtHly5dqK2tZfPmzfj6+jq6SkLcsEwmE9NnPMsW/Ye4u7nx3qp09u07wORJSQCkvf0+W7bmMHx4BN/v/5yff/mFiRNnNlkWIDZ2OMtfXkiXLl5syvwXhYV7eXDkQw5rZ7OQm/zqN336dBISEggICKB79+6cO3fO0VUS4oa29ePP2PrxZxavpb39vsX5tOnP2FwWIDPzYzIzP26+SqqBi97kl6VihHBhslRMy7jepWLOF26xObZNnwev67takkuNYIQQwik52b0VW0mCEUIIR3PRS2SSYIQQwtFkBCOEEMIuTLWOroFdSIIRQghHk0tkN5ba4z86ugpCXLdfjubT1v9eR1dDWCOXyIQQzuh6H6EVLUBGMEIIIexCEowQQgh7UOQmvxBCCLuQezBCCCHsQi6RCSGEsAsZwYiWtH3HLpa88iam+nriY4YzMWmcxfuKorD4lTfJ//Jr2rS5iUXP/Jnf/VcwFy7U8PATs6iprcVUZyLy/sE8OfHi8uivv/MBGzZ9zM2dOwEw/bGHGXLP3S3eNrWQPhaq0cwjmLy8PBYtWkR9fT0JCQlMnjzZ4n1FUVi0aBG5ubm0adOGJUuW0LNnTy5cuMBDDz1ETU0NJpOJqKgopk2bBsCpU6d46qmnKC8vJyAggFdeeYVOnTo1WQ+HbDiWl5dHVFQUkZGRpKWlXfW+oigsXLiQyMhIYmJi2Lt3r9Wyp06dIjk5mWHDhpGcnMzp06cBOHnyJElJSfTr14+UlBT7N64ZmEwmFi57nX8sW8Cm1W+xZdt/OHT4J4uY/C+/5kjZUbakv8P8p6ex4MXXAPDwaM0/Vyzho1VvsH7V63z+1TcU7tlvLpeUGMeGVa+zYdXrN/Q/fNLHQlWaccMxk8lESkoKK1euRK/Xk5WVxcGDBy1i8vLyKCkpITs7mwULFjB//nzg4saMq1atYtOmTWRkZJCfn09BQQEAaWlphIWFkZ2dTVhYWIP/dl+pxRPM9TS+qbKNNf6mm25i+vTpPP300y3azuuxe/8BbunqT2CAH61bt2bE0HA+y99hEfPv7TsYNXwoGo2GPr16cObMWY4dr0Kj0dCuXVsA6urqqKura3B/8xud9LFQlbo62w8rioqKCAoKIjAwEA8PD6Kjo8nJybGIycnJIS4uDo1GQ9++famursZoNKLRaGjfvv3/V8nyz/alMgBxcXFs27bNal1aPMFcT+ObKttY49u1a8ddd93FTTfd1KLtvB7GY8fRabuYz321PhiPnbCIMRw7gU7rYxFjOHYcuJiI4x9+giEjxxM2oB+9e95hjluzYTOj/3sKz6a+xOnqM3ZuiXpJHwtVacYRjMFgQKfTmc99fX0xGAxNxuh0OnOMyWQiNjaWe+65h3vuuYc+ffoAcOLECbRaLQBarZaqqiqrdWnxBHM9jW+q7G9pvFo1tAXclT+QG9on7tIvDXd3dzasep2cje+ze98BfvixBIDE0dFsXftPNrz3Ol28vVj62tvNXXWnIX0sVKW+3uYjPT2dMWPGmI/09HSLj2rqz60tMe7u7mRmZpKbm0tRUREHDhz4zc1q8QRzPY23pawr8NX6UGk8Zj43GI/TxcfbIkan9aHSeNwiRntFTEfPDgzo35vtO3YB4ON1M+7u7ri5uTF21Aj27Pvtf3CcnfSxUJVrGMEkJiby0UcfmY/ExESLj9LpdFRWVprPDQaD+cd3YzGVlZVXxXTs2JGBAweSn58PgLe3N0ajEQCj0YiXl5fVZrV4grmexjdV9rc0Xq163dGdI2VHKTtaSW1tLVtzcrl/8CCLmPsGD2LTxzkoikLhnv106NCeLj5eVJ08RfWZswCcv3CBHV9/x21BgQAcO355VJeT+wXB3YJarlEqI30sVOUaRjDWhIaGUlJSQmlpKTU1Nej1eiIiIixiIiIiyMjIQFEUCgoK8PT0NF/5qa6uBuD8+fN88cUXdOvWzaIMQEZGBkOHDrValxZ/TPnXjff19UWv17Ns2TKLmIiICD744AOio6MpLCw0N97Ly6vRspcaP3nyZJsbr1atWrkz96kpPDbzWUwmE6NHDiO4WxDpG/XAxcswQ8IGkP/l14wY9z+0bdOGBXOfAuDYiZM8s/BFTPX1KPUKURH3ct/vBwKw7I13+P6HH0EDATpf/vb0NIe10dGkj4WqNOM8mFatWjFv3jwmTpx48V5hfDwhISGsWbMGgPHjxxMeHk5ubi6RkZG0bduW1NRU4OKP89mzZ2MymVAUheHDh3P//fcDMHnyZGbMmMH69evx8/Nj+fLlVuuiURq67mRnubm5pKammhs/ZcoUi8YrikJKSgr5+fnmxoeGhjZaFi4+jjxjxgwqKirMje/cuTNwMfmcPXuW2tpaPD09+ec//0lwcHCTdZTl+oWraO3TzdFVEFb8stb2KRRtx82zY02al0MSjDOQBCNchSQY9fsl/XmbY9sm/s2ONWleMpNfCCEcTdYiE0IIYReSYIQQQtiFLHYphBDCLkwmR9fALiTBCCGEo8klMiGEEHYhCUYIIYRdyD0YIYQQ9qDUu+Z0REkwQgjhaHKJTAghhF3IU2RCCCHsQkYwQggh7EISjGhJ23fsYskrb2Kqryc+ZjgTk8ZZvK8oCotfeZP8L7+mTZubWPTMn/ndfwVz4UINDz8xi5raWkx1JiLvH8yTE5MAeP2dD9iw6WNu7twJgOmPPcyQe+5u8baphfSxUA0XXXNYdQkmLy+PRYsWUV9fT0JCApMnT7Z4X1EUFi1aRG5uLm3atGHJkiX07NmzybJbt27ltdde49ChQ6xbt8689L9amUwmFi57nbdfSUWn9SFx4nTuHzyQ22+7vHlV/pdfc6TsKFvS36FobzELXnyNNW+/godHa/65Ygnt2rWltq6O/57yF+4ddBd9evUAICkxjuQJYx3VNNWQPhaq4qIjmBbf0bIpJpOJlJQUVq5ciV6vJysri4MHD1rE5OXlUVJSQnZ2NgsWLGD+/PlWy3bv3p1XX32VAQMGtHSTfpPd+w9wS1d/AgP8aN26NSOGhvNZ/g6LmH9v38Go4UPRaDT06dWDM2fOcux4FRqNhnbt2gJQV1dHXV2dS24rfb2kj4Wq1Cu2H05EVQmmqKiIoKAgAgMD8fDwIDo6mpycHIuYnJwc4uLi0Gg09O3bl+rqaoxGY5Nlb7/9dvO2n87AeOw4Om0X87mv1gfjsRMWMYZjJ9BpfSxiDMcu7h9vMpmIf/gJhowcT9iAfvTueYc5bs2GzYz+7yk8m/oSp6vP2Lkl6iV9LFTFZLL9cCKqSjAGgwGdTmc+9/X1xWAwNBmj0+kwGAw2lXUWDV2OvfIHckP7xF36Fe3u7s6GVa+Ts/F9du87wA8/lgAXtwHeuvafbHjvdbp4e7H0tbebu+pOQ/pYqIlSX2/z4UxUlWCa+gttLcaWss7CV+tDpfGY+dxgPE4XH2+LGJ3Wh0rjcYsY7RUxHT07MKB/b7bv2AWAj9fNuLu74+bmxthRI9iz74AdW6Fu0sdCVeQSmf3pdDoqKyvN5waDAa1W22RMZWUlWq3WprLOotcd3TlSdpSyo5XU1tayNSeX+wcPsoi5b/AgNn2cg6IoFO7ZT4cO7eni40XVyVNUnzkLwPkLF9jx9XfcFhQIwLHjVebyOblfENwtiBuV9LFQFaXe9sOJqOopstDQUEpKSigtLcXX1xe9Xs+yZcssYiIiIvjggw+Ijo6msLAQT09PtFotXl5eVss6i1at3Jn71BQem/ksJpOJ0SOHEdwtiPSNeuDiZZghYQPI//JrRoz7H9q2acOCuU8BcOzESZ5Z+CKm+nqUeoWoiHu57/cDAVj2xjt8/8OPoIEAnS9/e3qaw9roaNLHQlWcbGRiK43S0LUlB8rNzSU1NfXiTdT4eKZMmcKaNWsAGD9+PIqikJKSQn5+Pm3btiU1NdX82HFDZQE+/fRTFixYQFVVFR07dqRHjx688847Tdaj9viP9m2oEC2ktY/zPOByozo37w82x7ZP+V871qR5qS7BqIUkGOEqJMGo37nnxlkP+n/tF6y1Y02al6oukQkhxA3JRS+RqeomvxBC3Iia+zHlvLw8oqKiiIyMJC0t7ervUxQWLlxIZGQkMTEx7N27F4CKigqSkpIYMWIE0dHRrFq1ylzm1Vdf5d577yU2NpbY2Fhyc3Ot1kNGMEII4WjNOIK5tKrJu+++i6+vL2PHjiUiIoLg4GBzzK9XRCksLGT+/PmsW7cOd3d3Zs+eTc+ePTl79izx8fH8/ve/N5d95JFHePTRR22ui4xghBDC0ZpxHsz1rIii1WrNazt26NCBbt26XdeEdRnBCCGEo13DEjDp6emkp6ebzxMTE0lMTDSfN7SqSVFRkcVnNLYiyq/nDpaVlbF//3769Oljfm316tVkZGTQq1cvZs+eTadOnZqsqyQYIYRwMOUaLpFdmVCu+qzrWBHlknPnzjFt2jTmzp1Lhw4dgIvTRB5//HE0Gg3Lly9nyZIlLF68uMm6yiUyIYRwtGa8RHY9K6IA1NbWMm3aNGJiYhg2bJg5xsfHx7wMUkJCArt377ZaF0kwQgjhaPX1th9W/HpFlJqaGvR6PRERERYxERERZGRkoCgKBQUF5hVRFEXhmWeeoVu3biQnJ1uUMRqN5v/etm0bISEhVusil8iEEMLRmvEpslatWjFv3jwmTpxoXtUkJCTEYkWU8PBwcnNziYyMNK+IAvDNN9+QmZlJ9+7diY2NBWDmzJmEh4ezdOlSiouLAQgICCAlJcVqXWQmfyNkJr9wFTKTX/3O/Gm4zbGeb35sx5o0LxnBCCGEgykm51ol2VaSYFRq+45dLHnlTUz19cTHDGdikuVaRYqisPiVN8n/8mvatLmJRc/8md/9VzAXLtTw8BOzqKmtxVRnIvL+wTw5MQmA19/5gA2bPubmzhcfLZz+2MMMuefuFm+bWkgfC9Vw0aVinCbB5OXlsWjRIurr60lISGDy5MkW7yuKwqJFi8jNzaVNmzYsWbLEPGFozpw5/Oc//8Hb25usrCxHVP+amEwmFi57nbdfSUWn9SFx4nTuHzyQ22+7vLdI/pdfc6TsKFvS36FobzELXnyNNW+/godHa/65Ygnt2rWltq6O/57yF+4ddBd9evUAICkxjuQJYx3VNNWQPhZqci2PKTsTp3iK7NLSBytXrkSv15OVlcXBgwctYn699MGCBQuYP3+++b0xY8awcuXKFq71b7d7/wFu6epPYIAfrVu3ZsTQcD7L32ER8+/tOxg1fCgajYY+vXpw5sxZjh2vQqPR0K5dWwDq6uqoq6tz2p097Un6WKiK7GjpONez9AHAgAEDrM44VRPjsePotF3M575aH4zHTljEGI6dQKf1sYgxHLu4va/JZCL+4ScYMnI8YQP60bvnHea4NRs2M/q/p/Bs6kucrj5j55aol/SxUJX6aziciFMkmIaWPrhyfZzGlj5wRg0913flD+SmZuK6u7uzYdXr5Gx8n937DvDDjyXAxV0at679Jxvee50u3l4sfe3t5q6605A+Fmqi1NXbfDgTp0gwzbH0gTPx1fpQaTxmPjcYj9PFx9siRqf1odJ43CJGe0VMR88ODOjfm+07dgHg43WzeSbu2FEj2LPvgB1boW7Sx0JVZATjONe79IGz6XVHd46UHaXsaCW1tbVszcnl/sGDLGLuGzyITR/noCgKhXv206FDe7r4eFF18hTVZ84CcP7CBXZ8/R23BQUCcOx4lbl8Tu4XBHcL4kYlfSzURKlXbD6ciVM8RfbrpQ98fX3R6/UsW7bMIiYiIoIPPviA6OhoCgsLzUsfOKNWrdyZ+9QUHpv5LCaTidEjhxHcLYj0jXrg4mWYIWEDyP/ya0aM+x/atmnDgrlPAXDsxEmeWfgipvp6lHqFqIh7ue/3AwFY9sY7fP/Dj6CBAJ0vf3t6msPa6GjSx0JVnGxkYiunmcmfm5tLamqqeemDKVOmWCx9oCgKKSkp5Ofnm5c+CA0NBS4udbBz505OnjyJt7c3U6dOJSEhocnvk5n8wlXITH71qxodbnOs10brO0mqhdMkmJYmCUa4Ckkw6lcVew0JJtN5EoxTXCITQghXptQ5ugb2IQlGCCEcTHHRezCSYIQQwtEkwQghhLAHGcEIIYSwC0kwN5j/uiPe0VVwafu2PuvoKtww5Cky9VNMzrnqiDWSYIQQwsFkBCOEEMIulHoZwQghhLADGcEIIYSwC0WREYwQQgg7kBGMEEIIu6h30afInGI/mBvRkIh72LZjI5/tzORP05IbjJmX+jSf7cxkS246PXvfYXPZiU8k8ePx77jZq7O9qu8UPi88wKi/vMTImS/yzqarFxBUFIUl/9rMyJkvMnbOCvYfLgfgQk0tE+a9QcLcFYz+6yu8sWGbucxLH24ldtZLjJ2zghkvf0D1uV9arD3CeSn1GpsPW+Tl5REVFUVkZCRpaWlXf5+isHDhQiIjI4mJiWHv3r0AVFRUkJSUxIgRI4iOjmbVqlXmMqdOnSI5OZlhw4aRnJzM6dOnrdbD6ROMtY48dOgQiYmJ9OrVi3feeccBNbx2bm5uPP/CbJITnyTq9/HEjBlOcHfLuQz3PTCYW7vdQsTdscyduZAFS+faVNbP35fB4YMoL61o0Tapjam+ntRVm3jj6UfY+PcZfLyjkEPllltsby88wJHKE2xe9mfmPRrHwvcyAfBo3YqVcx9lXeo01i6ayudFByg6eASAQaHBbFgynfWLpxHk58M7m51n5VvhOM2ZYEwmEykpKaxcuRK9Xk9WVhYHDx60iMnLy6OkpITs7GwWLFjA/PnzgYtbgc+ePZutW7eSnp7Ohx9+aC6blpZGWFgY2dnZhIWFNfjv7ZWcOsHY0pGdO3fmmWee4dFHH3VQLa9dn/69+OlwKaU/lVNbW0fWxk+IHHGfRcwDI8LZuDYLgIJvdtOxkyddfH2sln124V9Y8vzyBreYvpHsOVRGoK83XbVetG7ViuGDevOfb/ZbxPz7m33EDO6HRqOhd/AtnDl3nmMnq9FoNLRrcxMAdSYTdXX1wMW/+PeEhtDK3R2A3rcHYqyy/itPCEWx/bCmqKiIoKAgAgMD8fDwIDo6mpycHIuYnJwc4uLi0Gg09O3bl+rqaoxGI1qtlp49ewLQoUMHunXrhsFgsCgDEBcXx7Zt27DGqROMLR3p7e1N7969adXKeW436fy0VBy9/Gu64qgBX78uV8eU/2qL6KMGdH7aJssOHR5OZYWR4r2yT7zx5Gl0Xp3M51qvThhOVl8RU42v9+UYX6+OGP8/xlRfz7i5r3L/46kMCg2md3DgVd+RkfcNv+/d3U4tEK7kWkYw6enpjBkzxnykp6dbfJbBYECn05nPfX19zUmisRidTndVTFlZGfv376dPnz4AnDhxwrxLsFarpaqqCmuc51/dBjTUkUVFRQ6sUTNpYBR85S8XjebqIEVRGi3bpm0bnnjqUR4e+3gzVdK5NfRL8Kquayjm//vd3c2NtalTqT73C0+98gE/lFYSEnj5z+Lbmf/G3c2N6N/3bbY6C9d1LY8pJyYmkpiY2MRnXf0H98p/L6zFnDt3jmnTpjF37lw6dOhgc92u5NQjGFs60hlVHjXi5+9rPvfz98VYecwipuKoAb+AX/0C8ffFUHms0bJBt3al6y0B6HPTyftWj85fy+bPPsRH623/BqmQr1cnKn91+cpYdRrtzR0tYrReHTGcuBxjqKqmS2dPi5iO7dsyoEc3vij6wfzaprxvyfuumMWPj3OJP4/C/kwmjc2HNTqdjsrKy1c3DAaDeeTRWExlZaU5pra2lmnTphETE8OwYcPMMd7e3hiNRgCMRiNeXl5W6+LUCcaWjnRGRd/t5dZut9D1Fn9at27FyNFRbPv4PxYxOR/nMnrcSAD63hnKmeqzHDMcb7Ts9/sPcnePoQzpH82Q/tFUHjUSEzGB48YTDmih4/XsFsCRyuOUGauoravj4x1FhPfvYRFzX/8ebN7+HYqiUHTwCB3ataHLzR2pqj5rfjrsfE0tO/Yc5Fb/i5chPy88wLtZuSyfmUTbmzxavF3COSmKxubDmtDQUEpKSigtLaWmpga9Xk9ERIRFTEREBBkZGSiKQkFBAZ6enmi1WhRF4ZlnnqFbt24kJyc3WAYgIyODoUOHWq2LU18i+3VH+vr6otfrWbZsmaOrdd1MJhPzZ7/AqnVv4ObmxroPM/nh+x+Z8MhYAD58bz3//nQ79z0wmH9/vYnzv5zn6WnzmywrLLVyd2fOw6OY8vd3qa9XiAu/k+CuvqzN+QqAcUMHcm/f/2J74feM/PMy2ni0JmXyxRW2j586w7Nvrae+XqFeqWfYwFDC+118THzxqk3U1Jn405J3AQgNDuS5/4lzSBuF82jOtchatWrFvHnzmDhxIiaTifj4eEJCQlizZg0A48ePJzw8nNzcXCIjI2nbti2pqakAfPPNN2RmZtK9e3diY2MBmDlzJuHh4UyePJkZM2awfv16/Pz8WL58udW6aBQnf5woNzeX1NRUc0dOmTLFoiOPHTtGfHw8Z8+exc3NjXbt2rFlyxar1xW7+fRrierfsGS5/pbTZoBsPaF2+0MetDm2xw9b7FiT5uX0CcZeJMHYlySYliMJRv323R5tc+zvDuntWJPm5dSXyIQQwhWY6p36dnijJMEIIYSDuep1JEkwQgjhYPUuulx/k+Oyn376iW+++eaq13ft2sWRI0fsVikhhLiRNOdjymrSZIJJTU2lffv2V71+0003mR9rE0IIcX2acy0yNWnyEll5eTl33HHHVa+HhoZSXl5ut0qpwZFqo6Or4NI6/H6ao6tww6irkafI1M5VL5E1mWAuXLjQ6Hvnz59v9soIIcSNyFWfImuyVaGhoaxdu/aq19etW2de0lkIIcT1Ua7hcCZNTrQ8fvw4Tz75JK1btzYnlD179lBbW8trr71Gly5dGivq9Fp5BDi6CkI0i7oa176c7Qq+8LP9MuY9FRvsWJPm1eQlMh8fH/73f/+XHTt28MMPF1eLDQ8PJywsrEUqJ4QQNwJnezrMVjbNgxk0aBCDBg2yd12EEOKGVO/oCtiJTLQUQggHUxraKdAFuOajCy4gath97N2TR/G+7Tw964kGY15+KYXifdv59ptP6de3l9Wy8fEjKSz4jJrzpdzZv7fd26B20sdCLeoUjc2HM3H6BDNnzhzCwsIYOXJkg+8risLChQuJjIwkJiaGvXv3tnANr52bmxsrli9iZMwfCe1zP4mJcfToEWIRM2J4BCHBt3HH7wYzZcpfef21xVbL7t1bTMK4SeTn72jxNqmN9LFQEwWNzYczcfoEM2bMGFauXNno+3l5eZSUlJCdnc2CBQuYP39+y1XuN7p7QD8OHSrh8OEj1NbWsnZtJqNioixiYmKieH/1egC+2vktnTp3QqfTNlm2uPggBw4cavH2qJH0sVCT+ms4nInTJ5gBAwbQqVOnRt/PyckhLi4OjUZD3759qa6uNu8rrVb+ATpKy46az8vKK/D311nEBPjrKCu9HFNeVkGAv86mskL6WKiLjGCclMFgQKe7/Jdfp9NhMBgcWCPrNJqr/xBdOV2psRhbygrpY6EurjqCcfmnyBr6i9/QPxBqUl5WQWBXf/N51wA/Kiosk2JZeQVdAy/HBHT142iFAQ8PD6tlhfSxUBeTk41MbOXyIxidTkdlZaX5vLKyEq1W68AaWff1rgKCg2/j1lsDad26NePGxbI5K9siJisrm6SHxgIw8O7+VJ+uprLSaFNZIX0s1KVeY/vhTFx+BBMREcEHH3xAdHQ0hYWFeHp6qj7BmEwmps94li36D3F3c+O9Vens23eAyZOSAEh7+322bM1h+PAIvt//OT//8gsTJ85ssixAbOxwlr+8kC5dvNiU+S8KC/fy4MiHHNZOR5I+FmpS76IjmCbXInMGM2fOZOfOnZw8eRJvb2+mTp1KXV0dAOPHj0dRFFJSUsjPz6dt27akpqYSGhpq9XNlLTLhKmQtMvXL0E2wOTau8kM71qR5OX2CsRdJMMJVSIJRv4+uIcGMcaIE4/L3YIQQQu3qNRqbD1vk5eURFRVFZGQkaWlpV73f1AT0xiavv/rqq9x7773ExsYSGxtLbm6u1XpIghFCCAczXcNh9bNMJlJSUli5ciV6vZ6srCwOHjxoEdPUBPSmJq8/8sgjZGZmkpmZSXh4uNW6SIIRQggHa86nyIqKiggKCiIwMBAPDw+io6PJycmxiGlqArq1yevXQhKMEEI4WD0am4/09HTGjBljPtLT0y0+68rJ5b6+vldNLv+tE9BXr15NTEwMc+bM4fTp01bjXf4xZSGEULtredIqMTGRxMTExj/Lhsnlv2UC+vjx43n88cfRaDQsX76cJUuWsHjx4ibLyAhGCCEcrDkvkV05udxgMFw19++3TED38fHB3d0dNzc3EhIS2L17t9W6SIIRQggHa861yEJDQykpKaG0tJSamhr0ej0REREWMREREWRkZKAoCgUFBTZNQP/1IsHbtm0jJCSkieiL5BKZEEI4mKkZJ/K3atWKefPmMXHiREwmE/Hx8YSEhLBmzRrg4qWu8PBwcnNziYyMNE9Av+TXk9eHDBnC1KlTSUhIYOnSpRQXFwMQEBBASkqK1brIRMtGyERL4SpkoqX6vd31jzbHTir7wI41aV4yghFCCAdztmX4bSUJRgghHExxzbUuJcEIIYSjueoIRp4iU6moYfexd08exfu28/SsJxqMefmlFIr3befbbz6lX99eVsvGx4+ksOAzas6Xcmf/3nZvg9pJHwu1aM6lYtTEKRJMQ4uvnTp1iuTkZIYNG0ZycnKjs0qtLfqmRm5ubqxYvoiRMX8ktM/9JCbG0aOH5SOBI4ZHEBJ8G3f8bjBTpvyV119bbLXs3r3FJIybRH7+jhZvk9pIHws1cdUNx5wiwTS0+FpaWhphYWFkZ2cTFhbWYPKwZdE3Nbp7QD8OHSrh8OEj1NbWsnZtJqNioixiYmKieH/1egC+2vktnTp3QqfTNlm2uPggBw4cavH2qJH0sVCT5pwHoyZOkWAaWnzt0mJtAHFxcWzbtu2qcrYs+qZG/gE6SsuOms/Lyivw99dZxAT46ygrvRxTXlZBgL/OprJC+lioiyQYlTlx4oR55qlWq6WqquqqGFsWfVOjhtYEunK6UmMxtpQV0sdCXZRrOJyJSz9F9lsWdFOD8rIKArv6m8+7BvhRUWGZGMvKK+gaeDkmoKsfRysMeHh4WC0rpI+FujjbvRVbOe0Ixtvb27w2jtFoxMvL66oYWxZ9U6OvdxUQHHwbt94aSOvWrRk3LpbNWdkWMVlZ2SQ9NBaAgXf3p/p0NZWVRpvKCuljoS7yFJnKXFqsDSAjI4OhQ4deFWPLom9qZDKZmD7jWbboP2RP0X9Yv34z+/YdYPKkJCZPSgJgy9Ycfjx8hO/3f86bb/6dJ6fObbIsQGzscEp+3MWgQXeyKfNfbMla7bA2Opr0sVCTehSbD2fiFGuR/XrxNW9vb6ZOncoDDzzAjBkzqKiowM/Pj+XLl9O5c2cMBgPPPvssb7/9NgC5ubmkpqaaF32bMmWKTd8pa5EJVyFrkanfgqCHbI597ifn+dHiFAnGESTBCFchCUb9Uq4hwcxzogTj0jf5hRDCGTjb48e2kgQjhBAOVqdxzQtJkmCEEMLBXDO9SIIRQgiHk0tkQggh7MLZHj+2lSQYIYRwMNdML5JghBDC4eQSmRBCCLswuegYRhKMEEI4mIxghBBC2IXioiMYp13sUgghXEVzbzhmbat4RVFYuHAhkZGRxMTEsHfvXvN7DW1RD7ZvU/9rkmBUKmrYfezdk0fxvu08PeuJBmNefimF4n3b+fabT+nXt5fVsvHxIyks+Iya86Xc2b+33dugdtLHQi2aczVlW7aKz8vLo6SkhOzsbBYsWMD8+fPN7zW0RT3Ytk39lVSVYBrKnE1lzbfeeovIyEiioqLIz89v8DN/S9Z1NDc3N1YsX8TImD8S2ud+EhPj6NEjxCJmxPAIQoJv447fDWbKlL/y+muLrZbdu7eYhHGTyM/f0eJtUhvpY6EmzbmjpS1bxV/acl6j0dC3b1+qq6vN+2s1tEX9r8tA49vUX0lVCaahzNlY1jx48CB6vR69Xs/KlSt5/vnnMZmu3o7nt2RdR7t7QD8OHSrh8OEj1NbWsnZtJqNioixiYmKieH/1egC+2vktnTp3QqfTNlm2uPggBw4cavH2qJH0sVCTOhSbj/T0dMaMGWM+0tPTLT7Llq3ir4zR6XRWt5O3ZZv6K6kqwTSUORvLmjk5OURHR1/cvjYwkKCgIIqKiq76zN+SdR3NP0BHadlR83lZeQX+/jqLmAB/HWWll2PKyyoI8NfZVFZIHwt1Ua7hf4mJiXz00UfmIzEx0fKzbNgqvqW2k1dVgmlIY1nTlizdVHk1a+j/6Cv/QDQWY0tZIX0s1KU5b/LbslX8lTGVlZVWt5O3ZZv6K6k+wTSmpTKwI5SXVRDY1d983jXAj4oKy+RZVl5B18DLMQFd/ThaYbCprJA+FupyLSMYa2zZKv7SlvOKolBQUICnp6fVBGPLNvVXUn2CaSxr2pKlmyqvZl/vKiA4+DZuvTWQ1q1bM25cLJuzsi1isrKySXpoLAAD7+5P9elqKiuNNpUV0sdCXZpzBNOqVSvmzZvHxIkTefDBBxkxYgQhISGsWbOGNWvWABAeHk5gYCCRkZE899xz/O1vfzOXnzlzJn/4wx84fPgwQ4YMYd26dQBMnjyZzz//nGHDhvH5558zefJk63W5hj5wiEtZc/LkyRZZMyIigj//+c8kJydjMBgoKSmhd++rHwttrLyamUwmps94li36D3F3c+O9Vens23eAyZOSAEh7+322bM1h+PAIvt//OT//8gsTJ85ssixAbOxwlr+8kC5dvNiU+S8KC/fy4Ejbt2p1JdLHQk1MzXyJNTw8nPDwcIvXxo8fb/5vjUZjkVR+7aWXXmrw9ZtvvplVq1ZdUz00ioouHs+cOZOdO3dy8uRJvL29mTp1Kg888AAzZsygoqICPz8/li9fTufOnQH4xz/+wYYNG3B3d2fu3LnmDn3mmWf4wx/+QGhoKCdPnmy0fFNaeQTYsaVCtJy6mnJHV0FYMSFotM2xH/600Y41aV6qSjBqIglGuApJMOo3PijO5tg1P2XYrR7NTfWXyIQQwtXJYpdCCCHsQna0FEIIYReuupqyJBghhHCw5n6KTC0kwQghhIPJJTIhhBB2ITf5hRBC2IXcgxFCCGEXcolMCCGEXbjqfHdJMEII4WAmGcEIIYSwB7lEJoQQwi5c9RKZ6veDuVFFDbuPvXvyKN63nadnPdFgzMsvpVC8bzvffvMp/fr2slo2Pn4khQWfUXO+lDv7X721wY1G+lioRT2KzYczcUiCmTNnDmFhYYwcOdL82qlTp0hOTmbYsGEkJydz+vRp83tvvfUWkZGRREVFkZ+fb359z549xMTEEBkZycKFCxv9FdBYebVyc3NjxfJFjIz5I6F97icxMY4ePUIsYkYMjyAk+Dbu+N1gpkz5K6+/tthq2b17i0kYN4n8/B0t3ia1kT4WatKcO1qqiUMSzJgxY1i5cqXFa2lpaYSFhZGdnU1YWBhpaWkAHDx4EL1ej16vZ+XKlTz//POYTCYA5s+fT0pKCtnZ2ZSUlJCXl3fVdzVVXq3uHtCPQ4dKOHz4CLW1taxdm8momCiLmJiYKN5fvR6Ar3Z+S6fOndDptE2WLS4+yIEDh1q8PWokfSzUxKQoNh/OxCEJZsCAAXTq1MnitZycHOLi4gCIi4tj27Zt5tejo6Px8PAgMDCQoKAgioqKMBqNnD17ln79+qHRaIiLiyMnJ+eq72qsvJr5B+goLTtqPi8rr8DfX2cRE+Cvo6z0ckx5WQUB/jqbygrpY6EuconMzk6cOIFWqwVAq9VSVVUFgMFgQKe7/JfX19cXg8Fw1es6nQ6DwXDV5zZWXs00Gs1Vr115+a+xGFvKCuljoS6ummBU/xRZQ39xNRpNo6/bWl7NyssqCOzqbz7vGuBHRYVlUiwrr6Br4OWYgK5+HK0wXBypWSkrpI+FurjqDxTVjGC8vb0xGo0AGI1GvLy8gIsjk8rKSnOcwWBAq9Ve9XplZaV5BPRrjZVXs693FRAcfBu33hpI69atGTculs1Z2RYxWVnZJD00FoCBd/en+nQ1lZVGm8oK6WOhLq46glFNgomIiCAjIwOAjIwMhg4dan5dr9dTU1NDaWkpJSUl9O7dG61WS/v27SkoKEBRFIsyV35uQ+XVzGQyMX3Gs2zRf8ieov+wfv1m9u07wORJSUyelATAlq05/Hj4CN/v/5w33/w7T06d22RZgNjY4ZT8uItBg+5kU+a/2JK12mFtdDTpY6EmrvoUmUZxwNhs5syZ7Ny5k5MnT+Lt7c3UqVN54IEHmDFjBhUVFfj5+bF8+XI6d+4MwD/+8Q82bNiAu7s7c+fOJTw8HIDdu3czZ84czp8/z5AhQ3juuefQaDTk5OSwZ88epk+f3mT5prTyCLBb+4VoSXU15Y6ugrCiv99gm2O/rdhux5o0L4ckGGcgCUa4Ckkw6tdP93ubY7+r/NxqTF5eHosWLaK+vp6EhAQmT55s8b6iKCxatIjc3FzatGnDkiVL6NmzZ5NlX331VdauXWu+fTFz5kyrP9ZVf5NfCCFcXXPeWzGZTKSkpPDuu+/i6+vL2LFjiYiIIDg42ByTl5dHSUkJ2dnZFBYWMn/+fNatW2e17COPPMKjjz5qc11Ucw9GCCFuVM15D6aoqIigoCACAwPx8PAgOjr6qjmCl+YdajQa+vbtS3V1NUaj0aay10ISjBBCOFi9oth8pKenM2bMGPORnp5u8Vm2zP1rbB6htbKrV68mJiaGOXPmWCzn1Ri5RCaEEA52LU+HJSYmkpiY2Phn2TD377fMLxw/fjyPP/44Go2G5cuXs2TJEhYvXtxkXWUEI4QQDmZS6m0+rLFl7l9j8wibKuvj44O7uztubm4kJCSwe/duq3WRBCOEEA52LZfIrAkNDaWkpITS0lJqamrQ6/VERERYxFyad6goCgUFBXh6eqLVapsse2kiPMC2bdsICbFcfbwhcolMCCEcrDknULZq1Yp58+YxceJETCYT8fHxhISEsGbNGuDipa7w8HByc3OJjIykbdu2pKamNlkWYOnSpRQXFwMQEBBASkqK1brIPJhGyDwY4SpkHoz63e7T3+bYQ8e/tWNNmpeMYIQQwsGcbQkYW0mCEUIIBzMp6t4E8beSBCOEEA7mqncqJMEIIYSDOdsy/LaSx5RVKmrYfezdk0fxvu08PeuJBmNefimF4n3b+fabT+nXt5fVsvHxIyks+Iya86Xc2V/dWxa0BOljoRaKoth8OBO7JZg5c+YQFhbGyJEjza+dOnWK5ORkhg0bRnJyssVSA2+99RaRkZFERUWRn59vfn3Pnj3ExMQQGRnJwoULzR1cU1PDjBkziIyMJCEhgbKysgbr0Vh5NXNzc2PF8kWMjPkjoX3uJzExjh49LJ85HzE8gpDg27jjd4OZMuWvvP7aYqtl9+4tJmHcJPLzd7R4m9RG+lioSXPOg1ETuyWYMWPGsHLlSovX0tLSCAsLIzs7m7CwMNLS0gA4ePAger0evV7PypUref755zGZLt70mj9/PikpKWRnZ1NSUkJeXh4A69ato2PHjnz66ac88sgjvPjiiw3Wo7Hyanb3gH4cOlTC4cNHqK2tZe3aTEbFRFnExMRE8f7q9QB8tfNbOnXuhE6nbbJscfFBDhw41OLtUSPpY6EmrrrhmN0SzIABA+jUqZPFa5dW8ASIi4tj27Zt5tejo6Mv7nUeGEhQUBBFRUUYjUbOnj1Lv3790Gg0xMXFmVf2/Oyzzxg9ejQAUVFRfPnll1eNTpoqr2b+ATpKy46az8vKK/D311nEBPjrKCu9HFNeVkGAv86mskL6WKhLcy4VoyYteg/mxIkT5nVttFotVVVVQOOrfza24uelMn5+fsDF2aeenp6cPHnS4vuaKq9mVy5MB1c/ZdJYjC1lhfSxUBdXvQejiqfIfsvKntezYqjalZdVENjV33zeNcCPigrLxFhWXkHXwMsxAV39OFphuDgKtFJWSB8LdXG2eyu2atERjLe3t3nBNKPRaN56s7EVPBtb8fNSmYqKCgDq6uo4c+YMnTt3tvi+psqr2de7CggOvo1bbw2kdevWjBsXy+asbIuYrKxskh4aC8DAu/tTfbqaykqjTWWF9LFQF1cdwbRogrm0gidARkYGQ4cONb+u1+upqamhtLSUkpISevfujVarpX379hQUFKAoylVlNm7cCMAnn3zCoEGDrhqdNFVezUwmE9NnPMsW/YfsKfoP69dvZt++A0yelMTkSUkAbNmaw4+Hj/D9/s95882/8+TUuU2WBYiNHU7Jj7sYNOhONmX+iy1Zqx3WRkeTPhZqUo9i8+FM7LbY5cyZM9m5cycnT57E29ubqVOn8sADDzBjxgwqKirw8/Nj+fLl5lHHP/7xDzZs2IC7uztz584lPDwcgN27dzNnzhzOnz/PkCFDeO6559BoNFy4cIFZs2axf/9+OnXqxMsvv0xgYCAAsbGxZGZmNlneGlnsUrgKWexS/Tq272ZzbPW5H+1Yk+Ylqyk3QhKMcBWSYNSvfbtbbY4993OJ3erR3FRxk18IIW5krnqTXxKMEEI4mKteSJIEI4QQDuZsM/RtJQlGCCEcTEYwQggh7MJV78HIU2RCCCHsQvaDEUIIYReSYIQQQtiFJBghhBB2IQlGCCGEXUiCEUIIYReSYIQQQtiFJBghhBB2IQnGifXr18/8348++ih33XUXjz32mANr5Hou9fH+/ftJTEwkOjqamJgYtmzZ4uCaCaF+MpPfRUycOJFffvmF9PR0R1fFJbVp04YXXniBW2+9FYPBQHx8PIMHD6Zjx46OrpoQqiUJxkWEhYXx1VdfOboaLuu2224z/7evry9eXl5UVVVJgrFBWVkZkyZN4s477+S7777D19eXN954g8OHD/O3v/2NX375hVtuuYXU1FQ6depEUlISvXv35quvvuLMmTMsWrSIu+66C5PJxIsvvsjOnTupqanhoYce4g9/+IOjmyeaIJfIhLhGRUVF1NbWcssttzi6Kk7jp59+4qGHHkKv1+Pp6cknn3zC008/zV/+8hc2b95M9+7dee2118zxJpOJ9evXM3fuXPPr69evx9PTkw0bNrBhwwbWrl1LaWmpo5okbCAjGCGugdFoZNasWbzwwgu4ucnvM1t17dqVHj16ANCzZ09KS0s5c+YMd999NwCjR49m+vTp5vjIyEhzbHn5xR05P//8c77//ns++eQTAM6cOcNPP/1k3ipdqI8kGCFsdPbsWR577DFmzJhB3759HV0dp+Lh4WH+b3d3d6qrq22Kd3Nzw2QyAReXtH/22We599577VdR0azkJ5gQNqipqeGJJ54gNjaWESNGOLo6Ts/T05OOHTuya9cuADIzMxkwYECTZQYPHsyaNWuora0F4PDhw/z88892r6v47WQE4yImTJjAjz/+yM8//8yQIUNYtGiR/NJrRlu3bmXXrl2cOnWKjRs3ArBkyRLzZR9x7V544QXzTf7AwEAWL17cZHxCQgLl5eWMGTMGRVG4+eabeeONN1qotuK3kP1ghBBC2IVcIhNCCGEXkmCEEELYhSQYIYQQdiEJRgghhF1IghFCCGEXkmCEaAZlZWWMHDkSuLjycm5uroNrJITjSYIRoplJghHiIkkw4oZQVlbG8OHD+etf/0pMTAzTpk3jl19+Yc+ePfzxj39kzJgxPProoxiNRgCSkpJYunQpY8eOJSoqyjzjvKysjAkTJjB69GhGjx7Nt99+a/E9NTU1rFixgi1bthAbG8uWLVsYNmwYVVVVANTX1xMZGWk+F8KVSYIRN4zDhw8zbtw4Nm/eTPv27Vm9ejULFy5kxYoVfPTRR8THx/Pyyy+b4xta0dfb25t3332XjRs38vLLL7Nw4UKL7/Dw8GDatGk8+OCDZGZm8uCDDzJq1Cg2bdoEwBdffMEdd9yBl5dXyzVcCAeRpWLEDcPPz48777wTgFGjRvHWW29x4MABkpOTgYujiy5dupjjG1rRt66ujpSUFIqLi3Fzc6OkpMTq98bHx/P444/zyCOPsGHDBsaMGdPMLRNCnSTBiBuGRqOxOG/fvj0hISGN7gLa0Iq+7733Hj4+PmRmZlJfX0/v3r2tfq+fnx/e3t58+eWXFBYW8uKLL15nS4RwDnKJTNwwjh49ynfffQeAXq+nT58+VFVVmV+rra3lhx9+aPIzzpw5Q5cuXXBzcyMzM9OceH6tffv2nDt3zuK1hIQEZs2axYgRI3B3d2+mFgmhbpJgxA3j9ttvZ+PGjcTExHD69GmSkpJYsWIFL774IqNGjSIuLs6cbBozYcIENm7cyLhx4ygpKaFdu3ZXxQwcOJCDBw+ab/IDRERE8PPPP8vlMXFDkdWUxQ2hrKyMP/3pT2RlZTnk+3fv3s3ixYv58MMPHfL9QjiC3IMRws7S0tJYs2YNS5cudXRVhGhRMoIRQghhF3IPRgghhF1IghFCCGEXkmCEEELYhSQYIYQQdiEJRgghhF38H/mFTTi9pcP5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = pd.DataFrame( best_model.cv_results_['params'] )\n",
    "\n",
    "results['score_acc'] = 1 - best_model.cv_results_['mean_test_accuracy']\n",
    "\n",
    "cols = results.columns.to_series().str.split('__').apply(lambda x: x[-1])\n",
    "results.columns = cols\n",
    "\n",
    "# Heat map\n",
    "sns.heatmap( results.query('solver==\"saga\"').pivot('C','penalty','score_acc'),\n",
    "             annot=True, fmt='.3f')\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "impaired-rhythm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets another 5000 random samples\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_p, Y_p, train_size = 5000, random_state = 3)\n",
    "\n",
    "# Grid Search\n",
    "pipe = Pipeline([('classifier', LogisticRegression())])\n",
    "\n",
    "search_space = [{'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['saga'],\n",
    "                 'classifier__penalty': ['l1', 'l2'],\n",
    "                 'classifier__C': np.logspace(-4, 4, 9)},\n",
    "                {'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['lbfgs'],\n",
    "                 'classifier__penalty': ['l2'],\n",
    "                 'classifier__C': np.logspace(-4, 4, 9)},\n",
    "                {'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['lbfgs','saga'],\n",
    "                 'classifier__penalty': ['none']}]\n",
    "                \n",
    "clf = GridSearchCV(pipe, search_space, cv=StratifiedKFold(n_splits=5), \n",
    "                   scoring=['accuracy', 'roc_auc_ovr', 'f1_micro'], refit=False,\n",
    "                   verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "liquid-cursor",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "medieval-stability",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([8.39147568e-03, 1.86957359e-02, 6.39357567e-03, 1.39684677e-02,\n",
       "        5.48634529e-03, 1.29612923e-02, 1.58883572e-02, 1.35078430e-02,\n",
       "        1.89266682e-02, 2.24709511e-02, 8.37059021e-02, 9.80743408e-02,\n",
       "        3.14213371e-01, 3.18510962e-01, 5.95688152e-01, 2.83915901e-01,\n",
       "        6.86443853e-01, 5.03534079e-01, 8.28354816e+00, 5.05144224e+00,\n",
       "        6.13011703e+00, 8.41364989e+00, 1.37752024e+01, 1.51347686e+01,\n",
       "        2.17729976e+01, 2.56920614e+01, 3.13337306e+01, 1.67340251e+01,\n",
       "        8.92442989e-01]),\n",
       " 'std_fit_time': array([1.03592436e-03, 4.90579914e-03, 1.18514022e-03, 1.68243957e-03,\n",
       "        1.08134947e-03, 5.53101539e-04, 1.07909984e-03, 1.29098390e-03,\n",
       "        2.02096064e-03, 1.60101108e-03, 2.08450727e-02, 3.34689905e-02,\n",
       "        2.50126356e-02, 1.51334953e-02, 3.75548932e-02, 4.98433997e-02,\n",
       "        3.92339078e-02, 2.00138668e-02, 4.37735909e-01, 4.27076742e-01,\n",
       "        2.78775084e-01, 6.86867564e-01, 1.25252548e+00, 4.97991225e-01,\n",
       "        2.02977066e+00, 2.18305155e+00, 1.31489335e+01, 2.01360697e+00,\n",
       "        3.24836785e-02]),\n",
       " 'mean_score_time': array([0.00979929, 0.00884557, 0.00792251, 0.00569663, 0.00575967,\n",
       "        0.00555468, 0.00537224, 0.00547805, 0.00545926, 0.00591297,\n",
       "        0.00613818, 0.00555029, 0.00580444, 0.0072865 , 0.00624127,\n",
       "        0.00742497, 0.00644794, 0.00791245, 0.08495889, 0.02789583,\n",
       "        0.06654034, 0.04872732, 0.08734956, 0.04718323, 0.04725356,\n",
       "        0.08594255, 0.06605678, 0.06474605, 0.01241441]),\n",
       " 'std_score_time': array([0.0015837 , 0.00165204, 0.00160219, 0.00041923, 0.00031098,\n",
       "        0.00039275, 0.00030807, 0.00023007, 0.00039706, 0.00025673,\n",
       "        0.00068313, 0.00034341, 0.00022498, 0.00148708, 0.0005555 ,\n",
       "        0.00171694, 0.00062563, 0.0018756 , 0.07167516, 0.04207295,\n",
       "        0.04611217, 0.04389786, 0.03957056, 0.04703136, 0.04763508,\n",
       "        0.03859927, 0.0477024 , 0.04653961, 0.01210893]),\n",
       " 'param_classifier': masked_array(data=[LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000)],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__C': masked_array(data=[0.0001, 0.0001, 0.001, 0.001, 0.01, 0.01, 0.1, 0.1,\n",
       "                    1.0, 1.0, 10.0, 10.0, 100.0, 100.0, 1000.0, 1000.0,\n",
       "                    10000.0, 10000.0, 0.0001, 0.001, 0.01, 0.1, 1.0, 10.0,\n",
       "                    100.0, 1000.0, 10000.0, --, --],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False,  True,  True],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__penalty': masked_array(data=['l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1',\n",
       "                    'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'none', 'none'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__solver': masked_array(data=['saga', 'saga', 'saga', 'saga', 'saga', 'saga', 'saga',\n",
       "                    'saga', 'saga', 'saga', 'saga', 'saga', 'saga', 'saga',\n",
       "                    'saga', 'saga', 'saga', 'saga', 'lbfgs', 'lbfgs',\n",
       "                    'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs',\n",
       "                    'lbfgs', 'lbfgs', 'saga'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__penalty': 'none',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__penalty': 'none',\n",
       "   'classifier__solver': 'saga'}],\n",
       " 'split0_test_accuracy': array([0.965, 0.965, 0.965, 0.965, 0.965, 0.965, 0.996, 0.967, 0.996,\n",
       "        0.996, 0.996, 0.996, 0.996, 0.996, 0.996, 0.996, 0.996, 0.996,\n",
       "        0.965, 0.965, 0.965, 0.967, 0.996, 0.996, 0.996, 0.996, 0.996,\n",
       "        0.996, 0.996]),\n",
       " 'split1_test_accuracy': array([0.965, 0.965, 0.965, 0.965, 0.965, 0.965, 0.994, 0.965, 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.965, 0.965, 0.965, 0.965, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split2_test_accuracy': array([0.965, 0.965, 0.965, 0.965, 0.965, 0.965, 1.   , 0.965, 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.965, 0.965, 0.965, 0.965, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split3_test_accuracy': array([0.965, 0.965, 0.965, 0.965, 0.965, 0.965, 0.999, 0.968, 0.999,\n",
       "        0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999,\n",
       "        0.965, 0.965, 0.965, 0.968, 0.999, 0.999, 0.999, 0.999, 0.999,\n",
       "        0.999, 0.999]),\n",
       " 'split4_test_accuracy': array([0.964, 0.964, 0.964, 0.964, 0.964, 0.964, 0.993, 0.965, 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.964, 0.964, 0.964, 0.965, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'mean_test_accuracy': array([0.9648, 0.9648, 0.9648, 0.9648, 0.9648, 0.9648, 0.9964, 0.966 ,\n",
       "        0.999 , 0.999 , 0.999 , 0.999 , 0.999 , 0.999 , 0.999 , 0.999 ,\n",
       "        0.999 , 0.999 , 0.9648, 0.9648, 0.9648, 0.966 , 0.999 , 0.999 ,\n",
       "        0.999 , 0.999 , 0.999 , 0.999 , 0.999 ]),\n",
       " 'std_test_accuracy': array([0.0004    , 0.0004    , 0.0004    , 0.0004    , 0.0004    ,\n",
       "        0.0004    , 0.00272764, 0.00126491, 0.00154919, 0.00154919,\n",
       "        0.00154919, 0.00154919, 0.00154919, 0.00154919, 0.00154919,\n",
       "        0.00154919, 0.00154919, 0.00154919, 0.0004    , 0.0004    ,\n",
       "        0.0004    , 0.00126491, 0.00154919, 0.00154919, 0.00154919,\n",
       "        0.00154919, 0.00154919, 0.00154919, 0.00154919]),\n",
       " 'rank_test_accuracy': array([21, 21, 21, 21, 21, 21, 18, 19,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1, 21, 21, 21, 19,  1,  1,  1,  1,  1,  1,  1], dtype=int32),\n",
       " 'split0_test_roc_auc_ovr': array([0.5       , 0.91683198, 0.5       , 0.91683198, 0.5       ,\n",
       "        0.94022206, 0.94285714, 0.94022206, 0.93708364, 0.94022206,\n",
       "        0.93708364, 0.94022206, 0.94019245, 0.94022206, 0.94022206,\n",
       "        0.94022206, 0.94022206, 0.94022206, 0.91683198, 0.91683198,\n",
       "        0.94022206, 0.94022206, 0.94022206, 0.94022206, 0.94022206,\n",
       "        0.94022206, 0.94022206, 0.94022206, 0.94022206]),\n",
       " 'split1_test_roc_auc_ovr': array([0.5, 1. , 0.5, 1. , 0.5, 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. ,\n",
       "        1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. ,\n",
       "        1. , 1. , 1. ]),\n",
       " 'split2_test_roc_auc_ovr': array([0.5       , 0.96678016, 0.5       , 0.96678016, 0.5       ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.96678016, 0.96678016,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'split3_test_roc_auc_ovr': array([0.5       , 0.9911621 , 0.5       , 0.99122132, 0.5       ,\n",
       "        0.99122132, 0.98571429, 0.99122132, 0.98571429, 0.99122132,\n",
       "        0.98296077, 0.98293116, 0.98296077, 0.98299038, 0.98299038,\n",
       "        0.98299038, 0.98299038, 0.98299038, 0.9911621 , 0.99122132,\n",
       "        0.99122132, 0.99122132, 0.99122132, 0.98293116, 0.98299038,\n",
       "        0.98299038, 0.98299038, 0.98299038, 0.98299038]),\n",
       " 'split4_test_roc_auc_ovr': array([0.5       , 0.94994813, 0.5       , 0.94994813, 0.5       ,\n",
       "        0.98331604, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.94994813, 0.94994813,\n",
       "        0.98331604, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'mean_test_roc_auc_ovr': array([0.5       , 0.96494447, 0.5       , 0.96495632, 0.5       ,\n",
       "        0.98295188, 0.98571429, 0.98628868, 0.98455959, 0.98628868,\n",
       "        0.98400888, 0.98463064, 0.98463064, 0.98464249, 0.98464249,\n",
       "        0.98464249, 0.98464249, 0.98464249, 0.96494447, 0.96495632,\n",
       "        0.98295188, 0.98628868, 0.98628868, 0.98463064, 0.98464249,\n",
       "        0.98464249, 0.98464249, 0.98464249, 0.98464249]),\n",
       " 'std_test_roc_auc_ovr': array([0.        , 0.02986411, 0.        , 0.02987452, 0.        ,\n",
       "        0.02225143, 0.02213133, 0.02328289, 0.02437424, 0.02328289,\n",
       "        0.02437304, 0.02316749, 0.02317841, 0.02316663, 0.02316663,\n",
       "        0.02316663, 0.02316663, 0.02316663, 0.02986411, 0.02987452,\n",
       "        0.02225143, 0.02328289, 0.02328289, 0.02316749, 0.02316663,\n",
       "        0.02316663, 0.02316663, 0.02316663, 0.02316663]),\n",
       " 'rank_test_roc_auc_ovr': array([27, 25, 27, 23, 27, 21,  5,  1, 19,  1, 20, 16, 16,  6,  6,  6,  6,\n",
       "         6, 25, 23, 21,  1,  1, 16,  6,  6,  6,  6,  6], dtype=int32),\n",
       " 'split0_test_f1_micro': array([0.965, 0.965, 0.965, 0.965, 0.965, 0.965, 0.996, 0.967, 0.996,\n",
       "        0.996, 0.996, 0.996, 0.996, 0.996, 0.996, 0.996, 0.996, 0.996,\n",
       "        0.965, 0.965, 0.965, 0.967, 0.996, 0.996, 0.996, 0.996, 0.996,\n",
       "        0.996, 0.996]),\n",
       " 'split1_test_f1_micro': array([0.965, 0.965, 0.965, 0.965, 0.965, 0.965, 0.994, 0.965, 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.965, 0.965, 0.965, 0.965, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split2_test_f1_micro': array([0.965, 0.965, 0.965, 0.965, 0.965, 0.965, 1.   , 0.965, 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.965, 0.965, 0.965, 0.965, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split3_test_f1_micro': array([0.965, 0.965, 0.965, 0.965, 0.965, 0.965, 0.999, 0.968, 0.999,\n",
       "        0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999,\n",
       "        0.965, 0.965, 0.965, 0.968, 0.999, 0.999, 0.999, 0.999, 0.999,\n",
       "        0.999, 0.999]),\n",
       " 'split4_test_f1_micro': array([0.964, 0.964, 0.964, 0.964, 0.964, 0.964, 0.993, 0.965, 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.964, 0.964, 0.964, 0.965, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'mean_test_f1_micro': array([0.9648, 0.9648, 0.9648, 0.9648, 0.9648, 0.9648, 0.9964, 0.966 ,\n",
       "        0.999 , 0.999 , 0.999 , 0.999 , 0.999 , 0.999 , 0.999 , 0.999 ,\n",
       "        0.999 , 0.999 , 0.9648, 0.9648, 0.9648, 0.966 , 0.999 , 0.999 ,\n",
       "        0.999 , 0.999 , 0.999 , 0.999 , 0.999 ]),\n",
       " 'std_test_f1_micro': array([0.0004    , 0.0004    , 0.0004    , 0.0004    , 0.0004    ,\n",
       "        0.0004    , 0.00272764, 0.00126491, 0.00154919, 0.00154919,\n",
       "        0.00154919, 0.00154919, 0.00154919, 0.00154919, 0.00154919,\n",
       "        0.00154919, 0.00154919, 0.00154919, 0.0004    , 0.0004    ,\n",
       "        0.0004    , 0.00126491, 0.00154919, 0.00154919, 0.00154919,\n",
       "        0.00154919, 0.00154919, 0.00154919, 0.00154919]),\n",
       " 'rank_test_f1_micro': array([21, 21, 21, 21, 21, 21, 18, 19,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1, 21, 21, 21, 19,  1,  1,  1,  1,  1,  1,  1], dtype=int32)}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "independent-story",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21, 21, 21, 21, 21, 21, 18, 19,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1, 21, 21, 21, 19,  1,  1,  1,  1,  1,  1,  1], dtype=int32)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.cv_results_['rank_test_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "hungarian-wildlife",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 1.0,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for accuracy\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_accuracy']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "contemporary-characteristic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 0.1,\n",
       " 'classifier__penalty': 'l2',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for roc auc\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_roc_auc_ovr']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "innocent-reunion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 1.0,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for f1\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_f1_micro']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "fossil-newcastle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best accuracy model\n",
    "acc_model = LogisticRegression(penalty = 'l1', C = 1.0, solver = 'saga', max_iter = 5000)\n",
    "\n",
    "# best roc auc model\n",
    "roc_model = LogisticRegression(penalty = 'l2', C = 0.1, solver = 'saga', max_iter = 5000)\n",
    "\n",
    "# best f1 model\n",
    "f1_model = LogisticRegression(penalty = 'l1', C = 1.0, solver = 'saga', max_iter = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "married-playing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=5000, penalty='l1', solver='saga')"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# models the data\n",
    "acc_model.fit(X_train, Y_train)\n",
    "roc_model.fit(X_train, Y_train)\n",
    "f1_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "utility-archives",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>C</th>\n",
       "      <th>penalty</th>\n",
       "      <th>solver</th>\n",
       "      <th>score_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           classifier           C penalty solver  score_acc\n",
       "0   LogisticRegression(max_iter=5000)      0.0001      l1   saga     0.0352\n",
       "1   LogisticRegression(max_iter=5000)      0.0001      l2   saga     0.0352\n",
       "2   LogisticRegression(max_iter=5000)      0.0010      l1   saga     0.0352\n",
       "3   LogisticRegression(max_iter=5000)      0.0010      l2   saga     0.0352\n",
       "4   LogisticRegression(max_iter=5000)      0.0100      l1   saga     0.0352\n",
       "5   LogisticRegression(max_iter=5000)      0.0100      l2   saga     0.0352\n",
       "6   LogisticRegression(max_iter=5000)      0.1000      l1   saga     0.0036\n",
       "7   LogisticRegression(max_iter=5000)      0.1000      l2   saga     0.0340\n",
       "8   LogisticRegression(max_iter=5000)      1.0000      l1   saga     0.0010\n",
       "9   LogisticRegression(max_iter=5000)      1.0000      l2   saga     0.0010\n",
       "10  LogisticRegression(max_iter=5000)     10.0000      l1   saga     0.0010\n",
       "11  LogisticRegression(max_iter=5000)     10.0000      l2   saga     0.0010\n",
       "12  LogisticRegression(max_iter=5000)    100.0000      l1   saga     0.0010\n",
       "13  LogisticRegression(max_iter=5000)    100.0000      l2   saga     0.0010\n",
       "14  LogisticRegression(max_iter=5000)   1000.0000      l1   saga     0.0010\n",
       "15  LogisticRegression(max_iter=5000)   1000.0000      l2   saga     0.0010\n",
       "16  LogisticRegression(max_iter=5000)  10000.0000      l1   saga     0.0010\n",
       "17  LogisticRegression(max_iter=5000)  10000.0000      l2   saga     0.0010\n",
       "18  LogisticRegression(max_iter=5000)      0.0001      l2  lbfgs     0.0352\n",
       "19  LogisticRegression(max_iter=5000)      0.0010      l2  lbfgs     0.0352\n",
       "20  LogisticRegression(max_iter=5000)      0.0100      l2  lbfgs     0.0352\n",
       "21  LogisticRegression(max_iter=5000)      0.1000      l2  lbfgs     0.0340\n",
       "22  LogisticRegression(max_iter=5000)      1.0000      l2  lbfgs     0.0010\n",
       "23  LogisticRegression(max_iter=5000)     10.0000      l2  lbfgs     0.0010\n",
       "24  LogisticRegression(max_iter=5000)    100.0000      l2  lbfgs     0.0010\n",
       "25  LogisticRegression(max_iter=5000)   1000.0000      l2  lbfgs     0.0010\n",
       "26  LogisticRegression(max_iter=5000)  10000.0000      l2  lbfgs     0.0010\n",
       "27  LogisticRegression(max_iter=5000)         NaN    none  lbfgs     0.0010\n",
       "28  LogisticRegression(max_iter=5000)         NaN    none   saga     0.0010"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEJCAYAAACpATGzAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAA7iUlEQVR4nO3de1yUZfr48c+AkifUBIcBJNLAzVU8ZKa0JokhGiIIImvmll8PZeVh3bX10JqhoJtZadqBbMstc/GQoowWShtgZWoleCKPJCDMqKiopcAwvz/4NTYKzKgM88x4vX09r5fPzHXB/dwvnWvu53DfKqPRaEQIIYSoZy72boAQQgjnJAVGCCGETUiBEUIIYRNSYIQQQtiEFBghhBA2IQVGCCGETUiBEUIIJ5OVlUV4eDhhYWEkJyff8L7RaGT+/PmEhYURGRnJgQMHALh69SrDhw9n6NChREREsHTpUlPOW2+9xSOPPEJUVBRRUVFkZmZabEej+jskIYQQ9mYwGEhISODDDz/Ey8uL4cOHExoaSkBAgCkmKyuL/Px80tPTycnJYe7cuaxduxY3NzdWrlxJ8+bNqaio4IknnqBfv350794dgKeffpqxY8da3RYpMEI4sUZuvvZuwh2hsrzotvIrzhy3OraxZ4c638/NzcXf3x8/Pz8AIiIiyMjIMCswGRkZREdHo1Kp6N69O2VlZej1etRqNc2bNwegsrKSyspKVCrVLRxRNTlFJoQQTkSn06HRaEz7Xl5e6HS6OmM0Go0pxmAwEBUVxcMPP8zDDz9Mt27dTHGrVq0iMjKSmTNncuHCBYttkQIjhBD2VmWwektJSSEmJsa0paSkmP2ommb/un4UUleMq6srqampZGZmkpuby+HDhwEYOXIk27ZtIzU1FbVazcKFCy0elpwiE0IIezNUWh0aHx9PfHx8re9rNBpKSkpM+zqdDrVaXWdMSUnJDTEtW7akd+/eZGdn07FjRzw9PU3vxcXF8eyzz1psq4xghBDCzozGKqs3S4KCgsjPz6egoIDy8nK0Wi2hoaFmMaGhoWzcuBGj0cjevXtxd3dHrVZTWlpKWVkZAFeuXOGbb76hQ4fqaz56vd6Uv337dgIDAy22RUYwQghhb1WWC4e1GjVqxJw5cxg3bhwGg4HY2FgCAwNZvXo1UH2qKyQkhMzMTMLCwmjatClJSUlAdRGZMWMGBoMBo9HIoEGD6N+/PwCLFi0iLy8PAF9fXxISEiy2RSXT9QvhvOQusoZxu3eRlRfkWB3r5tfNcpBCyCkyIYTNhA98lAP7s8g7uIMXpz9fY8wbryeQd3AHP3y/jR7du1jMjY0dQs7eLym/UkDPB7ra/BgaxE1c5HckUmCEEDbh4uLC0iWJDIl8kqBu/YmPj6ZTJ/Pz9oMHhRIY0J77/9iXiRP/wfJlCyzmHjiQR9yI8WRn72zwY7IZY5X1mwORazBCCJt4qFcPjh3L58SJkwCsWZPK0MhwDh06YoqJjAzn41XrAPhu1w+0at0KjUbNvf5+tebm5R1t+IOxMeNN3EXmSByywBQWFjJ+/Hh69uzJjz/+iJeXF2+//TabNm0iJSWFiooK/P39efXVV2natCkzZsygRYsW7N+/n9OnTzN9+nQGDRpk78MQwqn5+GooKDxl2i8sKuahXj3MYnx9NBQWXIspKizG10djVa5TqceL/ErisKfIfv75Z0aNGoVWq8Xd3Z0vvviCsLAw1q9fz6ZNm+jQoQPr1q0zxev1ej799FPee+89Fi9ebMeWC3FnqGmKkevvKaotxppcpyKnyJSlXbt2dOrUCYDOnTtTVFTEkSNHePPNN7l48SKXL1+mb9++pvjHHnsMFxcXAgICOHPmjL2aLcQdo6iwGL92Pqb9dr7eFBebT1lSWFRMO79rMb7tvDlVrMPNzc1irlNxsIv31nLYEYybm5vp766urhgMBmbMmMGcOXPYvHkzL7zwAuXl5TXGCyFsb/eevQQEtOfee/1o3LgxI0ZEsTkt3SwmLS2d0aOGA9D7oQcou1BGSYneqlynIiMY5bt8+TJt27aloqKCzZs34+XlZe8mCXHHMhgMTJn6Elu0n+Lq4sJHK1M4ePAwE8aPBiD5/Y/ZsjWDQYNC+enQ1/zy66+MGzetzlyAqKhBLHljPm3btmFT6n/IyTnA40NG2e0464Vc5Fe+KVOmEBcXh6+vLx07duTy5cv2bpIQd7Stn3/J1s+/NHst+f2PzfYnT5ltdS5AaurnpKZ+Xn+NVAInvcgvT/IL4cTkSf6GcbtP8l/J2WJ1bJNuj9/W72pITjWCEUIIh+Rg11asJQVGCCHszUlPkUmBEUIIe5MRjBBCCJswVNi7BTYhBUYIIexNTpHdWSrOHLd3E4S4bb+eyqapzyP2boawRE6RCSEc0e3eQisagIxghBBC2IQUGCGEELZglIv8QgghbEKuwQghhLAJOUUmhBDCJmQEIxrSjp17WPjmuxiqqoiNHMS40SPM3jcajSx4812yv91NkyZ3kTj7b/zxDwFcvVrOU89Pp7yiAkOlgbD+fXlhXPX06Ms/+IT1mz7n7tatAJjyzFP0e/ihBj82pZA+FoohI5j6k5WVRWJiIlVVVcTFxTFhwgSz941GI4mJiWRmZtKkSRMWLlxI586d68w9f/48f/3rXykqKsLX15c333yTVq1ace7cOSZPnsz+/fsZNmwYc+bMafDjvVkGg4H5i5fz/ptJaNSexI+bQv++vbmvvb8pJvvb3ZwsPMWWlA/IPZDHvNeWsfr9N3Fza8y/ly6kWbOmVFRW8peJf+eRPg/SrUv16p+j46MZ88Rwex2aYkgfC0Wp5xHMrX7GXr16lVGjRlFeXo7BYCA8PJzJkycDtX/G1qXBV7Q0GAwkJCSwYsUKtFotaWlpHD161CwmKyuL/Px80tPTmTdvHnPnzrWYm5ycTHBwMOnp6QQHB5OcnAzAXXfdxZQpU3jxxRcb9Dhvx75Dh7mnnQ9+vt40btyYwQNC+DJ7p1nM/3bsZOigAahUKrp16cTFi5c4faYUlUpFs2ZNAaisrKSysrLG9c3vdNLHQlEqK63fLLidz1g3NzdWrlzJpk2b2LhxI9nZ2ezduxeo/TO2Lg1eYHJzc/H398fPzw83NzciIiLIyMgwi8nIyCA6OhqVSkX37t0pKytDr9fXmftbDkB0dDTbt28HoFmzZjz44IPcddddDXqct0N/+gwadVvTvpfaE/3ps2YxutNn0ag9zWJ0p88A1f/AYp96nn5DRhLcqwddO99vilu9fjPD/jKRl5Je50LZRRsfiXJJHwtFqcclk2/nM1alUtG8eXPgxi9PtX3G1qXBC4xOp0Oj0Zj2vby80Ol0dcZoNBp0Ol2duWfPnkWtVgOgVqspLS215WHYVE1LwF3/BbmmdeJ++4fg6urK+pXLydjwMfsOHubI8XwA4odFsHXNv1n/0XLaerRh0bL367vpDkP6WChKVZXVW0pKCjExMaYtJSXF7EfdzmcsVH95ioqK4uGHH+bhhx+mW7duwK19xjZ4ganrP62lGGtynYGX2pMS/WnTvk5/hraeHmYxGrUnJfozZjHq62Jaureg1wNd2bFzDwCebe7G1dUVFxcXhg8dzP7/v8b5nUj6WCjKTYxg4uPj+eyzz0xbfHy8+Y+6jc9YqP7ylJqaSmZmJrm5uRw+fOv/hhu8wGg0GkpKSkz7Op3OVBVriykpKUGtVteZ6+HhgV6vB0Cv19OmTRtbHoZNdbm/IycLT1F4qoSKigq2ZmTSv28fs5hH+/Zh0+cZGI1GcvYfokWL5rT1bEPpufOUXbwEwJWrV9m5+0fa+/sBcPrMtW8cGZnfENDBnzuV9LFQlJsYwVhyO5+xv9eyZUt69+5NdnY2cGufsQ1+F1lQUBD5+fkUFBTg5eWFVqtl8eLFZjGhoaF88sknREREkJOTg7u7O2q1mjZt2tSaGxoaysaNG5kwYQIbN25kwIABDX1o9aZRI1dm/XUiz0x7CYPBwLAhAwno4E/KBi1QfRqmX3Avsr/dzeAR/0fTJk2YN+uvAJw+e47Z81/DUFWFscpIeOgjPPqn3gAsfvsDfjpyHFTgq/Hi5Rcn2+0Y7U36WChKPd5FdjufsaWlpTRq1IiWLVty5coVvvnmG8aPH2/KudnPWJWxprGSjWVmZpKUlFR9oTQ2lokTJ7J69WoARo4cidFoJCEhgezsbJo2bUpSUhJBQUG15gKcO3eOqVOnUlxcjLe3N0uWLKF169ZAdcdcunSJiooK3N3d+fe//01AQECdbZTp+oWzaOzZwd5NEBb8uibB6timIyw/anGrn7F5eXnMmDEDg8GA0Whk0KBBvPDCC0Ddn7G1sUuBcQRSYISzkAKjfL+mvGJ1bNP4l23YkvolT/ILIYS9yZP8QgghbEIKjBBCCJuQyS6FEELYhMFg7xbYhBQYIYSwNzlFJoQQwiakwAghhLAJuQYjhBDCFoxVzvk4ohQYIYSwNzlFJoQQwibkLjIhhBA2ISMY0ZB27NzDwjffxVBVRWzkIMaNHmH2vtFoZMGb75L97W6aNLmLxNl/449/CODq1XKeen465RUVGCoNhPXvywvjRgOw/INPWL/pc+5uXb2O9pRnnqLfww81+LEphfSxUAwpMA0jKyuLxMREqqqqiIuLY8KECWbvG41GEhMTyczMpEmTJixcuJDOnTvXmbt161aWLVvGsWPHWLt2rWlmZqUyGAzMX7yc999MQqP2JH7cFPr37c197a+tLZL97W5OFp5iS8oH5B7IY95ry1j9/pu4uTXm30sX0qxZUyoqK/nLxL/zSJ8H6dalEwCj46MZ88Rwex2aYkgfC0Vx0jmHG3zBsboYDAYSEhJYsWIFWq2WtLQ0jh49ahaTlZVFfn4+6enpzJs3j7lz51rM7dixI2+99Ra9evVq6EO6JfsOHeaedj74+XrTuHFjBg8I4cvsnWYx/9uxk6GDBqBSqejWpRMXL17i9JlSVCoVzZo1BW5cU1tcI30sFKUeFxxTEkUVmNzcXPz9/fHz88PNzY2IiAgyMjLMYjIyMoiOjkalUtG9e3fKysrQ6/V15t5333106OA4U5brT59Bo25r2vdSe6I/fdYsRnf6LBq1p1mM7nT18r4Gg4HYp56n35CRBPfqQdfO95viVq/fzLC/TOSlpNe5UHbRxkeiXNLHQlGqjNZvDkRRBUan06HRaEz7Xl5e6HS6OmM0Gg06nc6qXEdR02j5+i/IltbUXr9yORkbPmbfwcMcOZ4PVK/SuHXNv1n/0XLaerRh0bL367vpDkP6WCiKwWD95kAUVWDq+g9tKcaaXEfhpfakRH/atK/Tn6Gtp4dZjEbtSYn+jFmM+rqYlu4t6PVAV3bs3AOAZ5u7cXV1xcXFheFDB7P/4GEbHoWySR8LJTFWVVm9ORJFFRiNRkNJSYlpX6fToVar64wpKSlBrVZblesoutzfkZOFpyg8VUJFRQVbMzLp37ePWcyjffuw6fMMjEYjOfsP0aJFc9p6tqH03HnKLl4C4MrVq+zc/SPt/f0AOH2m1JSfkfkNAR38uVNJHwtFcdJTZIq6iywoKIj8/HwKCgrw8vJCq9WyePFis5jQ0FA++eQTIiIiyMnJwd3dHbVaTZs2bSzmOopGjVyZ9deJPDPtJQwGA8OGDCSggz8pG7RA9WmYfsG9yP52N4NH/B9NmzRh3qy/AnD67Dlmz38NQ1UVxioj4aGP8OifegOw+O0P+OnIcVCBr8aLl1+cbLdjtDfpY6EoTjoXmcpY07klO8rMzCQpKan6ImpsLBMnTmT16tUAjBw5EqPRSEJCAtnZ2TRt2pSkpCTTbcc15QJs27aNefPmUVpaSsuWLenUqRMffPBBne2oOHPctgcqRANp7Ok4N7jcqS4njLI6tvmcVTZsSf1SXIFRCikwwllIgVG+y3P+bHVs84T/2rAl9UtRp8iEEOKO5KSnyKTACCGEvTnYxXtrKeouMiGEuBPV923KWVlZhIeHExYWRnJy8o2/z2hk/vz5hIWFERkZyYEDBwAoLi5m9OjRDB48mIiICFauXGnKeeutt3jkkUeIiooiKiqKzMxMi+2QEYwQQthbPY5gfps268MPP8TLy4vhw4cTGhpKQECAKeb3U27l5OQwd+5c1q5di6urKzNmzKBz585cunSJ2NhY/vSnP5lyn376acaOHWt1W2QEI4QQ9laPz8HczpRbarXaNHlwixYt6NChw23NiCIjGCGEsLebmAImJSWFlJQU0358fDzx8fGm/ZqmzcrNzTX7GbVNufX7h9MLCws5dOgQ3bp1M722atUqNm7cSJcuXZgxYwatWrWqs61SYIQQws6MN3GK7PqCcsPPuo0pt35z+fJlJk+ezKxZs2jRogVQ/Rzic889h0qlYsmSJSxcuJAFCxbU2VY5RSaEEPZWj6fIbmfKLYCKigomT55MZGQkAwcONMV4enqa5tmLi4tj3759FtsiBUYIIeytHteD+f2UW+Xl5Wi1WkJDQ81iQkND2bhxI0ajkb1795qm3DIajcyePZsOHTowZswYsxy9Xm/6+/bt2wkMDLTYFjlFJoQQ9laPd5E1atSIOXPmMG7cONO0WYGBgWZTboWEhJCZmUlYWJhpyi2A77//ntTUVDp27EhUVBQA06ZNIyQkhEWLFpGXlweAr68vCQkJFtsiU8XUQqaKEc5CpopRvovPDrI61v3dz23YkvolIxghhLAzo0GmihENaMfOPSx8810MVVXERg5i3OgRZu8bjUYWvPku2d/upkmTu0ic/Tf++IcArl4t56nnp1NeUYGh0kBY/768MG40AMs/+IT1mz7n7tbVtxZOeeYp+j38UIMfm1JIHwvFcNKpYhymwGRlZZGYmEhVVRVxcXFMmDDB7H2j0UhiYiKZmZk0adKEhQsXmh4YmjlzJl999RUeHh6kpaXZo/k3xWAwMH/xct5/MwmN2pP4cVPo37c397W/tnhV9re7OVl4ii0pH5B7II95ry1j9ftv4ubWmH8vXUizZk2pqKzkLxP/ziN9HqRbl04AjI6PZswTw+11aIohfSyU5GZuU3YkDnEX2W9TH6xYsQKtVktaWhpHjx41i/n91Afz5s1j7ty5pvdiYmJYsWJFA7f61u07dJh72vng5+tN48aNGTwghC+zd5rF/G/HToYOGoBKpaJbl05cvHiJ02dKUalUNGvWFIDKykoqKysdduloW5I+ForipCtaOkSBuZ2pDwB69epl8YlTJdGfPoNG3da076X2RH/6rFmM7vRZNGpPsxjd6er14w0GA7FPPU+/ISMJ7tWDrp3vN8WtXr+ZYX+ZyEtJr3Oh7KKNj0S5pI+FolTdxOZAHKLA1DT1wfXz49Q29YEjqum+vuu/INf1JK6rqyvrVy4nY8PH7Dt4mCPH84HqZYC3rvk36z9aTluPNixa9n59N91hSB8LJTFWVlm9ORKHKDD1MfWBI/FSe1KiP23a1+nP0NbTwyxGo/akRH/GLEZ9XUxL9xb0eqArO3buAcCzzd2mJ3GHDx3M/oOHbXgUyiZ9LBRFRjD2c7tTHziaLvd35GThKQpPlVBRUcHWjEz69+1jFvNo3z5s+jwDo9FIzv5DtGjRnLaebSg9d56yi5cAuHL1Kjt3/0h7fz8ATp8pNeVnZH5DQAd/7lTSx0JJjFVGqzdH4hB3kf1+6gMvLy+0Wi2LFy82iwkNDeWTTz4hIiKCnJwc09QHjqhRI1dm/XUiz0x7CYPBwLAhAwno4E/KBi1QfRqmX3Avsr/dzeAR/0fTJk2YN+uvAJw+e47Z81/DUFWFscpIeOgjPPqn3gAsfvsDfjpyHFTgq/Hi5Rcn2+0Y7U36WCiKg41MrOUwT/JnZmaSlJRkmvpg4sSJZlMfGI1GEhISyM7ONk19EBQUBFRPdbBr1y7OnTuHh4cHkyZNIi4urs7fJ0/yC2chT/IrX+mwEKtj22ywvJKkUjhMgWloUmCEs5ACo3ylUTdRYFIdp8A4xCkyIYRwZsZKe7fANqTACCGEnRmd9BqMFBghhLA3KTBCCCFsQUYwQgghbEIKzB3mvo5R9m6CUzv6w4f2bsKdQ+4iUzyjwTFnHbFECowQQtiZjGCEEELYhLFKRjBCCCFsQEYwQgghbMJolBGMEEIIG5ARjBBCCJuoctK7yBxiPZg7UciAP/G/7zaRtUfLc1PG1hjzyoIZZO3R8kX2erp07WR17oQXnuJk6T7ubtPaVs13CDt25xA59u88/vQ0VqRsuuF9o9HIgrdX8vjT04h5dgYHj5wA4Gp5OSMn/ZPYZ2cSPf5Flv9n3Q25H63VEhQ+inMXZMlkYZmxSmX1Zo2srCzCw8MJCwsjOTn5xt9nNDJ//nzCwsKIjIzkwIEDABQXFzN69GgGDx5MREQEK1euNOWcP3+eMWPGMHDgQMaMGcOFCxcstsPhC4yljjx27Bjx8fF06dKFDz74wA4tvHkuLi7Mf3U2T414jgHBUQyNHUzgH8yfZej/2CPce58//R6MYMZfXyFx8UtW5Xr7evHIo8EUFpxq0GNSGoOhisTlH/H2/BdJff9Vtv7vW479XGgWk707h5+LStB+uJiXp4xl/lvVz+64NW7MB6/OZv27C1j7ThJf78kl59ARU16J/izf/rgPb7X56pdC1KY+C4zBYCAhIYEVK1ag1WpJS0vj6NGjZjFZWVnk5+eTnp7OvHnzmDt3LlC9FPiMGTPYunUrKSkpfPrpp6bc5ORkgoODSU9PJzg4uMbP2+s5dIGxpiNbt27N7NmzGTu25lGAEnXvGUT+iZOc/LmQiopKNn+2lYGD+5vFDHy8P+v/W/2t+8c9ubRs6Y7ay9Ni7suJL5L08us1LjF9J9n30zHu8fHCz1tN48aNGPxoH/737fdmMf/79nuGPvYIKpWKbp0CuXj5F06fPYdKpaJZ0yYAVFYaqDQYzJbnfvW9j5k2dqTDLtktGp7RaP1mSW5uLv7+/vj5+eHm5kZERAQZGRlmMRkZGURHR6NSqejevTtlZWXo9XrUajWdO3cGoEWLFnTo0AGdTmeWAxAdHc327dsttsWhC4w1Henh4UHXrl1p1MhxLjdpvNWcKrq2/HPxKR1e3l43xBT/LqbklA6Nt7rO3LBBj1JSrOfQAVknXn+2FE3bayMML8826M6cM485c2OM/mx1jMFQxfCJMwmJn0ifHl3oen8AUF2U1J5t+MN9slSysN7NjGBSUlKIiYkxbSkpKWY/S6fTodFoTPteXl6mIlFbjEajuSGmsLCQQ4cO0a1bNwDOnj1rWiVYrVZTWlqKJY7zqVuDmjoyNzfXji2qHzV9871hxFFjTO25TZo24YW/jefJmGfqrZ2OrKZvgtf3XY1fFv9/jKurC+veWUDZpctMfeUNjuQX0E6j5v3Vqby3YEb9N1g4tZu5TTk+Pp74+Pg6ftaN/3Jv+LdtIeby5ctMnjyZWbNm0aJFC6vbdj2HHsFY05GOqPiUDh/fa4XT28cLfYneLKbklA7v38VofLzQlehrzfW/1w+/e3z5PHsdX+/9HG8fL7Z8tYa2d+h1Ai/PNpScPmva150pRe3R2nLMdTdGtGzRnF7dOvH17lwKinUUlZxm+MSZhP9lCrrTpYx4fjZnSs/b8EiEMzAYVFZvlmg0GkpKrp3F0Ol0ppFHbTElJSWmmIqKCiZPnkxkZCQDBw40xXh4eKDXV38O6fV62rRpY7EtDl1grOlIR5Tzw37ad/DH7x5fGjduRGTMYLZ9/pVZzLat/yP2z0MB6PFgVy6WXUKvO1Nr7k+HjvDAHx7lT90H8afugyg+pePxR0dwWn+2hhY4vy5/6MDPRSUUluipqKhk61c7ebRPT7OY/n0eYNP2bIxGIzmHjtCiWVPaetxN6fkyyi5dBuDK1XJ2/nCA9n7edGx/D5lr3uGL/yzhi/8swattG9YsT8TzDr9bT1hmNKqs3iwJCgoiPz+fgoICysvL0Wq1hIaGmsWEhoayceNGjEYje/fuxd3dHbVajdFoZPbs2XTo0IExY8bUmAOwceNGBgwYYLEtDn2K7Pcd6eXlhVarZfHixfZu1m0zGAz888UkPl73Lq6urqSs2sDhvGM8+XQcAJ98tJYvt2XTP6wf2d9v4ddfr/D3F16qM1eYa+Tqyqznn+bZWf/CUFXFsIEhBNzbjjVp1RcuRwx5jEce6k7W7r08PmYaTe5yY/7fqk8vni49z0uvvYuhqgpjlZGB/XoT0ucBex6OcHD1ORdZo0aNmDNnDuPGjcNgMBAbG0tgYCCrV68GYOTIkYSEhJCZmUlYWBhNmzYlKSkJgO+//57U1FQ6duxIVFT1jPLTpk0jJCSECRMmMHXqVNatW4e3tzdLliyx2BaV0cFvJ8rMzCQpKcnUkRMnTjTryNOnTxMbG8ulS5dwcXGhWbNmbNmyxeJ5xXvaBDVE8+9YMl1/w3G790F7N0FYcCjwcatjOx3ZYsOW1C+HLzC2IgXGtqTANBwpMMp38L4Iq2P/eExrw5bUL4c+RSaEEM7AUOXQl8NrJQVGCCHszFnPI0mBEUIIO6ty0un66xyX/fzzz3z//fc3vL5nzx5Onjxps0YJIcSdpD5vU1aSOgtMUlISzZs3v+H1u+66y3RbmxBCiNtTn3ORKUmdp8iKioq4//77b3g9KCiIoqIimzVKCU5dsjzPjrh1zTpG2bsJd4zKcuf+v+oMnPUUWZ0F5urVq7W+d+XKlXpvjBBC3Imc9S6yOo8qKCiINWvW3PD62rVrTVM6CyGEuD3Gm9gcSZ0PWp45c4YXXniBxo0bmwrK/v37qaioYNmyZbRt27bBGtrQGrn52rsJQtQLOUWmfN94x1od+3Dxehu2pH7VeYrM09OT//73v+zcuZMjR6pX7AsJCSE4OLhBGieEEHcCR7s7zFpWPQfTp08f+vTpY+u2CCHEHanK3g2wEXnQUggh7MyIc45gnPPWBScQPvBRDuzPIu/gDl6c/nyNMW+8nkDewR388P02enTvYjE3NnYIOXu/pPxKAT0f6GrzY1A66WOhFJVGldWbI3H4AjNz5kyCg4MZMmRIje8bjUbmz59PWFgYkZGRHDhwoIFbePNcXFxYuiSRIZFPEtStP/Hx0XTqFGgWM3hQKIEB7bn/j32ZOPEfLF+2wGLugQN5xI0YT3b2zgY/JqWRPhZKYkRl9eZIHL7AxMTEsGLFilrfz8rKIj8/n/T0dObNm8fcuXMbrnG36KFePTh2LJ8TJ05SUVHBmjWpDI0MN4uJjAzn41XrAPhu1w+0at0KjUZdZ25e3lEOH5bFx0D6WChL1U1sjsThC0yvXr1o1apVre9nZGQQHR2NSqWie/fulJWVmdaVViofXw0FhadM+4VFxfj4aMxifH00FBZciykqLMbXR2NVrpA+FsoiIxgHpdPp0Giu/efXaDTodDo7tsgylerGf0TXP65UW4w1uUL6WCiLs45gnP4uspr+49f0AaEkRYXF+LXzMe238/WmuNi8KBYWFdPO71qMbztvThXrcHNzs5grpI+FshgcbGRiLacfwWg0GkpKSkz7JSUlqNVqO7bIst179hIQ0J577/WjcePGjBgRxea0dLOYtLR0Ro8aDkDvhx6g7EIZJSV6q3KF9LFQliqV9ZsjcfoRTGhoKJ988gkRERHk5OTg7u6u+AJjMBiYMvUltmg/xdXFhY9WpnDw4GEmjB8NQPL7H7NlawaDBoXy06Gv+eXXXxk3blqduQBRUYNY8sZ82rZtw6bU/5CTc4DHh4yy23Hak/SxUJIqJx3B1DkXmSOYNm0au3bt4ty5c3h4eDBp0iQqKysBGDlyJEajkYSEBLKzs2natClJSUkEBQVZ/LkyF5lwFjIXmfJt1DxhdWx0yac2bEn9cvgCYytSYISzkAKjfJ/dRIGJsaLAZGVlkZiYSFVVFXFxcUyYMMHsfaPRSGJiIpmZmTRp0oSFCxeaJjSeOXMmX331FR4eHqSlpZly3nrrLdasWUObNm2A6i/3ISEhdbbD6a/BCCGE0lWpVFZvlhgMBhISElixYgVarZa0tDSOHj1qFlPX84F1PVv49NNPk5qaSmpqqsXiAlJghBDC7gw3sVmSm5uLv78/fn5+uLm5ERERQUZGhllMXc8HWnq28GZIgRFCCDurz7vIrn/2z8vL64Zn/271+cBVq1YRGRnJzJkzuXDhgsV4KTBCCGFnVais3lJSUoiJiTFtKSkpZj/Lmmf/buX5wJEjR7Jt2zZSU1NRq9UsXLjQ4nE5/W3KQgihdDdzp1V8fDzx8fG1vn/9s386ne6GRzNu5flAT09P09/j4uJ49tlnLbZVRjBCCGFn9XmKLCgoiPz8fAoKCigvL0er1RIaGmoWExoaysaNGzEajezdu9eq5wN/P4fj9u3bCQwMrCO6moxghBDCzupzjrFGjRoxZ84cxo0bh8FgIDY2lsDAQFavXg1Un+oKCQkhMzOTsLAw0/OBv/n9s4X9+vVj0qRJxMXFsWjRIvLy8gDw9fUlISHBYlvkOZhayHMwwlnIczDK90G7J62OHVv4iQ1bUr9kBCOEEHbmaLMkW0sKjBBC2JkUGCGEEDZhdM65LuUuMqUKH/goB/ZnkXdwBy9Of77GmDdeTyDv4A5++H4bPbp3sZgbGzuEnL1fUn6lgJ4PdLX5MSid9LFQCmddcMwhCszMmTMJDg5myJAhptfOnz/PmDFjGDhwIGPGjKn1qdKsrCzCw8MJCwsjOTm5oZp8W1xcXFi6JJEhkU8S1K0/8fHRdOpkfkvg4EGhBAa05/4/9mXixH+wfNkCi7kHDuQRN2I82dk7G/yYlEb6WChJfU4VoyQOUWBqmnwtOTmZ4OBg0tPTCQ4OrrF4WDPpmxI91KsHx47lc+LESSoqKlizJpWhkeFmMZGR4Xy8ah0A3+36gVatW6HRqOvMzcs7yuHDxxr8eJRI+lgoibMuOOYQBaamydd+m6wNIDo6mu3bt9+QZ82kb0rk46uhoPCUab+wqBgfH41ZjK+PhsKCazFFhcX4+misyhXSx0JZ5BSZwpw9e9b05Klaraa0tPSGGGsmfVOimuYEuv5xpdpirMkV0sdCWZy1wDj1XWS3MqGbEhQVFuPXzse0387Xm+Ji88JYWFRMO79rMb7tvDlVrMPNzc1irpA+FsrirF9PHHYE4+HhYZobR6/Xm1ZZ+z1rJn1Tot179hIQ0J577/WjcePGjBgRxea0dLOYtLR0Ro8aDkDvhx6g7EIZJSV6q3KF9LFQFrkGozC/TdYGsHHjRgYMGHBDjDWTvimRwWBgytSX2KL9lP25X7Fu3WYOHjzMhPGjmTB+NABbtmZw/MRJfjr0Ne+++yovTJpVZy5AVNQg8o/voU+fnmxK/Q9b0lbZ7RjtTfpYKImz3kXmEHOR/X7yNQ8PDyZNmsRjjz3G1KlTKS4uxtvbmyVLltC6dWt0Oh0vvfQS77//PgCZmZkkJSWZJn2bOHGiVb9T5iITzkLmIlO+RP9RVsfO/tlxvrQ4RIGxBykwwllIgVG+eTdRYP7pQAXGqS/yCyGEI3DWb/lSYIQQws4c7fZja0mBEUIIO6tUOecYRgqMEELYmXOWFykwQghhd3KKTAghhE1UOekYRgqMEELYmXOWFykwQghhd3KKTAghhE0YnHQMIwVGCCHszFlHMA472aUQQjgL4038sYalpeKNRiPz588nLCyMyMhIDhw4YHqvpiXqwfpl6n9PCowQQthZfS44Zs1S8VlZWeTn55Oens68efOYO3eu6b2alqgH65apv54UGIUKH/goB/ZnkXdwBy9Of77GmDdeTyDv4A5++H4bPbp3sZgbGzuEnL1fUn6lgJ4PdLX5MSid9LFQiiqMVm+WWLNU/G9LzqtUKrp3705ZWZlpfa2alqj/fQ7Uvkz99RRVYGoamtU1LHvvvfcICwsjPDyc7OzsGn/mrQzr7M3FxYWlSxIZEvkkQd36Ex8fTadOgWYxgweFEhjQnvv/2JeJE//B8mULLOYeOJBH3IjxZGfvbPBjUhrpY6EkxpvYLLFmqfjrYzQajcXl5K1Zpv56iiowNQ3NahuWHT16FK1Wi1arZcWKFbzyyisYDDcux3Mrwzp7e6hXD44dy+fEiZNUVFSwZk0qQyPDzWIiI8P5eNU6AL7b9QOtWrdCo1HXmZuXd5TDh481+PEokfSxUJJKjFZvKSkpxMTEmLaUlBSzn2XNUvENtZy8ogpMTUOz2oZlGRkZREREVK+P7ueHv78/ubm5N/zMWxnW2ZuPr4aCwlOm/cKiYnx8NGYxvj4aCguuxRQVFuPro7EqV0gfC2W5mYv88fHxfPbZZ6YtPj7e7GdZs1T89TElJSUWl5O3Zpn66ymqwNSktmGZNcPAuvKVrKZvEtd/46gtxppcIX0slKU+L/Jbs1T8b0vOG41G9u7di7u7u8UCY80y9ddz2OdgGmqIZw9FhcX4tfMx7bfz9aa42Lx4FhYV087vWoxvO29OFeuqR3QWcoX0sVAWa28/tkajRo2YM2cO48aNMy0VHxgYyOrVqwEYOXIkISEhZGZmEhYWRtOmTUlKSjLl/36J+n79+jFp0iTi4uKYMGECU6dOZd26daZl6i22pd6OykZ+G5ap1WqzYZk1w8C68pVs9569BAS05957/SgqKmHEiChG/8X8Lqe0tHSem/g0KSmp9H7oAcoulFFSouf06bMWc4X0sVCW+n7QMiQkhJCQELPXRo4cafq7SqXi5ZdfrjH39ddfr/H1u+++m5UrV95UOxR/iqy2YVloaCharZby8nIKCgrIz8+na9cbbwu9lWGdvRkMBqZMfYkt2k/Zn/sV69Zt5uDBw0wYP5oJ40cDsGVrBsdPnOSnQ1/z7ruv8sKkWXXmAkRFDSL/+B769OnJptT/sCXNcdb2rm/Sx0JJDEaj1ZsjURkVdPL490MzDw8PJk2axGOPPcbUqVMpLi42Dctat24NwDvvvMP69etxdXVl1qxZpoo9e/Zs/vznPxMUFMS5c+dqza9LIzdfGx6pEA2nsrzI3k0QFjzhP8zq2E9/3mDDltQvRRUYJZECI5yFFBjlG+kfbXXs6p832qwd9U3x12CEEMLZOetkl1JghBDCzmRFSyGEEDZRn7cpK4kUGCGEsDNHuzvMWlJghBDCzuQUmRBCCJuQi/xCCCFsQq7BCCGEsAk5RSaEEMImnPV5dykwQghhZwYZwQghhLAFOUUmhBDCJpz1FJnip+u/U4UPfJQD+7PIO7iDF6fXvNbIG68nkHdwBz98v40e3btYzI2NHULO3i8pv1JAzwduXNrgTiN9LJSiCqPVmyOxS4GZOXMmwcHBDBkyxPTa+fPnGTNmDAMHDmTMmDFcuHDB9N57771HWFgY4eHhZGdnm17fv38/kZGRhIWFMX/+/Fq/BdSWr1QuLi4sXZLIkMgnCerWn/j4aDp1CjSLGTwolMCA9tz/x75MnPgPli9bYDH3wIE84kaMJzt7Z4Mfk9JIHwslMd7EH0dilwITExPDihUrzF5LTk4mODiY9PR0goODSU5OBuDo0aNotVq0Wi0rVqzglVdewWAwADB37lwSEhJIT08nPz+frKysG35XXflK9VCvHhw7ls+JEyepqKhgzZpUhkaGm8VERobz8ap1AHy36wdatW6FRqOuMzcv7yiHDx9r8ONRIuljoSTOuuCYXQpMr169aNWqldlrGRkZREdHAxAdHc327dtNr0dERFSvg+7nh7+/P7m5uej1ei5dukSPHj1QqVRER0eTkZFxw++qLV/JfHw1FBSeMu0XFhXj46Mxi/H10VBYcC2mqLAYXx+NVblC+lgoi5wis7GzZ8+iVqsBUKvVlJaWAqDT6dBorv3n9fLyQqfT3fC6RqNBp9Pd8HNry1cylUp1w2vXn/6rLcaaXCF9LJTFWQuM4u8iq+k/rkqlqvV1a/OVrKiwGL92Pqb9dr7eFBebF8XComLa+V2L8W3nzaliXfVIzUKukD4WyuKsX1AUM4Lx8PBAr9cDoNfradOmDVA9MikpKTHF6XQ61Gr1Da+XlJSYRkC/V1u+ku3es5eAgPbce68fjRs3ZsSIKDanpZvFpKWlM3rUcAB6P/QAZRfKKCnRW5UrpI+FsjjrCEYxBSY0NJSNGzcCsHHjRgYMGGB6XavVUl5eTkFBAfn5+XTt2hW1Wk3z5s3Zu3cvRqPRLOf6n1tTvpIZDAamTH2JLdpP2Z/7FevWbebgwcNMGD+aCeNHA7BlawbHT5zkp0Nf8+67r/LCpFl15gJERQ0i//ge+vTpyabU/7AlbZXdjtHepI+FkjjrXWQqox3GZtOmTWPXrl2cO3cODw8PJk2axGOPPcbUqVMpLi7G29ubJUuW0Lp1awDeeecd1q9fj6urK7NmzSIkJASAffv2MXPmTK5cuUK/fv345z//iUqlIiMjg/379zNlypQ68+vSyM3XZscvREOqLC+ydxOEBQ9497U69ofiHRZjsrKySExMpKqqiri4OCZMmGD2vtFoJDExkczMTJo0acLChQvp3LlznblvvfUWa9asMZ1dmjZtmsXPUrsUGEcgBUY4CykwytdD8yerY38s+brO9w0GA+Hh4Xz44Yd4eXkxfPhwXn/9dQICAkwxmZmZfPzxx7z//vvk5OSQmJjI2rVr68x96623aNasGWPHjrW6rYo5RSaEEHeq+rwGk5ubi7+/P35+fri5uREREXHDIxy/PRaiUqno3r07ZWVl6PV6q3JvhhQYIYSws5u5BpOSkkJMTIxpS0lJMftZ1jyaUdtjHpZyV61aRWRkJDNnzjSbbaU2ir9NWQghnF3VTVypiI+PJz4+vtb3rXk041Ye/xg5ciTPPfccKpWKJUuWsHDhQhYsWFBnW2UEI4QQdlafd5FZ82hGbY951JXr6emJq6srLi4uxMXFsW/fPottkQIjhBB2ZjBWWb1ZEhQURH5+PgUFBZSXl6PVagkNDTWL+e2xEKPRyN69e3F3d0etVteZ+9tzigDbt28nMNB8ctiayCkyIYSws5s5RWZJo0aNmDNnDuPGjcNgMBAbG0tgYCCrV68Gqk91hYSEkJmZSVhYGE2bNiUpKanOXIBFixaRl5cHgK+vLwkJCRbbIrcp10JuUxbOQm5TVr7Atj2tjj1y+nsbtqR+yQhGCCHsrD5HMEoiBUYIIezM0aaAsZYUGCGEsDODUdmLIN4qKTBCCGFnznopXG5TVqjwgY9yYH8WeQd38OL052uMeeP1BPIO7uCH77fRo3sXi7mxsUPI2fsl5VcK6PmAsmeUbgjSx0IpZLr+mzRz5kyCg4MZMmSI6bXz588zZswYBg4cyJgxY8ymGnjvvfcICwsjPDyc7Oxs0+v79+8nMjKSsLAw5s+fb6r05eXlTJ06lbCwMOLi4igsLKyxHbXlK5mLiwtLlyQyJPJJgrr1Jz4+mk6dzO85HzwolMCA9tz/x75MnPgPli9bYDH3wIE84kaMJzt7Z4Mfk9JIHwslMRqNVm+OxGYFJiYmhhUrVpi9lpycTHBwMOnp6QQHB5OcnAzA0aNH0Wq1aLVaVqxYwSuvvILBUH1Ocu7cuSQkJJCenk5+fj5ZWVkArF27lpYtW7Jt2zaefvppXnvttRrbUVu+kj3UqwfHjuVz4sRJKioqWLMmlaGR4WYxkZHhfLxqHQDf7fqBVq1bodGo68zNyzvK4cPHGvx4lEj6WChJldFo9eZIbFZgevXqRatWrcxe+20GT4Do6Gi2b99uej0iIqJ6KVo/P/z9/cnNzUWv13Pp0iV69OiBSqUiOjraNLPnl19+ybBhwwAIDw/n22+/vaG615WvZD6+GgoKT5n2C4uK8fHRmMX4+mgoLLgWU1RYjK+PxqpcIX0slMVZFxxr0GswZ8+eNc1ro1arKS0tBWqf/bO2GT9/y/H29gaqnz51d3fn3LlzZr+vrnwlu35iOrjxImBtMdbkCuljoSz1OVWMkijiLrJbmdnzdmYMVbqiwmL82vmY9tv5elNcbF4YC4uKaed3Lca3nTeninXVo0ALuUL6WCiLs35BadARjIeHh2nCNL1eb1p6s7YZPGub8fO3nOLiYgAqKyu5ePGiaYnl39SVr2S79+wlIKA9997rR+PGjRkxIorNaelmMWlp6YweNRyA3g89QNmFMkpK9FblCuljoSxyDaYe/DaDJ8DGjRsZMGCA6XWtVkt5eTkFBQXk5+fTtWtX1Go1zZs3Z+/evRiNxhtyNmzYAMAXX3xBnz59bhid1JWvZAaDgSlTX2KL9lP2537FunWbOXjwMBPGj2bC+NEAbNmawfETJ/np0Ne8++6rvDBpVp25AFFRg8g/voc+fXqyKfU/bElbZbdjtDfpY6EkznoXmc0mu5w2bRq7du3i3LlzeHh4MGnSJB577DGmTp1KcXEx3t7eLFmyxDTqeOedd1i/fj2urq7MmjWLkJAQAPbt28fMmTO5cuUK/fr145///CcqlYqrV68yffp0Dh06RKtWrXjjjTfw8/MDICoqitTU1DrzLZHJLoWzkMkula9Vi/usjr1wyXHuUpTZlGshBUY4CykwyteyeQerY8suH7dhS+qXIi7yCyHEnczR7g6zlhQYIYSwM0e7eG8tKTBCCGFnznqlQgqMEELYmaM9oW8tKTBCCGFnMoIRQghhE856DUZuUxZCCGETsuCYEEIIm5ACI4QQwiakwAghhLAJKTBCCCFsQgqMEEIIm5ACI4QQwiakwDiwHj16mP4+duxYHnzwQZ555hk7tsj5/NbHhw4dIj4+noiICCIjI9myZYudWyaE8smDlk5i3Lhx/Prrr6SkpNi7KU6pSZMm/Otf/+Lee+9Fp9MRGxtL3759admypb2bJoRiSYFxEsHBwXz33Xf2bobTat++venvXl5etGnThtLSUikwVigsLGT8+PH07NmTH3/8ES8vL95++21OnDjByy+/zK+//so999xDUlISrVq1YvTo0XTt2pXvvvuOixcvkpiYyIMPPojBYOC1115j165dlJeXM2rUKP785z/b+/BEHeQUmRA3KTc3l4qKCu655x57N8Vh/Pzzz4waNQqtVou7uztffPEFL774In//+9/ZvHkzHTt2ZNmyZaZ4g8HAunXrmDVrlun1devW4e7uzvr161m/fj1r1qyhoKDAXockrCAjGCFugl6vZ/r06fzrX//CxUW+n1mrXbt2dOrUCYDOnTtTUFDAxYsXeeihhwAYNmwYU6ZMMcWHhYWZYouKqlfk/Prrr/npp5/44osvALh48SI///yzaal0oTxSYISw0qVLl3jmmWeYOnUq3bt3t3dzHIqbm5vp766urpSVlVkV7+LigsFgAKpnHH7ppZd45JFHbNdQUa/kK5gQVigvL+f5558nKiqKwYMH27s5Ds/d3Z2WLVuyZ88eAFJTU+nVq1edOX379mX16tVUVFQAcOLECX755Rebt1XcOhnBOIknnniC48eP88svv9CvXz8SExPlm1492rp1K3v27OH8+fNs2LABgIULF5pO+4ib969//ct0kd/Pz48FCxbUGR8XF0dRURExMTEYjUbuvvtu3n777QZqrbgVMl2/EEIIm5BTZEIIIWxCCowQQgibkAIjhBDCJqTACCGEsAkpMEIIIWxCCowQ9aCwsJAhQ4YA1TMvZ2Zm2rlFQtifFBgh6pkUGCGqSYERd4TCwkIGDRrEP/7xDyIjI5k8eTK//vor+/fv58knnyQmJoaxY8ei1+sBGD16NIsWLWL48OGEh4ebnjgvLCzkiSeeYNiwYQwbNowffvjB7PeUl5ezdOlStmzZQlRUFFu2bGHgwIGUlpYCUFVVRVhYmGlfCGcmBUbcMU6cOMGIESPYvHkzzZs3Z9WqVcyfP5+lS5fy2WefERsbyxtvvGGKr2lGXw8PDz788EM2bNjAG2+8wfz5881+h5ubG5MnT+bxxx8nNTWVxx9/nKFDh7Jp0yYAvvnmG+6//37atGnTcAcuhJ3IVDHijuHt7U3Pnj0BGDp0KO+99x6HDx9mzJgxQPXoom3btqb4mmb0raysJCEhgby8PFxcXMjPz7f4e2NjY3nuued4+umnWb9+PTExMfV8ZEIokxQYccdQqVRm+82bNycwMLDWVUBrmtH3o48+wtPTk9TUVKqqqujatavF3+vt7Y2HhwfffvstOTk5vPbaa7d5JEI4BjlFJu4Yp06d4scffwRAq9XSrVs3SktLTa9VVFRw5MiROn/GxYsXadu2LS4uLqSmppoKz+81b96cy5cvm70WFxfH9OnTGTx4MK6urvV0REIomxQYcce477772LBhA5GRkVy4cIHRo0ezdOlSXnvtNYYOHUp0dLSp2NTmiSeeYMOGDYwYMYL8/HyaNWt2Q0zv3r05evSo6SI/QGhoKL/88oucHhN3FJlNWdwRCgsLefbZZ0lLS7PL79+3bx8LFizg008/tcvvF8Ie5BqMEDaWnJzM6tWrWbRokb2bIkSDkhGMEEIIm5BrMEIIIWxCCowQQgibkAIjhBDCJqTACCGEsAkpMEIIIWxCCowQQgib+H+1u0Viy2FTYAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = pd.DataFrame( best_model.cv_results_['params'] )\n",
    "\n",
    "results['score_acc'] = 1 - best_model.cv_results_['mean_test_accuracy']\n",
    "\n",
    "cols = results.columns.to_series().str.split('__').apply(lambda x: x[-1])\n",
    "results.columns = cols\n",
    "\n",
    "# Heat map\n",
    "sns.heatmap( results.query('solver==\"saga\"').pivot('C','penalty','score_acc'),\n",
    "             annot=True, fmt='.3f')\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "derived-virtue",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets another 5000 random samples\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_p, Y_p, train_size = 5000, random_state = 4)\n",
    "\n",
    "# Grid Search\n",
    "pipe = Pipeline([('classifier', LogisticRegression())])\n",
    "\n",
    "search_space = [{'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['saga'],\n",
    "                 'classifier__penalty': ['l1', 'l2'],\n",
    "                 'classifier__C': np.logspace(-4, 4, 9)},\n",
    "                {'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['lbfgs'],\n",
    "                 'classifier__penalty': ['l2'],\n",
    "                 'classifier__C': np.logspace(-4, 4, 9)},\n",
    "                {'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['lbfgs','saga'],\n",
    "                 'classifier__penalty': ['none']}]\n",
    "                \n",
    "clf = GridSearchCV(pipe, search_space, cv=StratifiedKFold(n_splits=5), \n",
    "                   scoring=['accuracy', 'roc_auc_ovr', 'f1_micro'], refit=False,\n",
    "                   verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "cutting-vancouver",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "romantic-dubai",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([8.79807472e-03, 3.80117893e-02, 4.21433449e-03, 1.44897461e-02,\n",
       "        6.24480247e-03, 1.19880199e-02, 1.84023380e-02, 2.15517998e-02,\n",
       "        2.20106602e-02, 2.63590813e-02, 1.09934330e-01, 9.71488953e-02,\n",
       "        3.49275351e-01, 3.57771921e-01, 6.85887480e-01, 2.81907701e-01,\n",
       "        7.10621786e-01, 5.79707050e-01, 7.42375445e+00, 4.69340639e+00,\n",
       "        5.60879254e+00, 8.67295914e+00, 1.10508671e+01, 1.56095476e+01,\n",
       "        1.92277944e+01, 2.83326004e+01, 4.65309328e+01, 1.69901748e+01,\n",
       "        8.40160513e-01]),\n",
       " 'std_fit_time': array([1.46896008e-03, 4.32837025e-02, 7.17524110e-05, 1.06358764e-03,\n",
       "        3.83467171e-04, 6.17823106e-04, 3.12727585e-03, 4.07904242e-03,\n",
       "        2.48881969e-03, 1.39684806e-03, 2.75485847e-02, 6.55908496e-03,\n",
       "        3.35033948e-02, 3.18701847e-02, 8.32289293e-02, 5.51666372e-02,\n",
       "        4.10289440e-02, 6.10813560e-02, 4.26243419e-01, 2.24150578e-01,\n",
       "        3.64650944e-01, 6.39827646e-01, 1.08233478e+00, 5.04401431e-01,\n",
       "        1.69126035e+00, 6.30791806e+00, 1.13213434e+01, 1.18826021e+00,\n",
       "        5.33389444e-02]),\n",
       " 'mean_score_time': array([0.01145306, 0.00646024, 0.00567131, 0.00627098, 0.00535154,\n",
       "        0.0054462 , 0.00743051, 0.00943356, 0.00630088, 0.00613499,\n",
       "        0.00602317, 0.00596662, 0.00826969, 0.0066987 , 0.00916653,\n",
       "        0.00596766, 0.0066813 , 0.00682759, 0.04802446, 0.08635879,\n",
       "        0.02884617, 0.08576531, 0.04980979, 0.04950986, 0.10720563,\n",
       "        0.09031692, 0.04949741, 0.03040357, 0.01230083]),\n",
       " 'std_score_time': array([0.00161189, 0.00163017, 0.00013581, 0.00016601, 0.00038871,\n",
       "        0.00025917, 0.00220421, 0.00139702, 0.00012226, 0.00059193,\n",
       "        0.00082151, 0.00091098, 0.00320347, 0.00116908, 0.00314976,\n",
       "        0.00068207, 0.00129502, 0.00214799, 0.07634992, 0.06845851,\n",
       "        0.03900754, 0.0379853 , 0.04699522, 0.04416763, 0.06278999,\n",
       "        0.04019321, 0.04603237, 0.0392087 , 0.01268825]),\n",
       " 'param_classifier': masked_array(data=[LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000)],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__C': masked_array(data=[0.0001, 0.0001, 0.001, 0.001, 0.01, 0.01, 0.1, 0.1,\n",
       "                    1.0, 1.0, 10.0, 10.0, 100.0, 100.0, 1000.0, 1000.0,\n",
       "                    10000.0, 10000.0, 0.0001, 0.001, 0.01, 0.1, 1.0, 10.0,\n",
       "                    100.0, 1000.0, 10000.0, --, --],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False,  True,  True],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__penalty': masked_array(data=['l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1',\n",
       "                    'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'none', 'none'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__solver': masked_array(data=['saga', 'saga', 'saga', 'saga', 'saga', 'saga', 'saga',\n",
       "                    'saga', 'saga', 'saga', 'saga', 'saga', 'saga', 'saga',\n",
       "                    'saga', 'saga', 'saga', 'saga', 'lbfgs', 'lbfgs',\n",
       "                    'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs',\n",
       "                    'lbfgs', 'lbfgs', 'saga'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__penalty': 'none',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__penalty': 'none',\n",
       "   'classifier__solver': 'saga'}],\n",
       " 'split0_test_accuracy': array([0.967, 0.967, 0.967, 0.967, 0.967, 0.967, 0.994, 0.968, 0.999,\n",
       "        0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999,\n",
       "        0.967, 0.967, 0.967, 0.968, 0.999, 0.999, 0.999, 0.999, 0.999,\n",
       "        0.999, 0.999]),\n",
       " 'split1_test_accuracy': array([0.966, 0.966, 0.966, 0.966, 0.966, 0.966, 0.995, 0.969, 0.999,\n",
       "        0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999,\n",
       "        0.966, 0.966, 0.966, 0.969, 0.999, 0.999, 0.999, 0.999, 0.999,\n",
       "        0.999, 0.999]),\n",
       " 'split2_test_accuracy': array([0.966, 0.966, 0.966, 0.966, 0.966, 0.966, 0.999, 0.969, 0.999,\n",
       "        0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999,\n",
       "        0.966, 0.966, 0.966, 0.969, 0.999, 0.999, 0.999, 0.999, 0.999,\n",
       "        0.999, 0.999]),\n",
       " 'split3_test_accuracy': array([0.966, 0.966, 0.966, 0.966, 0.966, 0.966, 0.991, 0.967, 0.999,\n",
       "        0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999,\n",
       "        0.966, 0.966, 0.966, 0.967, 0.999, 0.999, 0.999, 0.999, 0.999,\n",
       "        0.999, 0.999]),\n",
       " 'split4_test_accuracy': array([0.966, 0.966, 0.966, 0.966, 0.966, 0.966, 0.996, 0.969, 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.966, 0.966, 0.966, 0.969, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'mean_test_accuracy': array([0.9662, 0.9662, 0.9662, 0.9662, 0.9662, 0.9662, 0.995 , 0.9684,\n",
       "        0.9992, 0.9992, 0.9992, 0.9992, 0.9992, 0.9992, 0.9992, 0.9992,\n",
       "        0.9992, 0.9992, 0.9662, 0.9662, 0.9662, 0.9684, 0.9992, 0.9992,\n",
       "        0.9992, 0.9992, 0.9992, 0.9992, 0.9992]),\n",
       " 'std_test_accuracy': array([0.0004    , 0.0004    , 0.0004    , 0.0004    , 0.0004    ,\n",
       "        0.0004    , 0.00260768, 0.0008    , 0.0004    , 0.0004    ,\n",
       "        0.0004    , 0.0004    , 0.0004    , 0.0004    , 0.0004    ,\n",
       "        0.0004    , 0.0004    , 0.0004    , 0.0004    , 0.0004    ,\n",
       "        0.0004    , 0.0008    , 0.0004    , 0.0004    , 0.0004    ,\n",
       "        0.0004    , 0.0004    , 0.0004    , 0.0004    ]),\n",
       " 'rank_test_accuracy': array([21, 21, 21, 21, 21, 21, 18, 19,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1, 21, 21, 21, 19,  1,  1,  1,  1,  1,  1,  1], dtype=int32),\n",
       " 'split0_test_roc_auc_ovr': array([0.5       , 0.99064586, 0.5       , 0.99064586, 0.5       ,\n",
       "        0.99064586, 0.98484848, 0.99064586, 0.98484848, 0.99064586,\n",
       "        0.98209082, 0.98209082, 0.98209082, 0.98209082, 0.98209082,\n",
       "        0.98209082, 0.98209082, 0.98209082, 0.99064586, 0.99064586,\n",
       "        0.99064586, 0.99064586, 0.99064586, 0.98209082, 0.98209082,\n",
       "        0.98209082, 0.98212215, 0.98212215, 0.98209082]),\n",
       " 'split1_test_roc_auc_ovr': array([0.5       , 0.91987882, 0.5       , 0.91987882, 0.5       ,\n",
       "        0.97751492, 0.98529412, 0.97751492, 0.98529412, 0.97751492,\n",
       "        0.97751492, 0.97751492, 0.97751492, 0.97754537, 0.97754537,\n",
       "        0.97754537, 0.97754537, 0.97754537, 0.91987882, 0.91987882,\n",
       "        0.97751492, 0.97751492, 0.97751492, 0.97751492, 0.97754537,\n",
       "        0.97754537, 0.97754537, 0.97754537, 0.97754537]),\n",
       " 'split2_test_roc_auc_ovr': array([0.5       , 0.99147485, 0.5       , 0.99147485, 0.5       ,\n",
       "        0.99147485, 0.98529412, 0.99147485, 0.98529412, 0.99147485,\n",
       "        0.98270613, 0.98273657, 0.98270613, 0.98273657, 0.98273657,\n",
       "        0.98273657, 0.98273657, 0.98273657, 0.99147485, 0.99147485,\n",
       "        0.99147485, 0.99147485, 0.99147485, 0.98273657, 0.98273657,\n",
       "        0.98273657, 0.98273657, 0.98273657, 0.98273657]),\n",
       " 'split3_test_roc_auc_ovr': array([0.5       , 0.92473511, 0.5       , 0.92476556, 0.5       ,\n",
       "        0.97862623, 0.98529412, 0.97862623, 0.98529412, 0.97862623,\n",
       "        0.98702959, 0.97865668, 0.97862623, 0.97865668, 0.97865668,\n",
       "        0.97865668, 0.97865668, 0.97865668, 0.92473511, 0.92476556,\n",
       "        0.97862623, 0.97862623, 0.97862623, 0.97865668, 0.97865668,\n",
       "        0.97865668, 0.97865668, 0.97865668, 0.97865668]),\n",
       " 'split4_test_roc_auc_ovr': array([0.5, 1. , 0.5, 1. , 0.5, 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. ,\n",
       "        1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. ,\n",
       "        1. , 1. , 1. ]),\n",
       " 'mean_test_roc_auc_ovr': array([0.5       , 0.96534693, 0.5       , 0.96535302, 0.5       ,\n",
       "        0.98765237, 0.98814617, 0.98765237, 0.98814617, 0.98765237,\n",
       "        0.98586829, 0.9841998 , 0.98418762, 0.98420589, 0.98420589,\n",
       "        0.98420589, 0.98420589, 0.98420589, 0.96534693, 0.96535302,\n",
       "        0.98765237, 0.98765237, 0.98765237, 0.9841998 , 0.98420589,\n",
       "        0.98420589, 0.98421215, 0.98421215, 0.98420589]),\n",
       " 'std_test_roc_auc_ovr': array([0.        , 0.03532763, 0.        , 0.03532063, 0.        ,\n",
       "        0.00848853, 0.00592943, 0.00848853, 0.00592943, 0.00848853,\n",
       "        0.00768246, 0.00814431, 0.00814956, 0.00813932, 0.00813932,\n",
       "        0.00813932, 0.00813932, 0.00813932, 0.03532763, 0.03532063,\n",
       "        0.00848853, 0.00848853, 0.00848853, 0.00814431, 0.00813932,\n",
       "        0.00813932, 0.0081377 , 0.0081377 , 0.00813932]),\n",
       " 'rank_test_roc_auc_ovr': array([27, 25, 27, 23, 27,  3,  1,  3,  1,  3,  9, 20, 22, 12, 12, 12, 12,\n",
       "        12, 25, 23,  3,  3,  3, 20, 12, 12, 10, 10, 12], dtype=int32),\n",
       " 'split0_test_f1_micro': array([0.967, 0.967, 0.967, 0.967, 0.967, 0.967, 0.994, 0.968, 0.999,\n",
       "        0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999,\n",
       "        0.967, 0.967, 0.967, 0.968, 0.999, 0.999, 0.999, 0.999, 0.999,\n",
       "        0.999, 0.999]),\n",
       " 'split1_test_f1_micro': array([0.966, 0.966, 0.966, 0.966, 0.966, 0.966, 0.995, 0.969, 0.999,\n",
       "        0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999,\n",
       "        0.966, 0.966, 0.966, 0.969, 0.999, 0.999, 0.999, 0.999, 0.999,\n",
       "        0.999, 0.999]),\n",
       " 'split2_test_f1_micro': array([0.966, 0.966, 0.966, 0.966, 0.966, 0.966, 0.999, 0.969, 0.999,\n",
       "        0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999,\n",
       "        0.966, 0.966, 0.966, 0.969, 0.999, 0.999, 0.999, 0.999, 0.999,\n",
       "        0.999, 0.999]),\n",
       " 'split3_test_f1_micro': array([0.966, 0.966, 0.966, 0.966, 0.966, 0.966, 0.991, 0.967, 0.999,\n",
       "        0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999,\n",
       "        0.966, 0.966, 0.966, 0.967, 0.999, 0.999, 0.999, 0.999, 0.999,\n",
       "        0.999, 0.999]),\n",
       " 'split4_test_f1_micro': array([0.966, 0.966, 0.966, 0.966, 0.966, 0.966, 0.996, 0.969, 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.966, 0.966, 0.966, 0.969, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'mean_test_f1_micro': array([0.9662, 0.9662, 0.9662, 0.9662, 0.9662, 0.9662, 0.995 , 0.9684,\n",
       "        0.9992, 0.9992, 0.9992, 0.9992, 0.9992, 0.9992, 0.9992, 0.9992,\n",
       "        0.9992, 0.9992, 0.9662, 0.9662, 0.9662, 0.9684, 0.9992, 0.9992,\n",
       "        0.9992, 0.9992, 0.9992, 0.9992, 0.9992]),\n",
       " 'std_test_f1_micro': array([0.0004    , 0.0004    , 0.0004    , 0.0004    , 0.0004    ,\n",
       "        0.0004    , 0.00260768, 0.0008    , 0.0004    , 0.0004    ,\n",
       "        0.0004    , 0.0004    , 0.0004    , 0.0004    , 0.0004    ,\n",
       "        0.0004    , 0.0004    , 0.0004    , 0.0004    , 0.0004    ,\n",
       "        0.0004    , 0.0008    , 0.0004    , 0.0004    , 0.0004    ,\n",
       "        0.0004    , 0.0004    , 0.0004    , 0.0004    ]),\n",
       " 'rank_test_f1_micro': array([21, 21, 21, 21, 21, 21, 18, 19,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1, 21, 21, 21, 19,  1,  1,  1,  1,  1,  1,  1], dtype=int32)}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "toxic-cooper",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21, 21, 21, 21, 21, 21, 18, 19,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1, 21, 21, 21, 19,  1,  1,  1,  1,  1,  1,  1], dtype=int32)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.cv_results_['rank_test_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "opposite-lending",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 1.0,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for accuracy\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_accuracy']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "digital-development",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 0.1,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for roc auc\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_roc_auc_ovr']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "incident-logic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 1.0,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for f1\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_f1_micro']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "sought-equivalent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best accuracy model\n",
    "acc_model = LogisticRegression(penalty = 'l1', C = 1.0, solver = 'saga', max_iter = 5000)\n",
    "\n",
    "# best roc auc model\n",
    "roc_model = LogisticRegression(penalty = 'l1', C = 0.1, solver = 'saga', max_iter = 5000)\n",
    "\n",
    "# best f1 model\n",
    "f1_model = LogisticRegression(penalty = 'l1', C = 1.0, solver = 'saga', max_iter = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "unauthorized-orchestra",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=5000, penalty='l1', solver='saga')"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# models the data\n",
    "acc_model.fit(X_train, Y_train)\n",
    "roc_model.fit(X_train, Y_train)\n",
    "f1_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "stopped-series",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>C</th>\n",
       "      <th>penalty</th>\n",
       "      <th>solver</th>\n",
       "      <th>score_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           classifier           C penalty solver  score_acc\n",
       "0   LogisticRegression(max_iter=5000)      0.0001      l1   saga     0.0338\n",
       "1   LogisticRegression(max_iter=5000)      0.0001      l2   saga     0.0338\n",
       "2   LogisticRegression(max_iter=5000)      0.0010      l1   saga     0.0338\n",
       "3   LogisticRegression(max_iter=5000)      0.0010      l2   saga     0.0338\n",
       "4   LogisticRegression(max_iter=5000)      0.0100      l1   saga     0.0338\n",
       "5   LogisticRegression(max_iter=5000)      0.0100      l2   saga     0.0338\n",
       "6   LogisticRegression(max_iter=5000)      0.1000      l1   saga     0.0050\n",
       "7   LogisticRegression(max_iter=5000)      0.1000      l2   saga     0.0316\n",
       "8   LogisticRegression(max_iter=5000)      1.0000      l1   saga     0.0008\n",
       "9   LogisticRegression(max_iter=5000)      1.0000      l2   saga     0.0008\n",
       "10  LogisticRegression(max_iter=5000)     10.0000      l1   saga     0.0008\n",
       "11  LogisticRegression(max_iter=5000)     10.0000      l2   saga     0.0008\n",
       "12  LogisticRegression(max_iter=5000)    100.0000      l1   saga     0.0008\n",
       "13  LogisticRegression(max_iter=5000)    100.0000      l2   saga     0.0008\n",
       "14  LogisticRegression(max_iter=5000)   1000.0000      l1   saga     0.0008\n",
       "15  LogisticRegression(max_iter=5000)   1000.0000      l2   saga     0.0008\n",
       "16  LogisticRegression(max_iter=5000)  10000.0000      l1   saga     0.0008\n",
       "17  LogisticRegression(max_iter=5000)  10000.0000      l2   saga     0.0008\n",
       "18  LogisticRegression(max_iter=5000)      0.0001      l2  lbfgs     0.0338\n",
       "19  LogisticRegression(max_iter=5000)      0.0010      l2  lbfgs     0.0338\n",
       "20  LogisticRegression(max_iter=5000)      0.0100      l2  lbfgs     0.0338\n",
       "21  LogisticRegression(max_iter=5000)      0.1000      l2  lbfgs     0.0316\n",
       "22  LogisticRegression(max_iter=5000)      1.0000      l2  lbfgs     0.0008\n",
       "23  LogisticRegression(max_iter=5000)     10.0000      l2  lbfgs     0.0008\n",
       "24  LogisticRegression(max_iter=5000)    100.0000      l2  lbfgs     0.0008\n",
       "25  LogisticRegression(max_iter=5000)   1000.0000      l2  lbfgs     0.0008\n",
       "26  LogisticRegression(max_iter=5000)  10000.0000      l2  lbfgs     0.0008\n",
       "27  LogisticRegression(max_iter=5000)         NaN    none  lbfgs     0.0008\n",
       "28  LogisticRegression(max_iter=5000)         NaN    none   saga     0.0008"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = pd.DataFrame( best_model.cv_results_['params'] )\n",
    "\n",
    "results['score_acc'] = 1 - best_model.cv_results_['mean_test_accuracy']\n",
    "\n",
    "cols = results.columns.to_series().str.split('__').apply(lambda x: x[-1])\n",
    "results.columns = cols\n",
    "\n",
    "# Heat map\n",
    "sns.heatmap( results.query('solver==\"saga\"').pivot('C','penalty','score_acc'),\n",
    "             annot=True, fmt='.3f')\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "adjusted-thousand",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets another 5000 random samples\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_p, Y_p, train_size = 5000, random_state = 5)\n",
    "\n",
    "# Grid Search\n",
    "pipe = Pipeline([('classifier', LogisticRegression())])\n",
    "\n",
    "search_space = [{'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['saga'],\n",
    "                 'classifier__penalty': ['l1', 'l2'],\n",
    "                 'classifier__C': np.logspace(-4, 4, 9)},\n",
    "                {'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['lbfgs'],\n",
    "                 'classifier__penalty': ['l2'],\n",
    "                 'classifier__C': np.logspace(-4, 4, 9)},\n",
    "                {'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['lbfgs','saga'],\n",
    "                 'classifier__penalty': ['none']}]\n",
    "                \n",
    "clf = GridSearchCV(pipe, search_space, cv=StratifiedKFold(n_splits=5), \n",
    "                   scoring=['accuracy', 'roc_auc_ovr', 'f1_micro'], refit=False,\n",
    "                   verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "wanted-tradition",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "professional-disorder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([8.05716515e-03, 1.35886669e-02, 3.90424728e-03, 2.52711773e-02,\n",
       "        1.38176441e-02, 1.76843643e-02, 1.80134296e-02, 1.46399498e-02,\n",
       "        2.01443672e-02, 2.29954243e-02, 8.63862514e-02, 1.04141712e-01,\n",
       "        2.74066734e-01, 2.94428635e-01, 5.09094524e-01, 2.61963749e-01,\n",
       "        5.37478781e-01, 3.79064178e-01, 6.52566643e+00, 5.53680096e+00,\n",
       "        5.79611068e+00, 8.79254298e+00, 1.26281224e+01, 1.67087855e+01,\n",
       "        2.26097698e+01, 3.26507159e+01, 3.38891936e+01, 2.00530329e+01,\n",
       "        5.53521442e-01]),\n",
       " 'std_fit_time': array([1.22471444e-03, 1.31999169e-03, 7.22567380e-05, 7.03241766e-03,\n",
       "        2.66107299e-03, 3.31996427e-03, 1.77083694e-03, 9.19376067e-04,\n",
       "        6.37091501e-04, 1.15436382e-03, 1.98514036e-02, 3.13178233e-02,\n",
       "        3.61589038e-02, 1.41366283e-02, 8.43994323e-02, 1.65991975e-02,\n",
       "        1.29605954e-01, 6.02506829e-02, 4.84994646e-01, 6.87462046e-01,\n",
       "        5.03857511e-01, 6.94797894e-01, 7.86425793e-01, 1.24668969e+00,\n",
       "        2.71969006e+00, 2.90300250e+00, 9.27909191e+00, 1.17749189e+00,\n",
       "        1.04686271e-01]),\n",
       " 'mean_score_time': array([0.01035933, 0.00539837, 0.00511961, 0.01182532, 0.01351633,\n",
       "        0.00879226, 0.00607514, 0.00633793, 0.00645046, 0.00741744,\n",
       "        0.00611567, 0.00638995, 0.00621123, 0.00731382, 0.00746717,\n",
       "        0.00628624, 0.00642443, 0.00555801, 0.04652462, 0.06716223,\n",
       "        0.08490024, 0.04857593, 0.10773344, 0.06932473, 0.08988056,\n",
       "        0.04996438, 0.02856026, 0.06914315, 0.00793552]),\n",
       " 'std_score_time': array([1.33639715e-03, 1.29934985e-04, 2.86183346e-05, 3.19187434e-03,\n",
       "        1.12795110e-03, 2.00699682e-03, 1.56771919e-04, 5.64497531e-04,\n",
       "        3.18961946e-04, 1.97669494e-03, 5.62809870e-04, 3.48782395e-04,\n",
       "        3.83861180e-04, 1.29844120e-03, 2.66896146e-03, 1.02979253e-03,\n",
       "        4.83615688e-04, 5.18985059e-04, 4.56445938e-02, 4.83721413e-02,\n",
       "        3.53525626e-02, 4.61085478e-02, 2.67978746e-03, 7.41414461e-02,\n",
       "        3.94216843e-02, 4.80430921e-02, 3.77910457e-02, 7.76006916e-02,\n",
       "        1.84581235e-03]),\n",
       " 'param_classifier': masked_array(data=[LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000)],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__C': masked_array(data=[0.0001, 0.0001, 0.001, 0.001, 0.01, 0.01, 0.1, 0.1,\n",
       "                    1.0, 1.0, 10.0, 10.0, 100.0, 100.0, 1000.0, 1000.0,\n",
       "                    10000.0, 10000.0, 0.0001, 0.001, 0.01, 0.1, 1.0, 10.0,\n",
       "                    100.0, 1000.0, 10000.0, --, --],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False,  True,  True],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__penalty': masked_array(data=['l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1',\n",
       "                    'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'none', 'none'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__solver': masked_array(data=['saga', 'saga', 'saga', 'saga', 'saga', 'saga', 'saga',\n",
       "                    'saga', 'saga', 'saga', 'saga', 'saga', 'saga', 'saga',\n",
       "                    'saga', 'saga', 'saga', 'saga', 'lbfgs', 'lbfgs',\n",
       "                    'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs',\n",
       "                    'lbfgs', 'lbfgs', 'saga'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__penalty': 'none',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__penalty': 'none',\n",
       "   'classifier__solver': 'saga'}],\n",
       " 'split0_test_accuracy': array([0.97 , 0.97 , 0.97 , 0.97 , 0.97 , 0.97 , 0.993, 0.97 , 0.997,\n",
       "        0.997, 0.997, 0.997, 0.997, 0.997, 0.997, 0.997, 0.997, 0.997,\n",
       "        0.97 , 0.97 , 0.97 , 0.97 , 0.997, 0.997, 0.997, 0.997, 0.997,\n",
       "        0.997, 0.997]),\n",
       " 'split1_test_accuracy': array([0.969, 0.969, 0.969, 0.969, 0.969, 0.969, 0.997, 0.97 , 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.969, 0.969, 0.969, 0.97 , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split2_test_accuracy': array([0.969, 0.969, 0.969, 0.969, 0.969, 0.969, 0.995, 0.971, 0.997,\n",
       "        0.997, 0.997, 0.997, 0.997, 0.997, 0.997, 0.997, 0.997, 0.997,\n",
       "        0.969, 0.969, 0.969, 0.971, 0.997, 0.997, 0.997, 0.997, 0.997,\n",
       "        0.997, 0.997]),\n",
       " 'split3_test_accuracy': array([0.969, 0.969, 0.969, 0.969, 0.969, 0.969, 0.996, 0.971, 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.969, 0.969, 0.969, 0.971, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split4_test_accuracy': array([0.969, 0.969, 0.969, 0.969, 0.969, 0.969, 0.998, 0.971, 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.969, 0.969, 0.969, 0.971, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'mean_test_accuracy': array([0.9692, 0.9692, 0.9692, 0.9692, 0.9692, 0.9692, 0.9958, 0.9706,\n",
       "        0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "        0.9988, 0.9988, 0.9692, 0.9692, 0.9692, 0.9706, 0.9988, 0.9988,\n",
       "        0.9988, 0.9988, 0.9988, 0.9988, 0.9988]),\n",
       " 'std_test_accuracy': array([0.0004    , 0.0004    , 0.0004    , 0.0004    , 0.0004    ,\n",
       "        0.0004    , 0.00172047, 0.0004899 , 0.00146969, 0.00146969,\n",
       "        0.00146969, 0.00146969, 0.00146969, 0.00146969, 0.00146969,\n",
       "        0.00146969, 0.00146969, 0.00146969, 0.0004    , 0.0004    ,\n",
       "        0.0004    , 0.0004899 , 0.00146969, 0.00146969, 0.00146969,\n",
       "        0.00146969, 0.00146969, 0.00146969, 0.00146969]),\n",
       " 'rank_test_accuracy': array([21, 21, 21, 21, 21, 21, 18, 19,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1, 21, 21, 21, 19,  1,  1,  1,  1,  1,  1,  1], dtype=int32),\n",
       " 'split0_test_roc_auc_ovr': array([0.5       , 0.94001718, 0.5       , 0.94001718, 0.5       ,\n",
       "        0.94001718, 0.95      , 0.94001718, 0.95      , 0.96664948,\n",
       "        0.96005155, 0.96012027, 0.96005155, 0.96012027, 0.96015464,\n",
       "        0.96015464, 0.96022337, 0.96022337, 0.94001718, 0.94001718,\n",
       "        0.94001718, 0.94001718, 0.96664948, 0.96012027, 0.96012027,\n",
       "        0.96022337, 0.96025773, 0.96025773, 0.96022337]),\n",
       " 'split1_test_roc_auc_ovr': array([0.5       , 0.94237491, 0.5       , 0.94237491, 0.5       ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.94237491, 0.94237491,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'split2_test_roc_auc_ovr': array([0.5       , 0.94553747, 0.5       , 0.94553747, 0.5       ,\n",
       "        0.94553747, 0.9516129 , 0.94553747, 0.95291122, 0.94553747,\n",
       "        0.94552082, 0.94553747, 0.94552082, 0.94553747, 0.94553747,\n",
       "        0.94553747, 0.94553747, 0.94553747, 0.94553747, 0.94553747,\n",
       "        0.94553747, 0.94553747, 0.94553747, 0.94553747, 0.94553747,\n",
       "        0.94553747, 0.94553747, 0.94553747, 0.94553747]),\n",
       " 'split3_test_roc_auc_ovr': array([0.5      , 0.9618496, 0.5      , 0.9618496, 0.5      , 1.       ,\n",
       "        1.       , 1.       , 1.       , 1.       , 1.       , 1.       ,\n",
       "        1.       , 1.       , 1.       , 1.       , 1.       , 1.       ,\n",
       "        0.9618496, 0.9618496, 1.       , 1.       , 1.       , 1.       ,\n",
       "        1.       , 1.       , 1.       , 1.       , 1.       ]),\n",
       " 'split4_test_roc_auc_ovr': array([0.5, 1. , 0.5, 1. , 0.5, 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. ,\n",
       "        1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. ,\n",
       "        1. , 1. , 1. ]),\n",
       " 'mean_test_roc_auc_ovr': array([0.5       , 0.95795583, 0.5       , 0.95795583, 0.5       ,\n",
       "        0.97711093, 0.98032258, 0.97711093, 0.98058224, 0.98243739,\n",
       "        0.98111447, 0.98113155, 0.98111447, 0.98113155, 0.98113842,\n",
       "        0.98113842, 0.98115217, 0.98115217, 0.95795583, 0.95795583,\n",
       "        0.97711093, 0.97711093, 0.98243739, 0.98113155, 0.98113155,\n",
       "        0.98115217, 0.98115904, 0.98115904, 0.98115217]),\n",
       " 'std_test_roc_auc_ovr': array([0.        , 0.02236806, 0.        , 0.02236806, 0.        ,\n",
       "        0.02808757, 0.02410522, 0.02808757, 0.02379961, 0.02252198,\n",
       "        0.02358196, 0.02356467, 0.02358196, 0.02356467, 0.02355854,\n",
       "        0.02355854, 0.02354631, 0.02354631, 0.02236806, 0.02236806,\n",
       "        0.02808757, 0.02808757, 0.02252198, 0.02356467, 0.02356467,\n",
       "        0.02354631, 0.02354021, 0.02354021, 0.02354631]),\n",
       " 'rank_test_roc_auc_ovr': array([27, 23, 27, 23, 27, 19, 18, 19, 17,  1, 15, 11, 15, 11,  9,  9,  5,\n",
       "         5, 23, 23, 19, 19,  1, 11, 11,  5,  3,  3,  5], dtype=int32),\n",
       " 'split0_test_f1_micro': array([0.97 , 0.97 , 0.97 , 0.97 , 0.97 , 0.97 , 0.993, 0.97 , 0.997,\n",
       "        0.997, 0.997, 0.997, 0.997, 0.997, 0.997, 0.997, 0.997, 0.997,\n",
       "        0.97 , 0.97 , 0.97 , 0.97 , 0.997, 0.997, 0.997, 0.997, 0.997,\n",
       "        0.997, 0.997]),\n",
       " 'split1_test_f1_micro': array([0.969, 0.969, 0.969, 0.969, 0.969, 0.969, 0.997, 0.97 , 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.969, 0.969, 0.969, 0.97 , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split2_test_f1_micro': array([0.969, 0.969, 0.969, 0.969, 0.969, 0.969, 0.995, 0.971, 0.997,\n",
       "        0.997, 0.997, 0.997, 0.997, 0.997, 0.997, 0.997, 0.997, 0.997,\n",
       "        0.969, 0.969, 0.969, 0.971, 0.997, 0.997, 0.997, 0.997, 0.997,\n",
       "        0.997, 0.997]),\n",
       " 'split3_test_f1_micro': array([0.969, 0.969, 0.969, 0.969, 0.969, 0.969, 0.996, 0.971, 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.969, 0.969, 0.969, 0.971, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split4_test_f1_micro': array([0.969, 0.969, 0.969, 0.969, 0.969, 0.969, 0.998, 0.971, 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.969, 0.969, 0.969, 0.971, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'mean_test_f1_micro': array([0.9692, 0.9692, 0.9692, 0.9692, 0.9692, 0.9692, 0.9958, 0.9706,\n",
       "        0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "        0.9988, 0.9988, 0.9692, 0.9692, 0.9692, 0.9706, 0.9988, 0.9988,\n",
       "        0.9988, 0.9988, 0.9988, 0.9988, 0.9988]),\n",
       " 'std_test_f1_micro': array([0.0004    , 0.0004    , 0.0004    , 0.0004    , 0.0004    ,\n",
       "        0.0004    , 0.00172047, 0.0004899 , 0.00146969, 0.00146969,\n",
       "        0.00146969, 0.00146969, 0.00146969, 0.00146969, 0.00146969,\n",
       "        0.00146969, 0.00146969, 0.00146969, 0.0004    , 0.0004    ,\n",
       "        0.0004    , 0.0004899 , 0.00146969, 0.00146969, 0.00146969,\n",
       "        0.00146969, 0.00146969, 0.00146969, 0.00146969]),\n",
       " 'rank_test_f1_micro': array([21, 21, 21, 21, 21, 21, 18, 19,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1, 21, 21, 21, 19,  1,  1,  1,  1,  1,  1,  1], dtype=int32)}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "moderate-cheat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21, 21, 21, 21, 21, 21, 18, 19,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1, 21, 21, 21, 19,  1,  1,  1,  1,  1,  1,  1], dtype=int32)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.cv_results_['rank_test_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "grateful-butter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 1.0,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for accuracy\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_accuracy']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "architectural-interim",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 1.0,\n",
       " 'classifier__penalty': 'l2',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for roc auc\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_roc_auc_ovr']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "stunning-peace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 1.0,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for f1\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_f1_micro']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "unavailable-processing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best accuracy model\n",
    "acc_model = LogisticRegression(penalty = 'l1', C = 1.0, solver = 'saga', max_iter = 5000)\n",
    "\n",
    "# best roc auc model\n",
    "roc_model = LogisticRegression(penalty = 'l2', C = 1.0, solver = 'saga', max_iter = 5000)\n",
    "\n",
    "# best f1 model\n",
    "f1_model = LogisticRegression(penalty = 'l1', C = 1.0, solver = 'saga', max_iter = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "proper-naples",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=5000, penalty='l1', solver='saga')"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# models the data\n",
    "acc_model.fit(X_train, Y_train)\n",
    "roc_model.fit(X_train, Y_train)\n",
    "f1_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "chemical-alaska",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>C</th>\n",
       "      <th>penalty</th>\n",
       "      <th>solver</th>\n",
       "      <th>score_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           classifier           C penalty solver  score_acc\n",
       "0   LogisticRegression(max_iter=5000)      0.0001      l1   saga     0.0308\n",
       "1   LogisticRegression(max_iter=5000)      0.0001      l2   saga     0.0308\n",
       "2   LogisticRegression(max_iter=5000)      0.0010      l1   saga     0.0308\n",
       "3   LogisticRegression(max_iter=5000)      0.0010      l2   saga     0.0308\n",
       "4   LogisticRegression(max_iter=5000)      0.0100      l1   saga     0.0308\n",
       "5   LogisticRegression(max_iter=5000)      0.0100      l2   saga     0.0308\n",
       "6   LogisticRegression(max_iter=5000)      0.1000      l1   saga     0.0042\n",
       "7   LogisticRegression(max_iter=5000)      0.1000      l2   saga     0.0294\n",
       "8   LogisticRegression(max_iter=5000)      1.0000      l1   saga     0.0012\n",
       "9   LogisticRegression(max_iter=5000)      1.0000      l2   saga     0.0012\n",
       "10  LogisticRegression(max_iter=5000)     10.0000      l1   saga     0.0012\n",
       "11  LogisticRegression(max_iter=5000)     10.0000      l2   saga     0.0012\n",
       "12  LogisticRegression(max_iter=5000)    100.0000      l1   saga     0.0012\n",
       "13  LogisticRegression(max_iter=5000)    100.0000      l2   saga     0.0012\n",
       "14  LogisticRegression(max_iter=5000)   1000.0000      l1   saga     0.0012\n",
       "15  LogisticRegression(max_iter=5000)   1000.0000      l2   saga     0.0012\n",
       "16  LogisticRegression(max_iter=5000)  10000.0000      l1   saga     0.0012\n",
       "17  LogisticRegression(max_iter=5000)  10000.0000      l2   saga     0.0012\n",
       "18  LogisticRegression(max_iter=5000)      0.0001      l2  lbfgs     0.0308\n",
       "19  LogisticRegression(max_iter=5000)      0.0010      l2  lbfgs     0.0308\n",
       "20  LogisticRegression(max_iter=5000)      0.0100      l2  lbfgs     0.0308\n",
       "21  LogisticRegression(max_iter=5000)      0.1000      l2  lbfgs     0.0294\n",
       "22  LogisticRegression(max_iter=5000)      1.0000      l2  lbfgs     0.0012\n",
       "23  LogisticRegression(max_iter=5000)     10.0000      l2  lbfgs     0.0012\n",
       "24  LogisticRegression(max_iter=5000)    100.0000      l2  lbfgs     0.0012\n",
       "25  LogisticRegression(max_iter=5000)   1000.0000      l2  lbfgs     0.0012\n",
       "26  LogisticRegression(max_iter=5000)  10000.0000      l2  lbfgs     0.0012\n",
       "27  LogisticRegression(max_iter=5000)         NaN    none  lbfgs     0.0012\n",
       "28  LogisticRegression(max_iter=5000)         NaN    none   saga     0.0012"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = pd.DataFrame( best_model.cv_results_['params'] )\n",
    "\n",
    "results['score_acc'] = 1 - best_model.cv_results_['mean_test_accuracy']\n",
    "\n",
    "cols = results.columns.to_series().str.split('__').apply(lambda x: x[-1])\n",
    "results.columns = cols\n",
    "\n",
    "# Heat map\n",
    "sns.heatmap( results.query('solver==\"saga\"').pivot('C','penalty','score_acc'),\n",
    "             annot=True, fmt='.3f')\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-diagnosis",
   "metadata": {},
   "source": [
    "## Nursery Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composed-python",
   "metadata": {},
   "source": [
    "https://archive.ics.uci.edu/ml/datasets/Nursery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "municipal-philip",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads the dataset\n",
    "nursery = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/nursery/nursery.data')\n",
    "\n",
    "# One hot encoding categorical features\n",
    "encoder = OneHotEncoder().fit(nursery[['usual', 'proper', 'complete', '1', 'convenient', 'convenient.1', 'nonprob', 'recommended', 'recommend']])\n",
    "encoder.categories_\n",
    "\n",
    "transformed = encoder.transform(nursery[['usual', 'proper', 'complete', '1', 'convenient', 'convenient.1', 'nonprob', 'recommended', 'recommend']] ).toarray() \n",
    "transformed\n",
    "\n",
    "for index, category in enumerate( np.concatenate(encoder.categories_) ):\n",
    "    nursery[category] = transformed[:,index]\n",
    "\n",
    "# drops string\n",
    "nursery = nursery.drop(columns = ['convenient.1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "unlike-essex",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stores column of 'recommended' in Y and everything else in X\n",
    "X_n = nursery.drop(['recommended'], axis=1)\n",
    "Y_n = nursery['recommended']\n",
    "\n",
    "# Gets 5000 random samples\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_n, Y_n, train_size = 5000, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fundamental-spectrum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "pipe = Pipeline([('classifier', LogisticRegression())])\n",
    "\n",
    "search_space = [{'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['saga'],\n",
    "                 'classifier__penalty': ['l1', 'l2'],\n",
    "                 'classifier__C': np.logspace(-4, 4, 9)},\n",
    "                {'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['lbfgs'],\n",
    "                 'classifier__penalty': ['l2'],\n",
    "                 'classifier__C': np.logspace(-4, 4, 9)},\n",
    "                {'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['lbfgs','saga'],\n",
    "                 'classifier__penalty': ['none']}]\n",
    "                \n",
    "clf = GridSearchCV(pipe, search_space, cv=StratifiedKFold(n_splits=5), \n",
    "                   scoring=['accuracy', 'roc_auc_ovr', 'f1_micro'], refit=False,\n",
    "                   verbose=0)\n",
    "                \n",
    "best_model = clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "southeast-worthy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 0.02307649,  0.11751189,  0.08169107,  0.0652987 ,  0.08869057,\n",
       "         0.06145024,  0.10587187,  0.10534363,  0.10086846,  0.05995722,\n",
       "         0.3030612 ,  0.0978456 ,  0.79018316,  0.2921824 ,  1.180968  ,\n",
       "         0.59027834,  1.36558022,  0.940275  ,  1.88439226,  2.01818752,\n",
       "         3.70361366,  6.78337994, 11.26564779, 15.17122102, 13.86626244,\n",
       "        14.82763925, 12.03784986,  8.88008046,  1.01320662]),\n",
       " 'std_fit_time': array([0.01770207, 0.0407875 , 0.03441407, 0.03466978, 0.06845308,\n",
       "        0.03605945, 0.04363092, 0.02575898, 0.01464443, 0.00983802,\n",
       "        0.05156189, 0.03129921, 0.0488595 , 0.06509395, 0.05282872,\n",
       "        0.01981934, 0.0713995 , 0.05890705, 0.1660693 , 0.16457808,\n",
       "        0.1660934 , 0.72163876, 2.6529995 , 5.61154348, 2.34979053,\n",
       "        5.12087694, 2.91378879, 0.56222005, 0.04595151]),\n",
       " 'mean_score_time': array([0.35781288, 0.34926834, 0.43400278, 0.43200822, 0.36819334,\n",
       "        0.41169744, 0.3931076 , 0.35319238, 0.31511993, 0.37714567,\n",
       "        0.33641057, 0.32254462, 0.38683391, 0.31049724, 0.34719892,\n",
       "        0.28726735, 0.45169973, 0.37851558, 0.42222142, 0.46882682,\n",
       "        0.39409046, 0.42928467, 0.52224021, 0.49110518, 0.41327248,\n",
       "        0.38840413, 0.4604001 , 0.51984329, 0.34471927]),\n",
       " 'std_score_time': array([0.02985826, 0.02437652, 0.09082872, 0.13438114, 0.05069951,\n",
       "        0.09027856, 0.0540259 , 0.0236958 , 0.04713254, 0.04261004,\n",
       "        0.07660143, 0.0665673 , 0.08945156, 0.07019636, 0.08061258,\n",
       "        0.07352665, 0.09199849, 0.03840239, 0.0755534 , 0.07423614,\n",
       "        0.06187229, 0.04388514, 0.10532788, 0.08473324, 0.16808159,\n",
       "        0.02367813, 0.09649802, 0.12115553, 0.02881567]),\n",
       " 'param_classifier': masked_array(data=[LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000)],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__C': masked_array(data=[0.0001, 0.0001, 0.001, 0.001, 0.01, 0.01, 0.1, 0.1,\n",
       "                    1.0, 1.0, 10.0, 10.0, 100.0, 100.0, 1000.0, 1000.0,\n",
       "                    10000.0, 10000.0, 0.0001, 0.001, 0.01, 0.1, 1.0, 10.0,\n",
       "                    100.0, 1000.0, 10000.0, --, --],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False,  True,  True],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__penalty': masked_array(data=['l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1',\n",
       "                    'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'none', 'none'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__solver': masked_array(data=['saga', 'saga', 'saga', 'saga', 'saga', 'saga', 'saga',\n",
       "                    'saga', 'saga', 'saga', 'saga', 'saga', 'saga', 'saga',\n",
       "                    'saga', 'saga', 'saga', 'saga', 'lbfgs', 'lbfgs',\n",
       "                    'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs',\n",
       "                    'lbfgs', 'lbfgs', 'saga'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__penalty': 'none',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__penalty': 'none',\n",
       "   'classifier__solver': 'saga'}],\n",
       " 'split0_test_accuracy': array([0.662, 0.662, 0.662, 0.662, 0.662, 0.704, 0.732, 0.73 , 0.739,\n",
       "        0.735, 0.742, 0.741, 0.741, 0.741, 0.741, 0.741, 0.741, 0.741,\n",
       "        0.662, 0.662, 0.704, 0.73 , 0.735, 0.741, 0.741, 0.741, 0.741,\n",
       "        0.741, 0.741]),\n",
       " 'split1_test_accuracy': array([0.662, 0.662, 0.662, 0.662, 0.662, 0.72 , 0.771, 0.777, 0.773,\n",
       "        0.772, 0.768, 0.769, 0.768, 0.768, 0.768, 0.768, 0.768, 0.768,\n",
       "        0.662, 0.662, 0.72 , 0.777, 0.772, 0.769, 0.768, 0.768, 0.768,\n",
       "        0.768, 0.768]),\n",
       " 'split2_test_accuracy': array([0.662, 0.662, 0.662, 0.662, 0.662, 0.728, 0.754, 0.756, 0.772,\n",
       "        0.769, 0.772, 0.772, 0.772, 0.772, 0.772, 0.772, 0.772, 0.772,\n",
       "        0.662, 0.662, 0.728, 0.756, 0.769, 0.772, 0.772, 0.772, 0.772,\n",
       "        0.772, 0.772]),\n",
       " 'split3_test_accuracy': array([0.662, 0.662, 0.662, 0.662, 0.662, 0.708, 0.731, 0.738, 0.735,\n",
       "        0.736, 0.735, 0.736, 0.735, 0.735, 0.735, 0.735, 0.735, 0.735,\n",
       "        0.662, 0.662, 0.708, 0.738, 0.736, 0.736, 0.735, 0.735, 0.735,\n",
       "        0.735, 0.735]),\n",
       " 'split4_test_accuracy': array([0.662, 0.662, 0.662, 0.662, 0.662, 0.704, 0.729, 0.727, 0.728,\n",
       "        0.728, 0.727, 0.727, 0.727, 0.727, 0.727, 0.727, 0.727, 0.727,\n",
       "        0.662, 0.662, 0.704, 0.726, 0.728, 0.727, 0.727, 0.727, 0.727,\n",
       "        0.727, 0.727]),\n",
       " 'mean_test_accuracy': array([0.662 , 0.662 , 0.662 , 0.662 , 0.662 , 0.7128, 0.7434, 0.7456,\n",
       "        0.7494, 0.748 , 0.7488, 0.749 , 0.7486, 0.7486, 0.7486, 0.7486,\n",
       "        0.7486, 0.7486, 0.662 , 0.662 , 0.7128, 0.7454, 0.748 , 0.749 ,\n",
       "        0.7486, 0.7486, 0.7486, 0.7486, 0.7486]),\n",
       " 'std_test_accuracy': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0096    , 0.01652392, 0.01866119, 0.01918958, 0.01860108,\n",
       "        0.01799333, 0.01814387, 0.01807318, 0.01807318, 0.01807318,\n",
       "        0.01807318, 0.01807318, 0.01807318, 0.        , 0.        ,\n",
       "        0.0096    , 0.01886372, 0.01860108, 0.01814387, 0.01807318,\n",
       "        0.01807318, 0.01807318, 0.01807318, 0.01807318]),\n",
       " 'rank_test_accuracy': array([23, 23, 23, 23, 23, 21, 20, 18,  1, 16,  4,  2,  5,  5,  5,  5,  5,\n",
       "         5, 23, 23, 21, 19, 16,  2,  5,  5,  5,  5,  5], dtype=int32),\n",
       " 'split0_test_roc_auc_ovr': array([0.5       , 0.74028853, 0.5       , 0.74843133, 0.75155527,\n",
       "        0.787018  , 0.82060369, 0.82399355, 0.83106375, 0.83037997,\n",
       "        0.83138776, 0.83134307, 0.83141011, 0.8313967 , 0.83141011,\n",
       "        0.83141458, 0.83141458, 0.83141458, 0.74028853, 0.7484492 ,\n",
       "        0.78704035, 0.82400025, 0.83040008, 0.83132966, 0.83140117,\n",
       "        0.83141681, 0.83141458, 0.83142128, 0.83141458]),\n",
       " 'split1_test_roc_auc_ovr': array([0.5       , 0.78306057, 0.5       , 0.79290164, 0.79168827,\n",
       "        0.82929843, 0.85937137, 0.86287965, 0.86565053, 0.86558349,\n",
       "        0.86580695, 0.86582483, 0.86577567, 0.86575779, 0.86579578,\n",
       "        0.86579131, 0.86579354, 0.86579354, 0.78309632, 0.7928927 ,\n",
       "        0.82928502, 0.86287519, 0.8656036 , 0.86583153, 0.86575332,\n",
       "        0.86579801, 0.86580472, 0.86579578, 0.86580025]),\n",
       " 'split2_test_roc_auc_ovr': array([0.5       , 0.79129945, 0.5       , 0.79925901, 0.79714957,\n",
       "        0.83658539, 0.85731556, 0.85944064, 0.8588306 , 0.85911439,\n",
       "        0.85863619, 0.85862279, 0.85860044, 0.85860044, 0.85857809,\n",
       "        0.85858703, 0.85856916, 0.85857362, 0.79133074, 0.79927689,\n",
       "        0.8365988 , 0.85941383, 0.85911663, 0.85862725, 0.85860044,\n",
       "        0.85858703, 0.8585915 , 0.85857362, 0.85856692]),\n",
       " 'split3_test_roc_auc_ovr': array([0.5       , 0.76115948, 0.5       , 0.76939166, 0.77186757,\n",
       "        0.80413039, 0.82968725, 0.83403797, 0.836496  , 0.83660326,\n",
       "        0.83667924, 0.83667924, 0.83664349, 0.83668818, 0.83664796,\n",
       "        0.83665242, 0.83665689, 0.83665689, 0.76112372, 0.76939166,\n",
       "        0.80414827, 0.83402903, 0.83661667, 0.8366703 , 0.83668371,\n",
       "        0.83666136, 0.83667477, 0.83666583, 0.83665689]),\n",
       " 'split4_test_roc_auc_ovr': array([0.5       , 0.75448703, 0.5       , 0.76014945, 0.77797914,\n",
       "        0.79952716, 0.8401406 , 0.84368687, 0.84665439, 0.84654713,\n",
       "        0.84706108, 0.84693371, 0.84707673, 0.84703874, 0.84711025,\n",
       "        0.84709237, 0.84711025, 0.84710801, 0.75450938, 0.76014945,\n",
       "        0.79952269, 0.84368687, 0.84654266, 0.84693371, 0.84704321,\n",
       "        0.84708566, 0.84710578, 0.84710578, 0.84711025]),\n",
       " 'mean_test_roc_auc_ovr': array([0.5       , 0.76605901, 0.5       , 0.77402662, 0.77804796,\n",
       "        0.81131188, 0.84142369, 0.84480774, 0.84773906, 0.84764565,\n",
       "        0.84791425, 0.84788073, 0.84790129, 0.84789637, 0.84790844,\n",
       "        0.84790754, 0.84790888, 0.84790933, 0.76606974, 0.77403198,\n",
       "        0.81131903, 0.84480103, 0.84765593, 0.84787849, 0.84789637,\n",
       "        0.84790978, 0.84791827, 0.84791246, 0.84790978]),\n",
       " 'std_test_roc_auc_ovr': array([0.        , 0.01869848, 0.        , 0.01929828, 0.01606857,\n",
       "        0.01867036, 0.01514948, 0.01477289, 0.01303451, 0.0132253 ,\n",
       "        0.01292429, 0.01294022, 0.01291001, 0.01290121, 0.01291069,\n",
       "        0.01290923, 0.01290589, 0.01290665, 0.01871255, 0.01929647,\n",
       "        0.01866479, 0.0147659 , 0.01322373, 0.0129478 , 0.01289954,\n",
       "        0.01290904, 0.01290962, 0.01290403, 0.01290738]),\n",
       " 'rank_test_roc_auc_ovr': array([28, 27, 28, 25, 23, 22, 20, 18, 15, 17,  2, 13, 10, 11,  8,  9,  7,\n",
       "         6, 26, 24, 21, 19, 16, 14, 11,  5,  1,  3,  4], dtype=int32),\n",
       " 'split0_test_f1_micro': array([0.662, 0.662, 0.662, 0.662, 0.662, 0.704, 0.732, 0.73 , 0.739,\n",
       "        0.735, 0.742, 0.741, 0.741, 0.741, 0.741, 0.741, 0.741, 0.741,\n",
       "        0.662, 0.662, 0.704, 0.73 , 0.735, 0.741, 0.741, 0.741, 0.741,\n",
       "        0.741, 0.741]),\n",
       " 'split1_test_f1_micro': array([0.662, 0.662, 0.662, 0.662, 0.662, 0.72 , 0.771, 0.777, 0.773,\n",
       "        0.772, 0.768, 0.769, 0.768, 0.768, 0.768, 0.768, 0.768, 0.768,\n",
       "        0.662, 0.662, 0.72 , 0.777, 0.772, 0.769, 0.768, 0.768, 0.768,\n",
       "        0.768, 0.768]),\n",
       " 'split2_test_f1_micro': array([0.662, 0.662, 0.662, 0.662, 0.662, 0.728, 0.754, 0.756, 0.772,\n",
       "        0.769, 0.772, 0.772, 0.772, 0.772, 0.772, 0.772, 0.772, 0.772,\n",
       "        0.662, 0.662, 0.728, 0.756, 0.769, 0.772, 0.772, 0.772, 0.772,\n",
       "        0.772, 0.772]),\n",
       " 'split3_test_f1_micro': array([0.662, 0.662, 0.662, 0.662, 0.662, 0.708, 0.731, 0.738, 0.735,\n",
       "        0.736, 0.735, 0.736, 0.735, 0.735, 0.735, 0.735, 0.735, 0.735,\n",
       "        0.662, 0.662, 0.708, 0.738, 0.736, 0.736, 0.735, 0.735, 0.735,\n",
       "        0.735, 0.735]),\n",
       " 'split4_test_f1_micro': array([0.662, 0.662, 0.662, 0.662, 0.662, 0.704, 0.729, 0.727, 0.728,\n",
       "        0.728, 0.727, 0.727, 0.727, 0.727, 0.727, 0.727, 0.727, 0.727,\n",
       "        0.662, 0.662, 0.704, 0.726, 0.728, 0.727, 0.727, 0.727, 0.727,\n",
       "        0.727, 0.727]),\n",
       " 'mean_test_f1_micro': array([0.662 , 0.662 , 0.662 , 0.662 , 0.662 , 0.7128, 0.7434, 0.7456,\n",
       "        0.7494, 0.748 , 0.7488, 0.749 , 0.7486, 0.7486, 0.7486, 0.7486,\n",
       "        0.7486, 0.7486, 0.662 , 0.662 , 0.7128, 0.7454, 0.748 , 0.749 ,\n",
       "        0.7486, 0.7486, 0.7486, 0.7486, 0.7486]),\n",
       " 'std_test_f1_micro': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0096    , 0.01652392, 0.01866119, 0.01918958, 0.01860108,\n",
       "        0.01799333, 0.01814387, 0.01807318, 0.01807318, 0.01807318,\n",
       "        0.01807318, 0.01807318, 0.01807318, 0.        , 0.        ,\n",
       "        0.0096    , 0.01886372, 0.01860108, 0.01814387, 0.01807318,\n",
       "        0.01807318, 0.01807318, 0.01807318, 0.01807318]),\n",
       " 'rank_test_f1_micro': array([23, 23, 23, 23, 23, 21, 20, 18,  1, 16,  4,  2,  5,  5,  5,  5,  5,\n",
       "         5, 23, 23, 21, 19, 16,  2,  5,  5,  5,  5,  5], dtype=int32)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "insured-signature",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23, 23, 23, 23, 23, 21, 20, 18,  1, 16,  4,  2,  5,  5,  5,  5,  5,\n",
       "        5, 23, 23, 21, 19, 16,  2,  5,  5,  5,  5,  5], dtype=int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.cv_results_['rank_test_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "stuffed-hometown",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 1.0,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for accuracy\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_accuracy']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "overhead-administration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 10000.0,\n",
       " 'classifier__penalty': 'l2',\n",
       " 'classifier__solver': 'lbfgs'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for roc auc\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_roc_auc_ovr']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "grave-monitor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 1.0,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for f1\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_f1_micro'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "danish-beaver",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best accuracy model\n",
    "acc_model = LogisticRegression(penalty = 'l1', C = 1.0, solver = 'saga', max_iter = 5000)\n",
    "\n",
    "# best roc auc model\n",
    "roc_model = LogisticRegression(penalty = 'l2', C = 10000.0, solver = 'lbfgs', max_iter = 5000)\n",
    "\n",
    "# best f1 model\n",
    "f1_model = LogisticRegression(penalty = 'l1', C = 1.0, solver = 'saga', max_iter = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "weighted-winner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=5000, penalty='l1', solver='saga')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# models the data\n",
    "acc_model.fit(X_train, Y_train)\n",
    "roc_model.fit(X_train, Y_train)\n",
    "f1_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "designed-zealand",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>C</th>\n",
       "      <th>penalty</th>\n",
       "      <th>solver</th>\n",
       "      <th>score_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.3380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.3380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.3380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.3380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.3380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.3380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.3380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.2872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.2546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.2520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.2510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.2514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.2514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.2514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.2514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           classifier           C penalty solver  score_acc\n",
       "0   LogisticRegression(max_iter=5000)      0.0001      l1   saga     0.3380\n",
       "1   LogisticRegression(max_iter=5000)      0.0001      l2   saga     0.3380\n",
       "2   LogisticRegression(max_iter=5000)      0.0010      l1   saga     0.3380\n",
       "3   LogisticRegression(max_iter=5000)      0.0010      l2   saga     0.3380\n",
       "4   LogisticRegression(max_iter=5000)      0.0100      l1   saga     0.3380\n",
       "5   LogisticRegression(max_iter=5000)      0.0100      l2   saga     0.2872\n",
       "6   LogisticRegression(max_iter=5000)      0.1000      l1   saga     0.2566\n",
       "7   LogisticRegression(max_iter=5000)      0.1000      l2   saga     0.2544\n",
       "8   LogisticRegression(max_iter=5000)      1.0000      l1   saga     0.2506\n",
       "9   LogisticRegression(max_iter=5000)      1.0000      l2   saga     0.2520\n",
       "10  LogisticRegression(max_iter=5000)     10.0000      l1   saga     0.2512\n",
       "11  LogisticRegression(max_iter=5000)     10.0000      l2   saga     0.2510\n",
       "12  LogisticRegression(max_iter=5000)    100.0000      l1   saga     0.2514\n",
       "13  LogisticRegression(max_iter=5000)    100.0000      l2   saga     0.2514\n",
       "14  LogisticRegression(max_iter=5000)   1000.0000      l1   saga     0.2514\n",
       "15  LogisticRegression(max_iter=5000)   1000.0000      l2   saga     0.2514\n",
       "16  LogisticRegression(max_iter=5000)  10000.0000      l1   saga     0.2514\n",
       "17  LogisticRegression(max_iter=5000)  10000.0000      l2   saga     0.2514\n",
       "18  LogisticRegression(max_iter=5000)      0.0001      l2  lbfgs     0.3380\n",
       "19  LogisticRegression(max_iter=5000)      0.0010      l2  lbfgs     0.3380\n",
       "20  LogisticRegression(max_iter=5000)      0.0100      l2  lbfgs     0.2872\n",
       "21  LogisticRegression(max_iter=5000)      0.1000      l2  lbfgs     0.2546\n",
       "22  LogisticRegression(max_iter=5000)      1.0000      l2  lbfgs     0.2520\n",
       "23  LogisticRegression(max_iter=5000)     10.0000      l2  lbfgs     0.2510\n",
       "24  LogisticRegression(max_iter=5000)    100.0000      l2  lbfgs     0.2514\n",
       "25  LogisticRegression(max_iter=5000)   1000.0000      l2  lbfgs     0.2514\n",
       "26  LogisticRegression(max_iter=5000)  10000.0000      l2  lbfgs     0.2514\n",
       "27  LogisticRegression(max_iter=5000)         NaN    none  lbfgs     0.2514\n",
       "28  LogisticRegression(max_iter=5000)         NaN    none   saga     0.2514"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = pd.DataFrame( best_model.cv_results_['params'] )\n",
    "\n",
    "results['score_acc'] = 1 - best_model.cv_results_['mean_test_accuracy']\n",
    "\n",
    "cols = results.columns.to_series().str.split('__').apply(lambda x: x[-1])\n",
    "results.columns = cols\n",
    "\n",
    "# Heat map\n",
    "sns.heatmap( results.query('solver==\"saga\"').pivot('C','penalty','score_acc'),\n",
    "             annot=True, fmt='.3f')\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "compact-healthcare",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets another 5000 random samples\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_n, Y_n, train_size = 5000, random_state = 2)\n",
    "\n",
    "# Grid Search\n",
    "pipe = Pipeline([('classifier', LogisticRegression())])\n",
    "\n",
    "search_space = [{'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['saga'],\n",
    "                 'classifier__penalty': ['l1', 'l2'],\n",
    "                 'classifier__C': np.logspace(-4, 4, 9)},\n",
    "                {'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['lbfgs'],\n",
    "                 'classifier__penalty': ['l2'],\n",
    "                 'classifier__C': np.logspace(-4, 4, 9)},\n",
    "                {'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['lbfgs','saga'],\n",
    "                 'classifier__penalty': ['none']}]\n",
    "                \n",
    "clf = GridSearchCV(pipe, search_space, cv=StratifiedKFold(n_splits=5), \n",
    "                   scoring=['accuracy', 'roc_auc_ovr', 'f1_micro'], refit=False,\n",
    "                   verbose=0)\n",
    "                \n",
    "best_model = clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "indie-sweet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.02998857, 0.10862293, 0.04048257, 0.10956979, 0.07948799,\n",
       "        0.09539418, 0.08309288, 0.09117475, 0.12296891, 0.08824272,\n",
       "        0.30968804, 0.08748875, 0.79067402, 0.2479919 , 1.18628297,\n",
       "        0.5873836 , 1.20706973, 0.84744816, 1.70134592, 2.00617523,\n",
       "        3.85136938, 6.23425245, 6.29951396, 8.03522058, 8.88846951,\n",
       "        7.11537995, 6.7382607 , 8.73282523, 1.04518313]),\n",
       " 'std_fit_time': array([0.03257373, 0.06722819, 0.03576323, 0.07651821, 0.03595007,\n",
       "        0.03840588, 0.03760614, 0.03928223, 0.0448688 , 0.04501427,\n",
       "        0.0267905 , 0.04819836, 0.04963065, 0.05240054, 0.0593546 ,\n",
       "        0.05333394, 0.05096814, 0.01950021, 0.10724526, 0.25485731,\n",
       "        0.28267362, 0.54041345, 0.65164483, 0.93989466, 0.44491343,\n",
       "        0.44758353, 0.33718295, 0.59441762, 0.07746295]),\n",
       " 'mean_score_time': array([0.40037107, 0.37114868, 0.39802594, 0.35427604, 0.33521085,\n",
       "        0.36470776, 0.38907638, 0.39747262, 0.3902998 , 0.38969731,\n",
       "        0.4072464 , 0.38829899, 0.37042665, 0.34780407, 0.38262525,\n",
       "        0.30999694, 0.2321753 , 0.27124124, 0.41693549, 0.45236931,\n",
       "        0.48695617, 0.43243628, 0.45083923, 0.48220916, 0.3894176 ,\n",
       "        0.42533402, 0.45901709, 0.45267868, 0.39214873]),\n",
       " 'std_score_time': array([0.0473616 , 0.00485139, 0.05777687, 0.05075396, 0.03501382,\n",
       "        0.01395518, 0.08385723, 0.06485775, 0.05356449, 0.09077895,\n",
       "        0.14557462, 0.0731937 , 0.07210446, 0.06847283, 0.04082085,\n",
       "        0.02669501, 0.15176871, 0.05321407, 0.06444155, 0.04557075,\n",
       "        0.11622039, 0.04529378, 0.08736081, 0.06501635, 0.06347278,\n",
       "        0.05292403, 0.0973615 , 0.0663699 , 0.0292432 ]),\n",
       " 'param_classifier': masked_array(data=[LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000)],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__C': masked_array(data=[0.0001, 0.0001, 0.001, 0.001, 0.01, 0.01, 0.1, 0.1,\n",
       "                    1.0, 1.0, 10.0, 10.0, 100.0, 100.0, 1000.0, 1000.0,\n",
       "                    10000.0, 10000.0, 0.0001, 0.001, 0.01, 0.1, 1.0, 10.0,\n",
       "                    100.0, 1000.0, 10000.0, --, --],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False,  True,  True],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__penalty': masked_array(data=['l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1',\n",
       "                    'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'none', 'none'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__solver': masked_array(data=['saga', 'saga', 'saga', 'saga', 'saga', 'saga', 'saga',\n",
       "                    'saga', 'saga', 'saga', 'saga', 'saga', 'saga', 'saga',\n",
       "                    'saga', 'saga', 'saga', 'saga', 'lbfgs', 'lbfgs',\n",
       "                    'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs',\n",
       "                    'lbfgs', 'lbfgs', 'saga'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__penalty': 'none',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__penalty': 'none',\n",
       "   'classifier__solver': 'saga'}],\n",
       " 'split0_test_accuracy': array([0.666, 0.666, 0.666, 0.666, 0.666, 0.734, 0.767, 0.767, 0.761,\n",
       "        0.764, 0.759, 0.759, 0.759, 0.759, 0.759, 0.759, 0.759, 0.759,\n",
       "        0.666, 0.666, 0.735, 0.767, 0.765, 0.759, 0.759, 0.759, 0.759,\n",
       "        0.759, 0.759]),\n",
       " 'split1_test_accuracy': array([0.666, 0.666, 0.666, 0.666, 0.666, 0.698, 0.746, 0.753, 0.752,\n",
       "        0.753, 0.75 , 0.75 , 0.75 , 0.75 , 0.75 , 0.75 , 0.75 , 0.75 ,\n",
       "        0.666, 0.666, 0.698, 0.753, 0.752, 0.75 , 0.75 , 0.75 , 0.75 ,\n",
       "        0.75 , 0.75 ]),\n",
       " 'split2_test_accuracy': array([0.666, 0.666, 0.666, 0.666, 0.666, 0.736, 0.761, 0.764, 0.766,\n",
       "        0.766, 0.765, 0.765, 0.765, 0.765, 0.765, 0.765, 0.765, 0.765,\n",
       "        0.666, 0.666, 0.736, 0.764, 0.766, 0.765, 0.765, 0.765, 0.765,\n",
       "        0.765, 0.765]),\n",
       " 'split3_test_accuracy': array([0.665, 0.665, 0.665, 0.665, 0.665, 0.709, 0.733, 0.736, 0.747,\n",
       "        0.748, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747,\n",
       "        0.665, 0.665, 0.709, 0.736, 0.748, 0.747, 0.747, 0.747, 0.747,\n",
       "        0.747, 0.747]),\n",
       " 'split4_test_accuracy': array([0.665, 0.665, 0.665, 0.665, 0.665, 0.716, 0.746, 0.748, 0.76 ,\n",
       "        0.758, 0.759, 0.759, 0.759, 0.759, 0.759, 0.759, 0.759, 0.759,\n",
       "        0.665, 0.665, 0.716, 0.748, 0.758, 0.759, 0.759, 0.759, 0.759,\n",
       "        0.759, 0.759]),\n",
       " 'mean_test_accuracy': array([0.6656, 0.6656, 0.6656, 0.6656, 0.6656, 0.7186, 0.7506, 0.7536,\n",
       "        0.7572, 0.7578, 0.756 , 0.756 , 0.756 , 0.756 , 0.756 , 0.756 ,\n",
       "        0.756 , 0.756 , 0.6656, 0.6656, 0.7188, 0.7536, 0.7578, 0.756 ,\n",
       "        0.756 , 0.756 , 0.756 , 0.756 , 0.756 ]),\n",
       " 'std_test_accuracy': array([0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.01458218, 0.01207642, 0.01121784, 0.00679412, 0.00670522,\n",
       "        0.00657267, 0.00657267, 0.00657267, 0.00657267, 0.00657267,\n",
       "        0.00657267, 0.00657267, 0.00657267, 0.0004899 , 0.0004899 ,\n",
       "        0.0147973 , 0.01121784, 0.00705408, 0.00657267, 0.00657267,\n",
       "        0.00657267, 0.00657267, 0.00657267, 0.00657267]),\n",
       " 'rank_test_accuracy': array([23, 23, 23, 23, 23, 22, 20, 18,  3,  1,  4,  4,  4,  4,  4,  4,  4,\n",
       "         4, 23, 23, 21, 18,  1,  4,  4,  4,  4,  4,  4], dtype=int32),\n",
       " 'split0_test_roc_auc_ovr': array([0.5       , 0.77929951, 0.5       , 0.79065967, 0.78288468,\n",
       "        0.83180261, 0.85854193, 0.86133813, 0.85928368, 0.85995352,\n",
       "        0.85888808, 0.85905891, 0.85884762, 0.8588701 , 0.85883863,\n",
       "        0.85884312, 0.85883863, 0.85883863, 0.7793085 , 0.79064619,\n",
       "        0.83182509, 0.86132914, 0.85994003, 0.85905891, 0.8588656 ,\n",
       "        0.85884088, 0.85883863, 0.85884312, 0.85883863]),\n",
       " 'split1_test_roc_auc_ovr': array([0.5       , 0.7635225 , 0.5       , 0.77105699, 0.77186618,\n",
       "        0.80667044, 0.84338081, 0.84553865, 0.8514997 , 0.85136933,\n",
       "        0.85195375, 0.85201219, 0.85197623, 0.85197623, 0.85198072,\n",
       "        0.85198072, 0.85198072, 0.85198072, 0.7635315 , 0.77106148,\n",
       "        0.80669292, 0.84554315, 0.85137832, 0.8520077 , 0.85197173,\n",
       "        0.85198522, 0.85198522, 0.85198971, 0.85198072]),\n",
       " 'split2_test_roc_auc_ovr': array([0.5       , 0.79065293, 0.5       , 0.79792667, 0.79419989,\n",
       "        0.82397817, 0.8494992 , 0.85225945, 0.85620651, 0.85625146,\n",
       "        0.85626045, 0.85627619, 0.85625146, 0.85626944, 0.85625146,\n",
       "        0.85624697, 0.85624697, 0.85624697, 0.79069788, 0.79792667,\n",
       "        0.82397367, 0.85226844, 0.85625596, 0.85628293, 0.85626944,\n",
       "        0.85625146, 0.85626495, 0.85625371, 0.85624921]),\n",
       " 'split3_test_roc_auc_ovr': array([0.5       , 0.76900909, 0.5       , 0.77631242, 0.77865335,\n",
       "        0.80900011, 0.83944338, 0.84105039, 0.84331276, 0.8432948 ,\n",
       "        0.84364942, 0.84359556, 0.84359107, 0.84359556, 0.84359107,\n",
       "        0.84359556, 0.84359107, 0.84359107, 0.76908091, 0.77629896,\n",
       "        0.80897767, 0.84108181, 0.84330827, 0.84360004, 0.84360902,\n",
       "        0.84359107, 0.84359107, 0.84359107, 0.84359107]),\n",
       " 'split4_test_roc_auc_ovr': array([0.5       , 0.77730221, 0.5       , 0.78410279, 0.78360004,\n",
       "        0.81298171, 0.8411267 , 0.84351251, 0.84779486, 0.84762428,\n",
       "        0.84803277, 0.84794748, 0.84807317, 0.84807541, 0.84807766,\n",
       "        0.84807766, 0.84806643, 0.84806868, 0.77731568, 0.78409831,\n",
       "        0.81297946, 0.84351251, 0.84762428, 0.84794524, 0.84806868,\n",
       "        0.84807766, 0.84807317, 0.84807766, 0.84807317]),\n",
       " 'mean_test_roc_auc_ovr': array([0.5       , 0.77595725, 0.5       , 0.78401171, 0.78224083,\n",
       "        0.81688661, 0.8463984 , 0.84873983, 0.8516195 , 0.85169868,\n",
       "        0.85175689, 0.85177806, 0.85174791, 0.85175735, 0.85174791,\n",
       "        0.85174881, 0.85174476, 0.85174521, 0.77598689, 0.78400632,\n",
       "        0.81688976, 0.84874701, 0.85170137, 0.85177896, 0.8517569 ,\n",
       "        0.85174926, 0.85175061, 0.85175105, 0.85174656]),\n",
       " 'std_test_roc_auc_ovr': array([0.        , 0.00929346, 0.        , 0.00964296, 0.00729088,\n",
       "        0.00953512, 0.00696203, 0.00731854, 0.00571707, 0.0059364 ,\n",
       "        0.00549135, 0.00556642, 0.00549141, 0.00549854, 0.00548852,\n",
       "        0.00548761, 0.00548929, 0.00548899, 0.00929561, 0.00964204,\n",
       "        0.00954058, 0.00730932, 0.00592943, 0.00556647, 0.00549425,\n",
       "        0.00548914, 0.00549138, 0.00549013, 0.00548875]),\n",
       " 'rank_test_roc_auc_ovr': array([28, 27, 28, 23, 25, 22, 20, 19, 17, 16,  5,  2, 10,  3, 11,  9, 14,\n",
       "        13, 26, 24, 21, 18, 15,  1,  4,  8,  7,  6, 12], dtype=int32),\n",
       " 'split0_test_f1_micro': array([0.666, 0.666, 0.666, 0.666, 0.666, 0.734, 0.767, 0.767, 0.761,\n",
       "        0.764, 0.759, 0.759, 0.759, 0.759, 0.759, 0.759, 0.759, 0.759,\n",
       "        0.666, 0.666, 0.735, 0.767, 0.765, 0.759, 0.759, 0.759, 0.759,\n",
       "        0.759, 0.759]),\n",
       " 'split1_test_f1_micro': array([0.666, 0.666, 0.666, 0.666, 0.666, 0.698, 0.746, 0.753, 0.752,\n",
       "        0.753, 0.75 , 0.75 , 0.75 , 0.75 , 0.75 , 0.75 , 0.75 , 0.75 ,\n",
       "        0.666, 0.666, 0.698, 0.753, 0.752, 0.75 , 0.75 , 0.75 , 0.75 ,\n",
       "        0.75 , 0.75 ]),\n",
       " 'split2_test_f1_micro': array([0.666, 0.666, 0.666, 0.666, 0.666, 0.736, 0.761, 0.764, 0.766,\n",
       "        0.766, 0.765, 0.765, 0.765, 0.765, 0.765, 0.765, 0.765, 0.765,\n",
       "        0.666, 0.666, 0.736, 0.764, 0.766, 0.765, 0.765, 0.765, 0.765,\n",
       "        0.765, 0.765]),\n",
       " 'split3_test_f1_micro': array([0.665, 0.665, 0.665, 0.665, 0.665, 0.709, 0.733, 0.736, 0.747,\n",
       "        0.748, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747,\n",
       "        0.665, 0.665, 0.709, 0.736, 0.748, 0.747, 0.747, 0.747, 0.747,\n",
       "        0.747, 0.747]),\n",
       " 'split4_test_f1_micro': array([0.665, 0.665, 0.665, 0.665, 0.665, 0.716, 0.746, 0.748, 0.76 ,\n",
       "        0.758, 0.759, 0.759, 0.759, 0.759, 0.759, 0.759, 0.759, 0.759,\n",
       "        0.665, 0.665, 0.716, 0.748, 0.758, 0.759, 0.759, 0.759, 0.759,\n",
       "        0.759, 0.759]),\n",
       " 'mean_test_f1_micro': array([0.6656, 0.6656, 0.6656, 0.6656, 0.6656, 0.7186, 0.7506, 0.7536,\n",
       "        0.7572, 0.7578, 0.756 , 0.756 , 0.756 , 0.756 , 0.756 , 0.756 ,\n",
       "        0.756 , 0.756 , 0.6656, 0.6656, 0.7188, 0.7536, 0.7578, 0.756 ,\n",
       "        0.756 , 0.756 , 0.756 , 0.756 , 0.756 ]),\n",
       " 'std_test_f1_micro': array([0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.01458218, 0.01207642, 0.01121784, 0.00679412, 0.00670522,\n",
       "        0.00657267, 0.00657267, 0.00657267, 0.00657267, 0.00657267,\n",
       "        0.00657267, 0.00657267, 0.00657267, 0.0004899 , 0.0004899 ,\n",
       "        0.0147973 , 0.01121784, 0.00705408, 0.00657267, 0.00657267,\n",
       "        0.00657267, 0.00657267, 0.00657267, 0.00657267]),\n",
       " 'rank_test_f1_micro': array([23, 23, 23, 23, 23, 22, 20, 18,  3,  1,  4,  4,  4,  4,  4,  4,  4,\n",
       "         4, 23, 23, 21, 18,  1,  4,  4,  4,  4,  4,  4], dtype=int32)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "million-myrtle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23, 23, 23, 23, 23, 22, 20, 18,  3,  1,  4,  4,  4,  4,  4,  4,  4,\n",
       "        4, 23, 23, 21, 18,  1,  4,  4,  4,  4,  4,  4], dtype=int32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.cv_results_['rank_test_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "adjusted-cabinet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 1.0,\n",
       " 'classifier__penalty': 'l2',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for accuracy\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_accuracy']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "internal-outline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 10.0,\n",
       " 'classifier__penalty': 'l2',\n",
       " 'classifier__solver': 'lbfgs'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for roc auc\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_roc_auc_ovr']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "female-opposition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 1.0,\n",
       " 'classifier__penalty': 'l2',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for f1\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_f1_micro']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "increasing-massage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best accuracy model\n",
    "acc_model = LogisticRegression(penalty = 'l2', C = 1.0, solver = 'saga', max_iter = 5000)\n",
    "\n",
    "# best roc auc model\n",
    "roc_model = LogisticRegression(penalty = 'l2', C = 10.0, solver = 'lbfgs', max_iter = 5000)\n",
    "\n",
    "# best f1 model\n",
    "f1_model = LogisticRegression(penalty = 'l2', C = 1.0, solver = 'saga', max_iter = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "immune-tribute",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=5000, solver='saga')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# models the data\n",
    "acc_model.fit(X_train, Y_train)\n",
    "roc_model.fit(X_train, Y_train)\n",
    "f1_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "synthetic-auckland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>C</th>\n",
       "      <th>penalty</th>\n",
       "      <th>solver</th>\n",
       "      <th>score_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.3344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.3344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.3344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.3344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.3344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.3344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.3344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.2812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.2464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.2422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.2440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.2440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.2440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.2440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.2440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           classifier           C penalty solver  score_acc\n",
       "0   LogisticRegression(max_iter=5000)      0.0001      l1   saga     0.3344\n",
       "1   LogisticRegression(max_iter=5000)      0.0001      l2   saga     0.3344\n",
       "2   LogisticRegression(max_iter=5000)      0.0010      l1   saga     0.3344\n",
       "3   LogisticRegression(max_iter=5000)      0.0010      l2   saga     0.3344\n",
       "4   LogisticRegression(max_iter=5000)      0.0100      l1   saga     0.3344\n",
       "5   LogisticRegression(max_iter=5000)      0.0100      l2   saga     0.2814\n",
       "6   LogisticRegression(max_iter=5000)      0.1000      l1   saga     0.2494\n",
       "7   LogisticRegression(max_iter=5000)      0.1000      l2   saga     0.2464\n",
       "8   LogisticRegression(max_iter=5000)      1.0000      l1   saga     0.2428\n",
       "9   LogisticRegression(max_iter=5000)      1.0000      l2   saga     0.2422\n",
       "10  LogisticRegression(max_iter=5000)     10.0000      l1   saga     0.2440\n",
       "11  LogisticRegression(max_iter=5000)     10.0000      l2   saga     0.2440\n",
       "12  LogisticRegression(max_iter=5000)    100.0000      l1   saga     0.2440\n",
       "13  LogisticRegression(max_iter=5000)    100.0000      l2   saga     0.2440\n",
       "14  LogisticRegression(max_iter=5000)   1000.0000      l1   saga     0.2440\n",
       "15  LogisticRegression(max_iter=5000)   1000.0000      l2   saga     0.2440\n",
       "16  LogisticRegression(max_iter=5000)  10000.0000      l1   saga     0.2440\n",
       "17  LogisticRegression(max_iter=5000)  10000.0000      l2   saga     0.2440\n",
       "18  LogisticRegression(max_iter=5000)      0.0001      l2  lbfgs     0.3344\n",
       "19  LogisticRegression(max_iter=5000)      0.0010      l2  lbfgs     0.3344\n",
       "20  LogisticRegression(max_iter=5000)      0.0100      l2  lbfgs     0.2812\n",
       "21  LogisticRegression(max_iter=5000)      0.1000      l2  lbfgs     0.2464\n",
       "22  LogisticRegression(max_iter=5000)      1.0000      l2  lbfgs     0.2422\n",
       "23  LogisticRegression(max_iter=5000)     10.0000      l2  lbfgs     0.2440\n",
       "24  LogisticRegression(max_iter=5000)    100.0000      l2  lbfgs     0.2440\n",
       "25  LogisticRegression(max_iter=5000)   1000.0000      l2  lbfgs     0.2440\n",
       "26  LogisticRegression(max_iter=5000)  10000.0000      l2  lbfgs     0.2440\n",
       "27  LogisticRegression(max_iter=5000)         NaN    none  lbfgs     0.2440\n",
       "28  LogisticRegression(max_iter=5000)         NaN    none   saga     0.2440"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = pd.DataFrame( best_model.cv_results_['params'] )\n",
    "\n",
    "results['score_acc'] = 1 - best_model.cv_results_['mean_test_accuracy']\n",
    "\n",
    "cols = results.columns.to_series().str.split('__').apply(lambda x: x[-1])\n",
    "results.columns = cols\n",
    "\n",
    "# Heat map\n",
    "sns.heatmap( results.query('solver==\"saga\"').pivot('C','penalty','score_acc'),\n",
    "             annot=True, fmt='.3f')\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "adolescent-ceramic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 0.04132781,  0.0553369 ,  0.0206233 ,  0.07869158,  0.0754611 ,\n",
       "         0.05882297,  0.07956381,  0.05916357,  0.12629533,  0.06013761,\n",
       "         0.30690532,  0.1418036 ,  0.75461044,  0.2838213 ,  1.16981878,\n",
       "         0.60323648,  1.36170797,  0.9407948 ,  1.83269782,  2.06996036,\n",
       "         3.67276406,  6.92614217, 11.89898486, 18.89465222, 15.29383435,\n",
       "        16.36994853, 11.74633565,  8.83539972,  0.99570513]),\n",
       " 'std_fit_time': array([3.91493853e-02, 3.84694583e-02, 3.95072461e-03, 4.75975780e-02,\n",
       "        4.69848978e-02, 4.15866311e-02, 3.57077259e-02, 3.85265994e-02,\n",
       "        4.88622490e-02, 1.98781913e-02, 3.69104327e-02, 6.08388970e-02,\n",
       "        4.66057086e-02, 6.83448053e-02, 4.78769707e-02, 2.75529005e-02,\n",
       "        8.06537104e-02, 5.18731308e-02, 1.83265895e-01, 2.57451393e-01,\n",
       "        2.97146866e-01, 7.58217751e-01, 1.96206772e+00, 5.54964349e+00,\n",
       "        4.79478213e+00, 4.77286227e+00, 3.77098793e+00, 6.44089886e-01,\n",
       "        4.33345657e-02]),\n",
       " 'mean_score_time': array([0.37158771, 0.34423556, 0.4200304 , 0.42406445, 0.35960503,\n",
       "        0.37216024, 0.33041458, 0.3802114 , 0.35144963, 0.35240808,\n",
       "        0.39688663, 0.3356319 , 0.3422996 , 0.33428907, 0.39832425,\n",
       "        0.37409868, 0.3492301 , 0.38433042, 0.48228583, 0.45071306,\n",
       "        0.42651954, 0.44896622, 0.47966342, 0.42279115, 0.38784189,\n",
       "        0.40847769, 0.50954847, 0.36110263, 0.36299815]),\n",
       " 'std_score_time': array([0.04537114, 0.01886107, 0.07083298, 0.07338394, 0.00795312,\n",
       "        0.05339102, 0.02529355, 0.07392904, 0.03965244, 0.05216123,\n",
       "        0.04031288, 0.09233112, 0.06644903, 0.01616786, 0.06442305,\n",
       "        0.08945376, 0.05139684, 0.11336061, 0.09529317, 0.07612039,\n",
       "        0.07656904, 0.09745223, 0.09433603, 0.09843953, 0.07181013,\n",
       "        0.05412267, 0.05113843, 0.06532013, 0.04915795]),\n",
       " 'param_classifier': masked_array(data=[LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000)],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__C': masked_array(data=[0.0001, 0.0001, 0.001, 0.001, 0.01, 0.01, 0.1, 0.1,\n",
       "                    1.0, 1.0, 10.0, 10.0, 100.0, 100.0, 1000.0, 1000.0,\n",
       "                    10000.0, 10000.0, 0.0001, 0.001, 0.01, 0.1, 1.0, 10.0,\n",
       "                    100.0, 1000.0, 10000.0, --, --],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False,  True,  True],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__penalty': masked_array(data=['l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1',\n",
       "                    'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'none', 'none'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__solver': masked_array(data=['saga', 'saga', 'saga', 'saga', 'saga', 'saga', 'saga',\n",
       "                    'saga', 'saga', 'saga', 'saga', 'saga', 'saga', 'saga',\n",
       "                    'saga', 'saga', 'saga', 'saga', 'lbfgs', 'lbfgs',\n",
       "                    'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs',\n",
       "                    'lbfgs', 'lbfgs', 'saga'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__penalty': 'none',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__penalty': 'none',\n",
       "   'classifier__solver': 'saga'}],\n",
       " 'split0_test_accuracy': array([0.665, 0.665, 0.665, 0.665, 0.665, 0.691, 0.735, 0.742, 0.748,\n",
       "        0.749, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748,\n",
       "        0.665, 0.665, 0.692, 0.742, 0.749, 0.748, 0.748, 0.748, 0.748,\n",
       "        0.748, 0.748]),\n",
       " 'split1_test_accuracy': array([0.666, 0.666, 0.666, 0.666, 0.666, 0.719, 0.753, 0.766, 0.77 ,\n",
       "        0.771, 0.77 , 0.77 , 0.77 , 0.77 , 0.77 , 0.77 , 0.77 , 0.77 ,\n",
       "        0.666, 0.666, 0.719, 0.766, 0.771, 0.77 , 0.77 , 0.77 , 0.77 ,\n",
       "        0.77 , 0.77 ]),\n",
       " 'split2_test_accuracy': array([0.666, 0.666, 0.666, 0.666, 0.666, 0.723, 0.74 , 0.746, 0.744,\n",
       "        0.743, 0.746, 0.745, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746,\n",
       "        0.666, 0.666, 0.723, 0.746, 0.742, 0.746, 0.746, 0.745, 0.746,\n",
       "        0.746, 0.746]),\n",
       " 'split3_test_accuracy': array([0.666, 0.666, 0.666, 0.666, 0.666, 0.725, 0.747, 0.75 , 0.749,\n",
       "        0.748, 0.748, 0.748, 0.747, 0.748, 0.747, 0.747, 0.747, 0.747,\n",
       "        0.666, 0.666, 0.725, 0.75 , 0.748, 0.748, 0.748, 0.747, 0.747,\n",
       "        0.747, 0.747]),\n",
       " 'split4_test_accuracy': array([0.666, 0.666, 0.666, 0.666, 0.666, 0.699, 0.741, 0.736, 0.743,\n",
       "        0.741, 0.744, 0.744, 0.744, 0.744, 0.744, 0.744, 0.744, 0.744,\n",
       "        0.666, 0.666, 0.699, 0.736, 0.741, 0.744, 0.744, 0.744, 0.744,\n",
       "        0.744, 0.744]),\n",
       " 'mean_test_accuracy': array([0.6658, 0.6658, 0.6658, 0.6658, 0.6658, 0.7114, 0.7432, 0.748 ,\n",
       "        0.7508, 0.7504, 0.7512, 0.751 , 0.751 , 0.7512, 0.751 , 0.751 ,\n",
       "        0.751 , 0.751 , 0.6658, 0.6658, 0.7116, 0.748 , 0.7502, 0.7512,\n",
       "        0.7512, 0.7508, 0.751 , 0.751 , 0.751 ]),\n",
       " 'std_test_accuracy': array([0.0004    , 0.0004    , 0.0004    , 0.0004    , 0.0004    ,\n",
       "        0.01376372, 0.00620967, 0.01011929, 0.00986712, 0.01072567,\n",
       "        0.0095163 , 0.00963328, 0.00959166, 0.0095163 , 0.00959166,\n",
       "        0.00959166, 0.00959166, 0.00959166, 0.0004    , 0.0004    ,\n",
       "        0.01346997, 0.01011929, 0.01087014, 0.0095163 , 0.0095163 ,\n",
       "        0.00970361, 0.00959166, 0.00959166, 0.00959166]),\n",
       " 'rank_test_accuracy': array([23, 23, 23, 23, 23, 22, 20, 18, 14, 16,  1,  5,  5,  1,  5,  5,  5,\n",
       "         5, 23, 23, 21, 18, 17,  1,  1, 15,  5,  5,  5], dtype=int32),\n",
       " 'split0_test_roc_auc_ovr': array([0.5       , 0.7837594 , 0.5       , 0.78770957, 0.79385703,\n",
       "        0.81425205, 0.84717091, 0.8491662 , 0.85184154, 0.8519403 ,\n",
       "        0.85217821, 0.85217372, 0.85224554, 0.85223656, 0.85225003,\n",
       "        0.85225452, 0.85225003, 0.85225003, 0.7837594 , 0.78768264,\n",
       "        0.81425654, 0.8491662 , 0.85193132, 0.85216923, 0.85223207,\n",
       "        0.85225003, 0.85225452, 0.85224105, 0.85225003]),\n",
       " 'split1_test_roc_auc_ovr': array([0.5       , 0.744484  , 0.5       , 0.75846056, 0.75453148,\n",
       "        0.80422938, 0.84759535, 0.85118951, 0.8597175 , 0.85917579,\n",
       "        0.86010412, 0.86000521, 0.86012659, 0.86012659, 0.86013109,\n",
       "        0.86013109, 0.86013109, 0.86013109, 0.74451098, 0.75845157,\n",
       "        0.8042114 , 0.85117603, 0.85918254, 0.86001421, 0.86013109,\n",
       "        0.86012659, 0.86013558, 0.86016256, 0.86013109]),\n",
       " 'split2_test_roc_auc_ovr': array([0.5       , 0.76589838, 0.5       , 0.77131323, 0.76677276,\n",
       "        0.80065095, 0.8466423 , 0.845696  , 0.85099171, 0.85059161,\n",
       "        0.85122997, 0.85114231, 0.85121424, 0.85122323, 0.85122323,\n",
       "        0.85122997, 0.85122323, 0.85122098, 0.76589389, 0.77131098,\n",
       "        0.8006532 , 0.845696  , 0.85058487, 0.8511513 , 0.85122323,\n",
       "        0.85122997, 0.85122772, 0.85123222, 0.85122098]),\n",
       " 'split3_test_roc_auc_ovr': array([0.5       , 0.76822481, 0.5       , 0.77699556, 0.78026155,\n",
       "        0.81476686, 0.84660409, 0.84592976, 0.84798871, 0.84793476,\n",
       "        0.84782013, 0.84782687, 0.84784036, 0.84784935, 0.84785834,\n",
       "        0.84784935, 0.84785834, 0.84785834, 0.7682338 , 0.77698657,\n",
       "        0.81481631, 0.84592302, 0.84793027, 0.84782687, 0.84784485,\n",
       "        0.84783136, 0.84784036, 0.84786283, 0.84785834]),\n",
       " 'split4_test_roc_auc_ovr': array([0.5       , 0.75833019, 0.5       , 0.76526676, 0.76662441,\n",
       "        0.79678031, 0.83554737, 0.83498319, 0.83707585, 0.83704663,\n",
       "        0.83680387, 0.83681286, 0.83678589, 0.83679488, 0.83679488,\n",
       "        0.83679713, 0.83679038, 0.83679038, 0.75835716, 0.76524429,\n",
       "        0.79680729, 0.83497644, 0.83704663, 0.83681286, 0.83679937,\n",
       "        0.83679488, 0.83678589, 0.83679488, 0.83679263]),\n",
       " 'mean_test_roc_auc_ovr': array([0.5       , 0.76413936, 0.5       , 0.77194914, 0.77240945,\n",
       "        0.80613591, 0.84471201, 0.84539293, 0.84952306, 0.84933782,\n",
       "        0.84962726, 0.84959219, 0.84964252, 0.84964612, 0.84965151,\n",
       "        0.84965241, 0.84965061, 0.84965016, 0.76415105, 0.77193521,\n",
       "        0.80614895, 0.84538754, 0.84933512, 0.84959489, 0.84964612,\n",
       "        0.84964657, 0.84964881, 0.84965871, 0.84965061]),\n",
       " 'std_test_roc_auc_ovr': array([0.        , 0.01284376, 0.        , 0.01000858, 0.01346488,\n",
       "        0.00723342, 0.00459688, 0.00559608, 0.00733139, 0.00718572,\n",
       "        0.00757028, 0.00753559, 0.00758555, 0.00758183, 0.00758357,\n",
       "        0.00758382, 0.00758509, 0.007585  , 0.01283351, 0.01000464,\n",
       "        0.00723989, 0.00559567, 0.00718685, 0.00753814, 0.00758146,\n",
       "        0.00758389, 0.00758921, 0.00759182, 0.00758424]),\n",
       " 'rank_test_roc_auc_ovr': array([28, 27, 28, 24, 23, 22, 20, 18, 15, 16, 12, 14, 11, 10,  3,  2,  4,\n",
       "         6, 26, 25, 21, 19, 17, 13,  9,  8,  7,  1,  4], dtype=int32),\n",
       " 'split0_test_f1_micro': array([0.665, 0.665, 0.665, 0.665, 0.665, 0.691, 0.735, 0.742, 0.748,\n",
       "        0.749, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748,\n",
       "        0.665, 0.665, 0.692, 0.742, 0.749, 0.748, 0.748, 0.748, 0.748,\n",
       "        0.748, 0.748]),\n",
       " 'split1_test_f1_micro': array([0.666, 0.666, 0.666, 0.666, 0.666, 0.719, 0.753, 0.766, 0.77 ,\n",
       "        0.771, 0.77 , 0.77 , 0.77 , 0.77 , 0.77 , 0.77 , 0.77 , 0.77 ,\n",
       "        0.666, 0.666, 0.719, 0.766, 0.771, 0.77 , 0.77 , 0.77 , 0.77 ,\n",
       "        0.77 , 0.77 ]),\n",
       " 'split2_test_f1_micro': array([0.666, 0.666, 0.666, 0.666, 0.666, 0.723, 0.74 , 0.746, 0.744,\n",
       "        0.743, 0.746, 0.745, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746,\n",
       "        0.666, 0.666, 0.723, 0.746, 0.742, 0.746, 0.746, 0.745, 0.746,\n",
       "        0.746, 0.746]),\n",
       " 'split3_test_f1_micro': array([0.666, 0.666, 0.666, 0.666, 0.666, 0.725, 0.747, 0.75 , 0.749,\n",
       "        0.748, 0.748, 0.748, 0.747, 0.748, 0.747, 0.747, 0.747, 0.747,\n",
       "        0.666, 0.666, 0.725, 0.75 , 0.748, 0.748, 0.748, 0.747, 0.747,\n",
       "        0.747, 0.747]),\n",
       " 'split4_test_f1_micro': array([0.666, 0.666, 0.666, 0.666, 0.666, 0.699, 0.741, 0.736, 0.743,\n",
       "        0.741, 0.744, 0.744, 0.744, 0.744, 0.744, 0.744, 0.744, 0.744,\n",
       "        0.666, 0.666, 0.699, 0.736, 0.741, 0.744, 0.744, 0.744, 0.744,\n",
       "        0.744, 0.744]),\n",
       " 'mean_test_f1_micro': array([0.6658, 0.6658, 0.6658, 0.6658, 0.6658, 0.7114, 0.7432, 0.748 ,\n",
       "        0.7508, 0.7504, 0.7512, 0.751 , 0.751 , 0.7512, 0.751 , 0.751 ,\n",
       "        0.751 , 0.751 , 0.6658, 0.6658, 0.7116, 0.748 , 0.7502, 0.7512,\n",
       "        0.7512, 0.7508, 0.751 , 0.751 , 0.751 ]),\n",
       " 'std_test_f1_micro': array([0.0004    , 0.0004    , 0.0004    , 0.0004    , 0.0004    ,\n",
       "        0.01376372, 0.00620967, 0.01011929, 0.00986712, 0.01072567,\n",
       "        0.0095163 , 0.00963328, 0.00959166, 0.0095163 , 0.00959166,\n",
       "        0.00959166, 0.00959166, 0.00959166, 0.0004    , 0.0004    ,\n",
       "        0.01346997, 0.01011929, 0.01087014, 0.0095163 , 0.0095163 ,\n",
       "        0.00970361, 0.00959166, 0.00959166, 0.00959166]),\n",
       " 'rank_test_f1_micro': array([23, 23, 23, 23, 23, 22, 20, 18, 14, 16,  1,  5,  5,  1,  5,  5,  5,\n",
       "         5, 23, 23, 21, 18, 17,  1,  1, 14,  5,  5,  5], dtype=int32)}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gets another 5000 random samples\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_n, Y_n, train_size = 5000, random_state = 3)\n",
    "\n",
    "# Grid Search\n",
    "pipe = Pipeline([('classifier', LogisticRegression())])\n",
    "\n",
    "search_space = [{'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['saga'],\n",
    "                 'classifier__penalty': ['l1', 'l2'],\n",
    "                 'classifier__C': np.logspace(-4, 4, 9)},\n",
    "                {'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['lbfgs'],\n",
    "                 'classifier__penalty': ['l2'],\n",
    "                 'classifier__C': np.logspace(-4, 4, 9)},\n",
    "                {'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['lbfgs','saga'],\n",
    "                 'classifier__penalty': ['none']}]\n",
    "                \n",
    "clf = GridSearchCV(pipe, search_space, cv=StratifiedKFold(n_splits=5), \n",
    "                   scoring=['accuracy', 'roc_auc_ovr', 'f1_micro'], refit=False,\n",
    "                   verbose=0)\n",
    "                \n",
    "best_model = clf.fit(X_train, Y_train)\n",
    "\n",
    "best_model.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "realistic-bermuda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23, 23, 23, 23, 23, 22, 20, 18, 14, 16,  1,  5,  5,  1,  5,  5,  5,\n",
       "        5, 23, 23, 21, 18, 17,  1,  1, 15,  5,  5,  5], dtype=int32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.cv_results_['rank_test_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "molecular-recipient",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 10.0,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for accuracy\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_accuracy']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "superb-circular",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__penalty': 'none',\n",
       " 'classifier__solver': 'lbfgs'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for roc auc\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_roc_auc_ovr']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "wicked-husband",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 10.0,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for f1\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_f1_micro']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "interim-acoustic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best accuracy model\n",
    "acc_model = LogisticRegression(penalty = 'l1', C = 10.0, solver = 'saga', max_iter = 5000)\n",
    "\n",
    "# best roc auc model\n",
    "roc_model = LogisticRegression(penalty = 'none', solver = 'lbfgs', max_iter = 5000)\n",
    "\n",
    "# best f1 model\n",
    "f1_model = LogisticRegression(penalty = 'l1', C = 10.0, solver = 'saga', max_iter = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "passing-check",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10.0, max_iter=5000, penalty='l1', solver='saga')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# models the data\n",
    "acc_model.fit(X_train, Y_train)\n",
    "roc_model.fit(X_train, Y_train)\n",
    "f1_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "listed-sugar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>C</th>\n",
       "      <th>penalty</th>\n",
       "      <th>solver</th>\n",
       "      <th>score_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.3342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.3342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.3342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.3342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.3342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.3342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.3342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.2884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.2520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.2498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.2488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.2488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.2492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.2490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.2490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           classifier           C penalty solver  score_acc\n",
       "0   LogisticRegression(max_iter=5000)      0.0001      l1   saga     0.3342\n",
       "1   LogisticRegression(max_iter=5000)      0.0001      l2   saga     0.3342\n",
       "2   LogisticRegression(max_iter=5000)      0.0010      l1   saga     0.3342\n",
       "3   LogisticRegression(max_iter=5000)      0.0010      l2   saga     0.3342\n",
       "4   LogisticRegression(max_iter=5000)      0.0100      l1   saga     0.3342\n",
       "5   LogisticRegression(max_iter=5000)      0.0100      l2   saga     0.2886\n",
       "6   LogisticRegression(max_iter=5000)      0.1000      l1   saga     0.2568\n",
       "7   LogisticRegression(max_iter=5000)      0.1000      l2   saga     0.2520\n",
       "8   LogisticRegression(max_iter=5000)      1.0000      l1   saga     0.2492\n",
       "9   LogisticRegression(max_iter=5000)      1.0000      l2   saga     0.2496\n",
       "10  LogisticRegression(max_iter=5000)     10.0000      l1   saga     0.2488\n",
       "11  LogisticRegression(max_iter=5000)     10.0000      l2   saga     0.2490\n",
       "12  LogisticRegression(max_iter=5000)    100.0000      l1   saga     0.2490\n",
       "13  LogisticRegression(max_iter=5000)    100.0000      l2   saga     0.2488\n",
       "14  LogisticRegression(max_iter=5000)   1000.0000      l1   saga     0.2490\n",
       "15  LogisticRegression(max_iter=5000)   1000.0000      l2   saga     0.2490\n",
       "16  LogisticRegression(max_iter=5000)  10000.0000      l1   saga     0.2490\n",
       "17  LogisticRegression(max_iter=5000)  10000.0000      l2   saga     0.2490\n",
       "18  LogisticRegression(max_iter=5000)      0.0001      l2  lbfgs     0.3342\n",
       "19  LogisticRegression(max_iter=5000)      0.0010      l2  lbfgs     0.3342\n",
       "20  LogisticRegression(max_iter=5000)      0.0100      l2  lbfgs     0.2884\n",
       "21  LogisticRegression(max_iter=5000)      0.1000      l2  lbfgs     0.2520\n",
       "22  LogisticRegression(max_iter=5000)      1.0000      l2  lbfgs     0.2498\n",
       "23  LogisticRegression(max_iter=5000)     10.0000      l2  lbfgs     0.2488\n",
       "24  LogisticRegression(max_iter=5000)    100.0000      l2  lbfgs     0.2488\n",
       "25  LogisticRegression(max_iter=5000)   1000.0000      l2  lbfgs     0.2492\n",
       "26  LogisticRegression(max_iter=5000)  10000.0000      l2  lbfgs     0.2490\n",
       "27  LogisticRegression(max_iter=5000)         NaN    none  lbfgs     0.2490\n",
       "28  LogisticRegression(max_iter=5000)         NaN    none   saga     0.2490"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = pd.DataFrame( best_model.cv_results_['params'] )\n",
    "\n",
    "results['score_acc'] = 1 - best_model.cv_results_['mean_test_accuracy']\n",
    "\n",
    "cols = results.columns.to_series().str.split('__').apply(lambda x: x[-1])\n",
    "results.columns = cols\n",
    "\n",
    "# Heat map\n",
    "sns.heatmap( results.query('solver==\"saga\"').pivot('C','penalty','score_acc'),\n",
    "             annot=True, fmt='.3f')\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "floating-illness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.01268663, 0.06456165, 0.05586877, 0.07757716, 0.14525533,\n",
       "        0.1257731 , 0.07584252, 0.12821651, 0.10619478, 0.06906295,\n",
       "        0.25276761, 0.07654109, 0.77723947, 0.26902099, 1.12408385,\n",
       "        0.55224543, 1.22705922, 0.93094144, 1.88278441, 2.03703909,\n",
       "        3.65650449, 6.15462947, 9.47885423, 7.94882188, 9.7581264 ,\n",
       "        6.37127547, 7.53912578, 9.05100579, 0.99063253]),\n",
       " 'std_fit_time': array([0.00359346, 0.05041488, 0.04962205, 0.04043397, 0.03633988,\n",
       "        0.04527296, 0.03594642, 0.01414065, 0.03104086, 0.03743426,\n",
       "        0.04181683, 0.05442691, 0.04120711, 0.0751404 , 0.04241632,\n",
       "        0.01922817, 0.07207089, 0.06847979, 0.08631932, 0.17383194,\n",
       "        0.3271211 , 0.19472231, 0.66458839, 1.07562786, 0.89882124,\n",
       "        0.42186721, 0.58631491, 0.48963498, 0.0529984 ]),\n",
       " 'mean_score_time': array([0.37255921, 0.34964457, 0.40596867, 0.35757117, 0.34041719,\n",
       "        0.39353485, 0.34076033, 0.36993847, 0.37828689, 0.34048023,\n",
       "        0.3637599 , 0.35217981, 0.37627954, 0.34491916, 0.39646111,\n",
       "        0.30347004, 0.33197761, 0.33185267, 0.43205767, 0.3661797 ,\n",
       "        0.42308092, 0.48073945, 0.39794598, 0.38813314, 0.44050274,\n",
       "        0.42409849, 0.46054144, 0.39250073, 0.35819802]),\n",
       " 'std_score_time': array([0.02646897, 0.04843655, 0.14811243, 0.0096272 , 0.03596614,\n",
       "        0.08429444, 0.02592638, 0.02461462, 0.06100418, 0.016421  ,\n",
       "        0.02281796, 0.04534542, 0.07225922, 0.04664892, 0.03923326,\n",
       "        0.11745513, 0.03693551, 0.07919987, 0.0757577 , 0.07698599,\n",
       "        0.0686029 , 0.06669929, 0.05614383, 0.02806683, 0.03670268,\n",
       "        0.04638162, 0.07690552, 0.04243312, 0.01651805]),\n",
       " 'param_classifier': masked_array(data=[LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000)],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__C': masked_array(data=[0.0001, 0.0001, 0.001, 0.001, 0.01, 0.01, 0.1, 0.1,\n",
       "                    1.0, 1.0, 10.0, 10.0, 100.0, 100.0, 1000.0, 1000.0,\n",
       "                    10000.0, 10000.0, 0.0001, 0.001, 0.01, 0.1, 1.0, 10.0,\n",
       "                    100.0, 1000.0, 10000.0, --, --],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False,  True,  True],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__penalty': masked_array(data=['l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1',\n",
       "                    'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'none', 'none'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__solver': masked_array(data=['saga', 'saga', 'saga', 'saga', 'saga', 'saga', 'saga',\n",
       "                    'saga', 'saga', 'saga', 'saga', 'saga', 'saga', 'saga',\n",
       "                    'saga', 'saga', 'saga', 'saga', 'lbfgs', 'lbfgs',\n",
       "                    'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs',\n",
       "                    'lbfgs', 'lbfgs', 'saga'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__penalty': 'none',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__penalty': 'none',\n",
       "   'classifier__solver': 'saga'}],\n",
       " 'split0_test_accuracy': array([0.674, 0.674, 0.674, 0.674, 0.674, 0.697, 0.76 , 0.758, 0.757,\n",
       "        0.757, 0.753, 0.754, 0.753, 0.754, 0.753, 0.753, 0.753, 0.753,\n",
       "        0.674, 0.674, 0.697, 0.758, 0.757, 0.754, 0.754, 0.753, 0.753,\n",
       "        0.753, 0.753]),\n",
       " 'split1_test_accuracy': array([0.674, 0.674, 0.674, 0.674, 0.674, 0.721, 0.772, 0.762, 0.755,\n",
       "        0.754, 0.758, 0.758, 0.758, 0.758, 0.758, 0.758, 0.758, 0.758,\n",
       "        0.674, 0.674, 0.721, 0.762, 0.754, 0.758, 0.758, 0.758, 0.758,\n",
       "        0.758, 0.758]),\n",
       " 'split2_test_accuracy': array([0.674, 0.674, 0.674, 0.674, 0.674, 0.709, 0.752, 0.75 , 0.745,\n",
       "        0.746, 0.744, 0.745, 0.744, 0.744, 0.744, 0.744, 0.744, 0.744,\n",
       "        0.674, 0.674, 0.709, 0.75 , 0.746, 0.745, 0.744, 0.744, 0.744,\n",
       "        0.744, 0.744]),\n",
       " 'split3_test_accuracy': array([0.674, 0.674, 0.674, 0.674, 0.674, 0.717, 0.76 , 0.754, 0.75 ,\n",
       "        0.749, 0.751, 0.751, 0.751, 0.751, 0.751, 0.751, 0.751, 0.751,\n",
       "        0.674, 0.674, 0.717, 0.754, 0.749, 0.751, 0.751, 0.751, 0.751,\n",
       "        0.751, 0.751]),\n",
       " 'split4_test_accuracy': array([0.673, 0.673, 0.673, 0.673, 0.673, 0.726, 0.759, 0.763, 0.767,\n",
       "        0.766, 0.766, 0.767, 0.766, 0.766, 0.766, 0.766, 0.766, 0.766,\n",
       "        0.673, 0.673, 0.726, 0.763, 0.766, 0.767, 0.766, 0.766, 0.766,\n",
       "        0.766, 0.766]),\n",
       " 'mean_test_accuracy': array([0.6738, 0.6738, 0.6738, 0.6738, 0.6738, 0.714 , 0.7606, 0.7574,\n",
       "        0.7548, 0.7544, 0.7544, 0.755 , 0.7544, 0.7546, 0.7544, 0.7544,\n",
       "        0.7544, 0.7544, 0.6738, 0.6738, 0.714 , 0.7574, 0.7544, 0.755 ,\n",
       "        0.7546, 0.7544, 0.7544, 0.7544, 0.7544]),\n",
       " 'std_test_accuracy': array([0.0004    , 0.0004    , 0.0004    , 0.0004    , 0.0004    ,\n",
       "        0.01015874, 0.00643739, 0.00488262, 0.00738647, 0.0069455 ,\n",
       "        0.00733757, 0.00734847, 0.00733757, 0.00731027, 0.00733757,\n",
       "        0.00733757, 0.00733757, 0.00733757, 0.0004    , 0.0004    ,\n",
       "        0.01015874, 0.00488262, 0.0069455 , 0.00734847, 0.00731027,\n",
       "        0.00733757, 0.00733757, 0.00733757, 0.00733757]),\n",
       " 'rank_test_accuracy': array([23, 23, 23, 23, 23, 21,  1,  2,  6,  9, 11,  4, 11,  7, 11, 11, 11,\n",
       "        11, 23, 23, 21,  2,  9,  4,  7, 11, 11, 11, 11], dtype=int32),\n",
       " 'split0_test_roc_auc_ovr': array([0.5       , 0.77276037, 0.5       , 0.7781626 , 0.77527717,\n",
       "        0.80854618, 0.84686243, 0.85039868, 0.85487703, 0.85479056,\n",
       "        0.85547778, 0.85543227, 0.85558246, 0.8555688 , 0.85557791,\n",
       "        0.85557336, 0.85557791, 0.85557791, 0.77276492, 0.77817171,\n",
       "        0.80854618, 0.85038503, 0.85479056, 0.85543682, 0.8555688 ,\n",
       "        0.85559156, 0.85557791, 0.85557791, 0.85557791]),\n",
       " 'split1_test_roc_auc_ovr': array([0.5       , 0.79326337, 0.5       , 0.80336695, 0.79375489,\n",
       "        0.83465621, 0.85937813, 0.85957838, 0.85904134, 0.85893667,\n",
       "        0.85874552, 0.85871366, 0.85870911, 0.85872276, 0.85873186,\n",
       "        0.85871366, 0.85873186, 0.85873186, 0.79325426, 0.8033715 ,\n",
       "        0.83465621, 0.85956473, 0.85893667, 0.85870911, 0.85872276,\n",
       "        0.85872731, 0.85871821, 0.85873186, 0.85873186]),\n",
       " 'split2_test_roc_auc_ovr': array([0.5       , 0.76376272, 0.5       , 0.7714906 , 0.77104458,\n",
       "        0.80119149, 0.83137709, 0.82954525, 0.8303235 , 0.83015055,\n",
       "        0.83010504, 0.83009594, 0.83010504, 0.83009139, 0.83010504,\n",
       "        0.83011414, 0.83010504, 0.83010049, 0.76374907, 0.7715088 ,\n",
       "        0.80118239, 0.82954525, 0.830146  , 0.83008684, 0.83009139,\n",
       "        0.83010049, 0.83010049, 0.83009594, 0.83010504]),\n",
       " 'split3_test_roc_auc_ovr': array([0.5       , 0.78316888, 0.5       , 0.79061004, 0.78113679,\n",
       "        0.81761665, 0.84369937, 0.84725155, 0.84943611, 0.84964319,\n",
       "        0.84952486, 0.84955672, 0.84953396, 0.84952941, 0.84952941,\n",
       "        0.84952941, 0.84953396, 0.84953396, 0.78318254, 0.79059638,\n",
       "        0.81760982, 0.84724017, 0.84964319, 0.84955217, 0.84953396,\n",
       "        0.84953396, 0.84952941, 0.84952941, 0.84953396]),\n",
       " 'split4_test_roc_auc_ovr': array([0.5       , 0.78301321, 0.5       , 0.79237837, 0.7793553 ,\n",
       "        0.82456798, 0.85426749, 0.85611007, 0.86005653, 0.85977026,\n",
       "        0.85976117, 0.8597339 , 0.85975662, 0.85974754, 0.85976117,\n",
       "        0.85976571, 0.85975662, 0.85975662, 0.78300412, 0.79238746,\n",
       "        0.82455435, 0.85612143, 0.8597748 , 0.85972936, 0.85975208,\n",
       "        0.85976571, 0.85975208, 0.85974981, 0.85975208]),\n",
       " 'mean_test_roc_auc_ovr': array([0.5       , 0.77919371, 0.5       , 0.78720171, 0.78011375,\n",
       "        0.8173157 , 0.8471169 , 0.84857679, 0.8507469 , 0.85065824,\n",
       "        0.85072287, 0.8507065 , 0.85073744, 0.85073198, 0.85074108,\n",
       "        0.85073926, 0.85074108, 0.85074017, 0.77919098, 0.78720717,\n",
       "        0.81730979, 0.84857132, 0.85065824, 0.85070286, 0.8507338 ,\n",
       "        0.85074381, 0.85073562, 0.85073699, 0.85074017]),\n",
       " 'std_test_roc_auc_ovr': array([0.        , 0.01007819, 0.        , 0.01120959, 0.00765957,\n",
       "        0.01174967, 0.00960161, 0.01044089, 0.01087528, 0.01086492,\n",
       "        0.01091048, 0.01090008, 0.0109134 , 0.01091795, 0.01091718,\n",
       "        0.01091142, 0.01091633, 0.01091805, 0.01007964, 0.01120434,\n",
       "        0.01175045, 0.01043946, 0.0108674 , 0.01090259, 0.0109186 ,\n",
       "        0.01092009, 0.0109154 , 0.01091874, 0.01091557]),\n",
       " 'rank_test_roc_auc_ovr': array([28, 26, 28, 24, 25, 21, 20, 18,  1, 16, 13, 14,  8, 12,  4,  7,  3,\n",
       "         6, 27, 23, 22, 19, 17, 15, 11,  2, 10,  9,  5], dtype=int32),\n",
       " 'split0_test_f1_micro': array([0.674, 0.674, 0.674, 0.674, 0.674, 0.697, 0.76 , 0.758, 0.757,\n",
       "        0.757, 0.753, 0.754, 0.753, 0.754, 0.753, 0.753, 0.753, 0.753,\n",
       "        0.674, 0.674, 0.697, 0.758, 0.757, 0.754, 0.754, 0.753, 0.753,\n",
       "        0.753, 0.753]),\n",
       " 'split1_test_f1_micro': array([0.674, 0.674, 0.674, 0.674, 0.674, 0.721, 0.772, 0.762, 0.755,\n",
       "        0.754, 0.758, 0.758, 0.758, 0.758, 0.758, 0.758, 0.758, 0.758,\n",
       "        0.674, 0.674, 0.721, 0.762, 0.754, 0.758, 0.758, 0.758, 0.758,\n",
       "        0.758, 0.758]),\n",
       " 'split2_test_f1_micro': array([0.674, 0.674, 0.674, 0.674, 0.674, 0.709, 0.752, 0.75 , 0.745,\n",
       "        0.746, 0.744, 0.745, 0.744, 0.744, 0.744, 0.744, 0.744, 0.744,\n",
       "        0.674, 0.674, 0.709, 0.75 , 0.746, 0.745, 0.744, 0.744, 0.744,\n",
       "        0.744, 0.744]),\n",
       " 'split3_test_f1_micro': array([0.674, 0.674, 0.674, 0.674, 0.674, 0.717, 0.76 , 0.754, 0.75 ,\n",
       "        0.749, 0.751, 0.751, 0.751, 0.751, 0.751, 0.751, 0.751, 0.751,\n",
       "        0.674, 0.674, 0.717, 0.754, 0.749, 0.751, 0.751, 0.751, 0.751,\n",
       "        0.751, 0.751]),\n",
       " 'split4_test_f1_micro': array([0.673, 0.673, 0.673, 0.673, 0.673, 0.726, 0.759, 0.763, 0.767,\n",
       "        0.766, 0.766, 0.767, 0.766, 0.766, 0.766, 0.766, 0.766, 0.766,\n",
       "        0.673, 0.673, 0.726, 0.763, 0.766, 0.767, 0.766, 0.766, 0.766,\n",
       "        0.766, 0.766]),\n",
       " 'mean_test_f1_micro': array([0.6738, 0.6738, 0.6738, 0.6738, 0.6738, 0.714 , 0.7606, 0.7574,\n",
       "        0.7548, 0.7544, 0.7544, 0.755 , 0.7544, 0.7546, 0.7544, 0.7544,\n",
       "        0.7544, 0.7544, 0.6738, 0.6738, 0.714 , 0.7574, 0.7544, 0.755 ,\n",
       "        0.7546, 0.7544, 0.7544, 0.7544, 0.7544]),\n",
       " 'std_test_f1_micro': array([0.0004    , 0.0004    , 0.0004    , 0.0004    , 0.0004    ,\n",
       "        0.01015874, 0.00643739, 0.00488262, 0.00738647, 0.0069455 ,\n",
       "        0.00733757, 0.00734847, 0.00733757, 0.00731027, 0.00733757,\n",
       "        0.00733757, 0.00733757, 0.00733757, 0.0004    , 0.0004    ,\n",
       "        0.01015874, 0.00488262, 0.0069455 , 0.00734847, 0.00731027,\n",
       "        0.00733757, 0.00733757, 0.00733757, 0.00733757]),\n",
       " 'rank_test_f1_micro': array([23, 23, 23, 23, 23, 21,  1,  2,  6,  9, 11,  4, 11,  7, 11, 11, 11,\n",
       "        11, 23, 23, 21,  2,  9,  4,  7, 11, 11, 11, 11], dtype=int32)}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gets another 5000 random samples\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_n, Y_n, train_size = 5000, random_state = 4)\n",
    "\n",
    "# Grid Search\n",
    "pipe = Pipeline([('classifier', LogisticRegression())])\n",
    "\n",
    "search_space = [{'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['saga'],\n",
    "                 'classifier__penalty': ['l1', 'l2'],\n",
    "                 'classifier__C': np.logspace(-4, 4, 9)},\n",
    "                {'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['lbfgs'],\n",
    "                 'classifier__penalty': ['l2'],\n",
    "                 'classifier__C': np.logspace(-4, 4, 9)},\n",
    "                {'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['lbfgs','saga'],\n",
    "                 'classifier__penalty': ['none']}]\n",
    "                \n",
    "clf = GridSearchCV(pipe, search_space, cv=StratifiedKFold(n_splits=5), \n",
    "                   scoring=['accuracy', 'roc_auc_ovr', 'f1_micro'], refit=False,\n",
    "                   verbose=0)\n",
    "                \n",
    "best_model = clf.fit(X_train, Y_train)\n",
    "\n",
    "best_model.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "compatible-bishop",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23, 23, 23, 23, 23, 21,  1,  2,  6,  9, 11,  4, 11,  7, 11, 11, 11,\n",
       "       11, 23, 23, 21,  2,  9,  4,  7, 11, 11, 11, 11], dtype=int32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.cv_results_['rank_test_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "married-politics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 0.1,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for accuracy\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_accuracy']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "accredited-centre",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 1.0,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for roc auc\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_roc_auc_ovr']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ready-basic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 0.1,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for f1\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_f1_micro']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "lonely-bronze",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best accuracy model\n",
    "acc_model = LogisticRegression(penalty = 'l1', C = 0.1, solver = 'saga', max_iter = 5000)\n",
    "\n",
    "# best roc auc model\n",
    "roc_model = LogisticRegression(penalty = 'l1', C = 1.0, solver = 'saga', max_iter = 5000)\n",
    "\n",
    "# best f1 model\n",
    "f1_model = LogisticRegression(penalty = 'l1', C = 0.1, solver = 'saga', max_iter = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "final-popularity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, max_iter=5000, penalty='l1', solver='saga')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# models the data\n",
    "acc_model.fit(X_train, Y_train)\n",
    "roc_model.fit(X_train, Y_train)\n",
    "f1_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "rotary-summit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>C</th>\n",
       "      <th>penalty</th>\n",
       "      <th>solver</th>\n",
       "      <th>score_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.3262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.3262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.3262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.3262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.3262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.3262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.3262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.2860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.2426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.2456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.2450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.2454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.2456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.2456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.2456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           classifier           C penalty solver  score_acc\n",
       "0   LogisticRegression(max_iter=5000)      0.0001      l1   saga     0.3262\n",
       "1   LogisticRegression(max_iter=5000)      0.0001      l2   saga     0.3262\n",
       "2   LogisticRegression(max_iter=5000)      0.0010      l1   saga     0.3262\n",
       "3   LogisticRegression(max_iter=5000)      0.0010      l2   saga     0.3262\n",
       "4   LogisticRegression(max_iter=5000)      0.0100      l1   saga     0.3262\n",
       "5   LogisticRegression(max_iter=5000)      0.0100      l2   saga     0.2860\n",
       "6   LogisticRegression(max_iter=5000)      0.1000      l1   saga     0.2394\n",
       "7   LogisticRegression(max_iter=5000)      0.1000      l2   saga     0.2426\n",
       "8   LogisticRegression(max_iter=5000)      1.0000      l1   saga     0.2452\n",
       "9   LogisticRegression(max_iter=5000)      1.0000      l2   saga     0.2456\n",
       "10  LogisticRegression(max_iter=5000)     10.0000      l1   saga     0.2456\n",
       "11  LogisticRegression(max_iter=5000)     10.0000      l2   saga     0.2450\n",
       "12  LogisticRegression(max_iter=5000)    100.0000      l1   saga     0.2456\n",
       "13  LogisticRegression(max_iter=5000)    100.0000      l2   saga     0.2454\n",
       "14  LogisticRegression(max_iter=5000)   1000.0000      l1   saga     0.2456\n",
       "15  LogisticRegression(max_iter=5000)   1000.0000      l2   saga     0.2456\n",
       "16  LogisticRegression(max_iter=5000)  10000.0000      l1   saga     0.2456\n",
       "17  LogisticRegression(max_iter=5000)  10000.0000      l2   saga     0.2456\n",
       "18  LogisticRegression(max_iter=5000)      0.0001      l2  lbfgs     0.3262\n",
       "19  LogisticRegression(max_iter=5000)      0.0010      l2  lbfgs     0.3262\n",
       "20  LogisticRegression(max_iter=5000)      0.0100      l2  lbfgs     0.2860\n",
       "21  LogisticRegression(max_iter=5000)      0.1000      l2  lbfgs     0.2426\n",
       "22  LogisticRegression(max_iter=5000)      1.0000      l2  lbfgs     0.2456\n",
       "23  LogisticRegression(max_iter=5000)     10.0000      l2  lbfgs     0.2450\n",
       "24  LogisticRegression(max_iter=5000)    100.0000      l2  lbfgs     0.2454\n",
       "25  LogisticRegression(max_iter=5000)   1000.0000      l2  lbfgs     0.2456\n",
       "26  LogisticRegression(max_iter=5000)  10000.0000      l2  lbfgs     0.2456\n",
       "27  LogisticRegression(max_iter=5000)         NaN    none  lbfgs     0.2456\n",
       "28  LogisticRegression(max_iter=5000)         NaN    none   saga     0.2456"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = pd.DataFrame( best_model.cv_results_['params'] )\n",
    "\n",
    "results['score_acc'] = 1 - best_model.cv_results_['mean_test_accuracy']\n",
    "\n",
    "cols = results.columns.to_series().str.split('__').apply(lambda x: x[-1])\n",
    "results.columns = cols\n",
    "\n",
    "# Heat map\n",
    "sns.heatmap( results.query('solver==\"saga\"').pivot('C','penalty','score_acc'),\n",
    "             annot=True, fmt='.3f')\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "clear-favor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.03211646, 0.05520263, 0.05361867, 0.07580819, 0.10961943,\n",
       "        0.09246459, 0.05646873, 0.10602975, 0.06320229, 0.05404658,\n",
       "        0.28535981, 0.10385919, 0.76024055, 0.20742297, 1.12947741,\n",
       "        0.55214663, 1.17560663, 0.88086915, 1.96779518, 2.06159544,\n",
       "        3.71086445, 6.59772124, 6.53578658, 8.28970447, 8.92674985,\n",
       "        6.48857708, 7.32077894, 8.79292727, 1.05867271]),\n",
       " 'std_fit_time': array([0.03826974, 0.03294739, 0.07392525, 0.07152151, 0.03937377,\n",
       "        0.04768518, 0.01050633, 0.05801818, 0.00360056, 0.02969555,\n",
       "        0.03034425, 0.05272746, 0.05215864, 0.03329252, 0.06156623,\n",
       "        0.02628047, 0.04822373, 0.04348587, 0.17892352, 0.22838283,\n",
       "        0.2219246 , 0.5711834 , 1.32437809, 0.96684709, 0.65446314,\n",
       "        0.14876899, 0.75567363, 0.44072776, 0.05411436]),\n",
       " 'mean_score_time': array([0.41992588, 0.41936936, 0.32443061, 0.37987065, 0.40855098,\n",
       "        0.35272288, 0.31375937, 0.3701293 , 0.36884742, 0.3289115 ,\n",
       "        0.37319646, 0.34124932, 0.3698164 , 0.36887565, 0.30838327,\n",
       "        0.33084359, 0.29551592, 0.31442389, 0.53549886, 0.47892575,\n",
       "        0.38747025, 0.41377587, 0.43196282, 0.45592365, 0.45510879,\n",
       "        0.43702607, 0.46812143, 0.42916102, 0.33707523]),\n",
       " 'std_score_time': array([0.04403908, 0.11146577, 0.02843099, 0.03944853, 0.08010975,\n",
       "        0.06258039, 0.05522281, 0.05323335, 0.08378562, 0.02941897,\n",
       "        0.04496882, 0.064396  , 0.05185328, 0.05383157, 0.03079045,\n",
       "        0.02872996, 0.02708896, 0.08035542, 0.11034527, 0.07138471,\n",
       "        0.04094452, 0.1013172 , 0.03752103, 0.06032147, 0.04503331,\n",
       "        0.05844052, 0.05088785, 0.07137466, 0.01747199]),\n",
       " 'param_classifier': masked_array(data=[LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000)],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__C': masked_array(data=[0.0001, 0.0001, 0.001, 0.001, 0.01, 0.01, 0.1, 0.1,\n",
       "                    1.0, 1.0, 10.0, 10.0, 100.0, 100.0, 1000.0, 1000.0,\n",
       "                    10000.0, 10000.0, 0.0001, 0.001, 0.01, 0.1, 1.0, 10.0,\n",
       "                    100.0, 1000.0, 10000.0, --, --],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False,  True,  True],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__penalty': masked_array(data=['l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1',\n",
       "                    'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'none', 'none'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__solver': masked_array(data=['saga', 'saga', 'saga', 'saga', 'saga', 'saga', 'saga',\n",
       "                    'saga', 'saga', 'saga', 'saga', 'saga', 'saga', 'saga',\n",
       "                    'saga', 'saga', 'saga', 'saga', 'lbfgs', 'lbfgs',\n",
       "                    'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs',\n",
       "                    'lbfgs', 'lbfgs', 'saga'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__penalty': 'none',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__penalty': 'none',\n",
       "   'classifier__solver': 'saga'}],\n",
       " 'split0_test_accuracy': array([0.662, 0.662, 0.662, 0.662, 0.701, 0.716, 0.729, 0.738, 0.732,\n",
       "        0.736, 0.738, 0.737, 0.738, 0.738, 0.738, 0.738, 0.738, 0.738,\n",
       "        0.662, 0.662, 0.716, 0.738, 0.736, 0.737, 0.738, 0.738, 0.738,\n",
       "        0.738, 0.738]),\n",
       " 'split1_test_accuracy': array([0.662, 0.662, 0.662, 0.662, 0.702, 0.718, 0.735, 0.731, 0.739,\n",
       "        0.74 , 0.737, 0.739, 0.737, 0.737, 0.737, 0.737, 0.737, 0.737,\n",
       "        0.662, 0.662, 0.718, 0.731, 0.74 , 0.739, 0.737, 0.737, 0.737,\n",
       "        0.737, 0.737]),\n",
       " 'split2_test_accuracy': array([0.661, 0.661, 0.661, 0.661, 0.661, 0.716, 0.744, 0.745, 0.756,\n",
       "        0.753, 0.751, 0.751, 0.75 , 0.75 , 0.75 , 0.75 , 0.75 , 0.75 ,\n",
       "        0.661, 0.661, 0.716, 0.745, 0.753, 0.751, 0.75 , 0.75 , 0.75 ,\n",
       "        0.75 , 0.75 ]),\n",
       " 'split3_test_accuracy': array([0.661, 0.661, 0.661, 0.661, 0.661, 0.717, 0.766, 0.758, 0.769,\n",
       "        0.771, 0.773, 0.772, 0.773, 0.773, 0.773, 0.773, 0.773, 0.773,\n",
       "        0.661, 0.661, 0.717, 0.758, 0.771, 0.772, 0.773, 0.773, 0.773,\n",
       "        0.773, 0.773]),\n",
       " 'split4_test_accuracy': array([0.661, 0.661, 0.661, 0.661, 0.661, 0.741, 0.76 , 0.768, 0.758,\n",
       "        0.756, 0.757, 0.758, 0.756, 0.756, 0.756, 0.756, 0.756, 0.756,\n",
       "        0.661, 0.661, 0.741, 0.767, 0.756, 0.758, 0.757, 0.756, 0.756,\n",
       "        0.756, 0.756]),\n",
       " 'mean_test_accuracy': array([0.6614, 0.6614, 0.6614, 0.6614, 0.6772, 0.7216, 0.7468, 0.748 ,\n",
       "        0.7508, 0.7512, 0.7512, 0.7514, 0.7508, 0.7508, 0.7508, 0.7508,\n",
       "        0.7508, 0.7508, 0.6614, 0.6614, 0.7216, 0.7478, 0.7512, 0.7514,\n",
       "        0.751 , 0.7508, 0.7508, 0.7508, 0.7508]),\n",
       " 'std_test_accuracy': array([0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.01984339,\n",
       "        0.00972831, 0.01419014, 0.01340149, 0.01343726, 0.01244829,\n",
       "        0.01330263, 0.01287789, 0.01322724, 0.01322724, 0.01322724,\n",
       "        0.01322724, 0.01322724, 0.01322724, 0.0004899 , 0.0004899 ,\n",
       "        0.00972831, 0.01310572, 0.01244829, 0.01287789, 0.01331165,\n",
       "        0.01322724, 0.01322724, 0.01322724, 0.01322724]),\n",
       " 'rank_test_accuracy': array([24, 24, 24, 24, 23, 21, 20, 18,  7,  3,  3,  1,  7,  7,  7,  7,  7,\n",
       "         7, 24, 24, 21, 19,  3,  1,  6,  7,  7,  7,  7], dtype=int32),\n",
       " 'split0_test_roc_auc_ovr': array([0.5       , 0.76057178, 0.5       , 0.7661761 , 0.76873916,\n",
       "        0.79716075, 0.83029952, 0.83390613, 0.83707923, 0.8370256 ,\n",
       "        0.83731609, 0.83731163, 0.83733397, 0.83735632, 0.83734291,\n",
       "        0.83734291, 0.83734291, 0.83734291, 0.76057625, 0.76616716,\n",
       "        0.79715181, 0.83393294, 0.83702113, 0.83731163, 0.83736079,\n",
       "        0.83734738, 0.83735185, 0.83733844, 0.83734291]),\n",
       " 'split1_test_roc_auc_ovr': array([0.5       , 0.7792819 , 0.5       , 0.78258013, 0.77727078,\n",
       "        0.80188241, 0.83167826, 0.83154865, 0.83499437, 0.83482901,\n",
       "        0.8351776 , 0.83517537, 0.83521336, 0.83520442, 0.83519995,\n",
       "        0.83518654, 0.83520218, 0.83520442, 0.77928637, 0.78257566,\n",
       "        0.80189582, 0.83155759, 0.8348089 , 0.8351776 , 0.83519995,\n",
       "        0.83519548, 0.83521559, 0.83518207, 0.83520442]),\n",
       " 'split2_test_roc_auc_ovr': array([0.5       , 0.78220628, 0.5       , 0.78828449, 0.78192736,\n",
       "        0.81415037, 0.84267825, 0.84490291, 0.84555447, 0.84571066,\n",
       "        0.84560356, 0.84551877, 0.84555893, 0.84558348, 0.84558125,\n",
       "        0.8455634 , 0.84558125, 0.84558125, 0.78220628, 0.78831573,\n",
       "        0.81415929, 0.84492969, 0.84573075, 0.84550761, 0.84559463,\n",
       "        0.8455634 , 0.84557232, 0.84557232, 0.84558125]),\n",
       " 'split3_test_roc_auc_ovr': array([0.5       , 0.79913557, 0.5       , 0.80438372, 0.80002142,\n",
       "        0.82997291, 0.86443174, 0.86434025, 0.86777654, 0.86765605,\n",
       "        0.86777654, 0.8677877 , 0.86781671, 0.86778993, 0.86782117,\n",
       "        0.86782563, 0.86782117, 0.86782117, 0.79912665, 0.8043748 ,\n",
       "        0.82996845, 0.86434249, 0.86763597, 0.86777654, 0.86779216,\n",
       "        0.86781671, 0.86781671, 0.86782563, 0.8678234 ]),\n",
       " 'split4_test_roc_auc_ovr': array([0.5       , 0.79079253, 0.5       , 0.79829435, 0.78894274,\n",
       "        0.82608366, 0.85460485, 0.8580456 , 0.86208882, 0.86188353,\n",
       "        0.86223386, 0.86217361, 0.86225617, 0.86221824, 0.86226286,\n",
       "        0.86227179, 0.86226286, 0.86226286, 0.7908327 , 0.7983122 ,\n",
       "        0.82608812, 0.8580456 , 0.86189246, 0.86217807, 0.86222716,\n",
       "        0.86226509, 0.86226286, 0.86226286, 0.86226286]),\n",
       " 'mean_test_roc_auc_ovr': array([0.5       , 0.78239761, 0.5       , 0.78794376, 0.78338029,\n",
       "        0.81385002, 0.84473852, 0.84654871, 0.84949869, 0.84942097,\n",
       "        0.84962153, 0.84959341, 0.84963583, 0.84963048, 0.84964163,\n",
       "        0.84963805, 0.84964207, 0.84964252, 0.78240565, 0.78794911,\n",
       "        0.8138527 , 0.84656166, 0.84941784, 0.84959029, 0.84963494,\n",
       "        0.84963761, 0.84964387, 0.84963627, 0.84964297]),\n",
       " 'std_test_roc_auc_ovr': array([0.        , 0.01293634, 0.        , 0.01326742, 0.01059875,\n",
       "        0.01289539, 0.01317928, 0.01293262, 0.01321186, 0.01317703,\n",
       "        0.01315196, 0.01315004, 0.01315889, 0.01314049, 0.0131613 ,\n",
       "        0.01316829, 0.01316081, 0.01316032, 0.01293754, 0.01327146,\n",
       "        0.01289499, 0.01292524, 0.01317733, 0.01314801, 0.01314227,\n",
       "        0.01316174, 0.01315551, 0.01316784, 0.01316093]),\n",
       " 'rank_test_roc_auc_ovr': array([28, 27, 28, 24, 25, 22, 20, 19, 15, 16, 12, 13,  9, 11,  5,  6,  4,\n",
       "         3, 26, 23, 21, 18, 17, 14, 10,  7,  1,  8,  2], dtype=int32),\n",
       " 'split0_test_f1_micro': array([0.662, 0.662, 0.662, 0.662, 0.701, 0.716, 0.729, 0.738, 0.732,\n",
       "        0.736, 0.738, 0.737, 0.738, 0.738, 0.738, 0.738, 0.738, 0.738,\n",
       "        0.662, 0.662, 0.716, 0.738, 0.736, 0.737, 0.738, 0.738, 0.738,\n",
       "        0.738, 0.738]),\n",
       " 'split1_test_f1_micro': array([0.662, 0.662, 0.662, 0.662, 0.702, 0.718, 0.735, 0.731, 0.739,\n",
       "        0.74 , 0.737, 0.739, 0.737, 0.737, 0.737, 0.737, 0.737, 0.737,\n",
       "        0.662, 0.662, 0.718, 0.731, 0.74 , 0.739, 0.737, 0.737, 0.737,\n",
       "        0.737, 0.737]),\n",
       " 'split2_test_f1_micro': array([0.661, 0.661, 0.661, 0.661, 0.661, 0.716, 0.744, 0.745, 0.756,\n",
       "        0.753, 0.751, 0.751, 0.75 , 0.75 , 0.75 , 0.75 , 0.75 , 0.75 ,\n",
       "        0.661, 0.661, 0.716, 0.745, 0.753, 0.751, 0.75 , 0.75 , 0.75 ,\n",
       "        0.75 , 0.75 ]),\n",
       " 'split3_test_f1_micro': array([0.661, 0.661, 0.661, 0.661, 0.661, 0.717, 0.766, 0.758, 0.769,\n",
       "        0.771, 0.773, 0.772, 0.773, 0.773, 0.773, 0.773, 0.773, 0.773,\n",
       "        0.661, 0.661, 0.717, 0.758, 0.771, 0.772, 0.773, 0.773, 0.773,\n",
       "        0.773, 0.773]),\n",
       " 'split4_test_f1_micro': array([0.661, 0.661, 0.661, 0.661, 0.661, 0.741, 0.76 , 0.768, 0.758,\n",
       "        0.756, 0.757, 0.758, 0.756, 0.756, 0.756, 0.756, 0.756, 0.756,\n",
       "        0.661, 0.661, 0.741, 0.767, 0.756, 0.758, 0.757, 0.756, 0.756,\n",
       "        0.756, 0.756]),\n",
       " 'mean_test_f1_micro': array([0.6614, 0.6614, 0.6614, 0.6614, 0.6772, 0.7216, 0.7468, 0.748 ,\n",
       "        0.7508, 0.7512, 0.7512, 0.7514, 0.7508, 0.7508, 0.7508, 0.7508,\n",
       "        0.7508, 0.7508, 0.6614, 0.6614, 0.7216, 0.7478, 0.7512, 0.7514,\n",
       "        0.751 , 0.7508, 0.7508, 0.7508, 0.7508]),\n",
       " 'std_test_f1_micro': array([0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.01984339,\n",
       "        0.00972831, 0.01419014, 0.01340149, 0.01343726, 0.01244829,\n",
       "        0.01330263, 0.01287789, 0.01322724, 0.01322724, 0.01322724,\n",
       "        0.01322724, 0.01322724, 0.01322724, 0.0004899 , 0.0004899 ,\n",
       "        0.00972831, 0.01310572, 0.01244829, 0.01287789, 0.01331165,\n",
       "        0.01322724, 0.01322724, 0.01322724, 0.01322724]),\n",
       " 'rank_test_f1_micro': array([24, 24, 24, 24, 23, 21, 20, 18,  7,  3,  5,  1,  7,  7,  7,  7,  7,\n",
       "         7, 24, 24, 21, 19,  3,  1,  6,  7,  7,  7,  7], dtype=int32)}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gets another 5000 random samples\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_n, Y_n, train_size = 5000, random_state = 5)\n",
    "\n",
    "# Grid Search\n",
    "pipe = Pipeline([('classifier', LogisticRegression())])\n",
    "\n",
    "search_space = [{'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['saga'],\n",
    "                 'classifier__penalty': ['l1', 'l2'],\n",
    "                 'classifier__C': np.logspace(-4, 4, 9)},\n",
    "                {'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['lbfgs'],\n",
    "                 'classifier__penalty': ['l2'],\n",
    "                 'classifier__C': np.logspace(-4, 4, 9)},\n",
    "                {'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['lbfgs','saga'],\n",
    "                 'classifier__penalty': ['none']}]\n",
    "                \n",
    "clf = GridSearchCV(pipe, search_space, cv=StratifiedKFold(n_splits=5), \n",
    "                   scoring=['accuracy', 'roc_auc_ovr', 'f1_micro'], refit=False,\n",
    "                   verbose=0)\n",
    "                \n",
    "best_model = clf.fit(X_train, Y_train)\n",
    "\n",
    "best_model.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "surrounded-excellence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24, 24, 24, 24, 23, 21, 20, 18,  7,  3,  3,  1,  7,  7,  7,  7,  7,\n",
       "        7, 24, 24, 21, 19,  3,  1,  6,  7,  7,  7,  7], dtype=int32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.cv_results_['rank_test_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "greek-influence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 10.0,\n",
       " 'classifier__penalty': 'l2',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for accuracy\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_accuracy']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "appointed-accessory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 10000.0,\n",
       " 'classifier__penalty': 'l2',\n",
       " 'classifier__solver': 'lbfgs'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for roc auc\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_roc_auc_ovr']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "desperate-remainder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 10.0,\n",
       " 'classifier__penalty': 'l2',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for f1\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_f1_micro']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "skilled-headquarters",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best accuracy model\n",
    "acc_model = LogisticRegression(penalty = 'l2', C = 1.0, solver = 'saga', max_iter = 5000)\n",
    "\n",
    "# best roc auc model\n",
    "roc_model = LogisticRegression(penalty = 'l2', C = 10000.0, solver = 'lbfgs', max_iter = 5000)\n",
    "\n",
    "# best f1 model\n",
    "f1_model = LogisticRegression(penalty = 'l2', C = 10.0, solver = 'saga', max_iter = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "instrumental-astronomy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10.0, max_iter=5000, solver='saga')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# models the data\n",
    "acc_model.fit(X_train, Y_train)\n",
    "roc_model.fit(X_train, Y_train)\n",
    "f1_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "confidential-figure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>C</th>\n",
       "      <th>penalty</th>\n",
       "      <th>solver</th>\n",
       "      <th>score_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.3386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.3386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.3386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.3386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.3228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.3386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.3386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.2784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.2522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.2488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.2486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.2490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.2492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.2492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.2492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           classifier           C penalty solver  score_acc\n",
       "0   LogisticRegression(max_iter=5000)      0.0001      l1   saga     0.3386\n",
       "1   LogisticRegression(max_iter=5000)      0.0001      l2   saga     0.3386\n",
       "2   LogisticRegression(max_iter=5000)      0.0010      l1   saga     0.3386\n",
       "3   LogisticRegression(max_iter=5000)      0.0010      l2   saga     0.3386\n",
       "4   LogisticRegression(max_iter=5000)      0.0100      l1   saga     0.3228\n",
       "5   LogisticRegression(max_iter=5000)      0.0100      l2   saga     0.2784\n",
       "6   LogisticRegression(max_iter=5000)      0.1000      l1   saga     0.2532\n",
       "7   LogisticRegression(max_iter=5000)      0.1000      l2   saga     0.2520\n",
       "8   LogisticRegression(max_iter=5000)      1.0000      l1   saga     0.2492\n",
       "9   LogisticRegression(max_iter=5000)      1.0000      l2   saga     0.2488\n",
       "10  LogisticRegression(max_iter=5000)     10.0000      l1   saga     0.2488\n",
       "11  LogisticRegression(max_iter=5000)     10.0000      l2   saga     0.2486\n",
       "12  LogisticRegression(max_iter=5000)    100.0000      l1   saga     0.2492\n",
       "13  LogisticRegression(max_iter=5000)    100.0000      l2   saga     0.2492\n",
       "14  LogisticRegression(max_iter=5000)   1000.0000      l1   saga     0.2492\n",
       "15  LogisticRegression(max_iter=5000)   1000.0000      l2   saga     0.2492\n",
       "16  LogisticRegression(max_iter=5000)  10000.0000      l1   saga     0.2492\n",
       "17  LogisticRegression(max_iter=5000)  10000.0000      l2   saga     0.2492\n",
       "18  LogisticRegression(max_iter=5000)      0.0001      l2  lbfgs     0.3386\n",
       "19  LogisticRegression(max_iter=5000)      0.0010      l2  lbfgs     0.3386\n",
       "20  LogisticRegression(max_iter=5000)      0.0100      l2  lbfgs     0.2784\n",
       "21  LogisticRegression(max_iter=5000)      0.1000      l2  lbfgs     0.2522\n",
       "22  LogisticRegression(max_iter=5000)      1.0000      l2  lbfgs     0.2488\n",
       "23  LogisticRegression(max_iter=5000)     10.0000      l2  lbfgs     0.2486\n",
       "24  LogisticRegression(max_iter=5000)    100.0000      l2  lbfgs     0.2490\n",
       "25  LogisticRegression(max_iter=5000)   1000.0000      l2  lbfgs     0.2492\n",
       "26  LogisticRegression(max_iter=5000)  10000.0000      l2  lbfgs     0.2492\n",
       "27  LogisticRegression(max_iter=5000)         NaN    none  lbfgs     0.2492\n",
       "28  LogisticRegression(max_iter=5000)         NaN    none   saga     0.2492"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = pd.DataFrame( best_model.cv_results_['params'] )\n",
    "\n",
    "results['score_acc'] = 1 - best_model.cv_results_['mean_test_accuracy']\n",
    "\n",
    "cols = results.columns.to_series().str.split('__').apply(lambda x: x[-1])\n",
    "results.columns = cols\n",
    "\n",
    "# Heat map\n",
    "sns.heatmap( results.query('solver==\"saga\"').pivot('C','penalty','score_acc'),\n",
    "             annot=True, fmt='.3f')\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extensive-netscape",
   "metadata": {},
   "source": [
    "## Electrical Grid Stability Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "choice-genealogy",
   "metadata": {},
   "source": [
    "https://archive.ics.uci.edu/ml/datasets/Electrical+Grid+Stability+Simulated+Data+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "verbal-piano",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stable</th>\n",
       "      <th>unstable</th>\n",
       "      <th>tau1</th>\n",
       "      <th>tau2</th>\n",
       "      <th>tau3</th>\n",
       "      <th>tau4</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>g4</th>\n",
       "      <th>stab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.959060</td>\n",
       "      <td>3.079885</td>\n",
       "      <td>8.381025</td>\n",
       "      <td>9.780754</td>\n",
       "      <td>3.763085</td>\n",
       "      <td>-0.782604</td>\n",
       "      <td>-1.257395</td>\n",
       "      <td>-1.723086</td>\n",
       "      <td>0.650456</td>\n",
       "      <td>0.859578</td>\n",
       "      <td>0.887445</td>\n",
       "      <td>0.958034</td>\n",
       "      <td>0.055347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.304097</td>\n",
       "      <td>4.902524</td>\n",
       "      <td>3.047541</td>\n",
       "      <td>1.369357</td>\n",
       "      <td>5.067812</td>\n",
       "      <td>-1.940058</td>\n",
       "      <td>-1.872742</td>\n",
       "      <td>-1.255012</td>\n",
       "      <td>0.413441</td>\n",
       "      <td>0.862414</td>\n",
       "      <td>0.562139</td>\n",
       "      <td>0.781760</td>\n",
       "      <td>-0.005957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.971707</td>\n",
       "      <td>8.848428</td>\n",
       "      <td>3.046479</td>\n",
       "      <td>1.214518</td>\n",
       "      <td>3.405158</td>\n",
       "      <td>-1.207456</td>\n",
       "      <td>-1.277210</td>\n",
       "      <td>-0.920492</td>\n",
       "      <td>0.163041</td>\n",
       "      <td>0.766689</td>\n",
       "      <td>0.839444</td>\n",
       "      <td>0.109853</td>\n",
       "      <td>0.003471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.716415</td>\n",
       "      <td>7.669600</td>\n",
       "      <td>4.486641</td>\n",
       "      <td>2.340563</td>\n",
       "      <td>3.963791</td>\n",
       "      <td>-1.027473</td>\n",
       "      <td>-1.938944</td>\n",
       "      <td>-0.997374</td>\n",
       "      <td>0.446209</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.929381</td>\n",
       "      <td>0.362718</td>\n",
       "      <td>0.028871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.134112</td>\n",
       "      <td>7.608772</td>\n",
       "      <td>4.943759</td>\n",
       "      <td>9.857573</td>\n",
       "      <td>3.525811</td>\n",
       "      <td>-1.125531</td>\n",
       "      <td>-1.845975</td>\n",
       "      <td>-0.554305</td>\n",
       "      <td>0.797110</td>\n",
       "      <td>0.455450</td>\n",
       "      <td>0.656947</td>\n",
       "      <td>0.820923</td>\n",
       "      <td>0.049860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.930406</td>\n",
       "      <td>9.487627</td>\n",
       "      <td>2.376523</td>\n",
       "      <td>6.187797</td>\n",
       "      <td>3.343416</td>\n",
       "      <td>-0.658054</td>\n",
       "      <td>-1.449106</td>\n",
       "      <td>-1.236256</td>\n",
       "      <td>0.601709</td>\n",
       "      <td>0.779642</td>\n",
       "      <td>0.813512</td>\n",
       "      <td>0.608385</td>\n",
       "      <td>0.023892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.392299</td>\n",
       "      <td>1.274827</td>\n",
       "      <td>2.954947</td>\n",
       "      <td>6.894759</td>\n",
       "      <td>4.349512</td>\n",
       "      <td>-1.663661</td>\n",
       "      <td>-0.952437</td>\n",
       "      <td>-1.733414</td>\n",
       "      <td>0.502079</td>\n",
       "      <td>0.567242</td>\n",
       "      <td>0.285880</td>\n",
       "      <td>0.366120</td>\n",
       "      <td>-0.025803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.364034</td>\n",
       "      <td>2.842030</td>\n",
       "      <td>8.776391</td>\n",
       "      <td>1.008906</td>\n",
       "      <td>4.299976</td>\n",
       "      <td>-1.380719</td>\n",
       "      <td>-0.943884</td>\n",
       "      <td>-1.975373</td>\n",
       "      <td>0.487838</td>\n",
       "      <td>0.986505</td>\n",
       "      <td>0.149286</td>\n",
       "      <td>0.145984</td>\n",
       "      <td>-0.031810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.631511</td>\n",
       "      <td>3.994398</td>\n",
       "      <td>2.757071</td>\n",
       "      <td>7.821347</td>\n",
       "      <td>2.514755</td>\n",
       "      <td>-0.966330</td>\n",
       "      <td>-0.649915</td>\n",
       "      <td>-0.898510</td>\n",
       "      <td>0.365246</td>\n",
       "      <td>0.587558</td>\n",
       "      <td>0.889118</td>\n",
       "      <td>0.818391</td>\n",
       "      <td>0.037789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.530527</td>\n",
       "      <td>6.781790</td>\n",
       "      <td>4.349695</td>\n",
       "      <td>8.673138</td>\n",
       "      <td>3.492807</td>\n",
       "      <td>-1.390285</td>\n",
       "      <td>-1.532193</td>\n",
       "      <td>-0.570329</td>\n",
       "      <td>0.073056</td>\n",
       "      <td>0.505441</td>\n",
       "      <td>0.378761</td>\n",
       "      <td>0.942631</td>\n",
       "      <td>0.045263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      stable  unstable      tau1      tau2      tau3      tau4        p1  \\\n",
       "0        0.0       1.0  2.959060  3.079885  8.381025  9.780754  3.763085   \n",
       "1        1.0       0.0  9.304097  4.902524  3.047541  1.369357  5.067812   \n",
       "2        0.0       1.0  8.971707  8.848428  3.046479  1.214518  3.405158   \n",
       "3        0.0       1.0  0.716415  7.669600  4.486641  2.340563  3.963791   \n",
       "4        0.0       1.0  3.134112  7.608772  4.943759  9.857573  3.525811   \n",
       "...      ...       ...       ...       ...       ...       ...       ...   \n",
       "9995     0.0       1.0  2.930406  9.487627  2.376523  6.187797  3.343416   \n",
       "9996     1.0       0.0  3.392299  1.274827  2.954947  6.894759  4.349512   \n",
       "9997     1.0       0.0  2.364034  2.842030  8.776391  1.008906  4.299976   \n",
       "9998     0.0       1.0  9.631511  3.994398  2.757071  7.821347  2.514755   \n",
       "9999     0.0       1.0  6.530527  6.781790  4.349695  8.673138  3.492807   \n",
       "\n",
       "            p2        p3        p4        g1        g2        g3        g4  \\\n",
       "0    -0.782604 -1.257395 -1.723086  0.650456  0.859578  0.887445  0.958034   \n",
       "1    -1.940058 -1.872742 -1.255012  0.413441  0.862414  0.562139  0.781760   \n",
       "2    -1.207456 -1.277210 -0.920492  0.163041  0.766689  0.839444  0.109853   \n",
       "3    -1.027473 -1.938944 -0.997374  0.446209  0.976744  0.929381  0.362718   \n",
       "4    -1.125531 -1.845975 -0.554305  0.797110  0.455450  0.656947  0.820923   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "9995 -0.658054 -1.449106 -1.236256  0.601709  0.779642  0.813512  0.608385   \n",
       "9996 -1.663661 -0.952437 -1.733414  0.502079  0.567242  0.285880  0.366120   \n",
       "9997 -1.380719 -0.943884 -1.975373  0.487838  0.986505  0.149286  0.145984   \n",
       "9998 -0.966330 -0.649915 -0.898510  0.365246  0.587558  0.889118  0.818391   \n",
       "9999 -1.390285 -1.532193 -0.570329  0.073056  0.505441  0.378761  0.942631   \n",
       "\n",
       "          stab  \n",
       "0     0.055347  \n",
       "1    -0.005957  \n",
       "2     0.003471  \n",
       "3     0.028871  \n",
       "4     0.049860  \n",
       "...        ...  \n",
       "9995  0.023892  \n",
       "9996 -0.025803  \n",
       "9997 -0.031810  \n",
       "9998  0.037789  \n",
       "9999  0.045263  \n",
       "\n",
       "[10000 rows x 15 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# electrical grid stability dataset\n",
    "electrical_grid = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/00471/Data_for_UCI_named.csv')\n",
    "\n",
    "# One hot encoding categorical features\n",
    "encoder = OneHotEncoder().fit(electrical_grid[['stabf']])\n",
    "encoder.categories_\n",
    "\n",
    "transformed = encoder.transform(electrical_grid[['stabf']] ).toarray() \n",
    "\n",
    "for index, category in enumerate( np.concatenate(encoder.categories_) ):\n",
    "    electrical_grid[category] = transformed[:,index]\n",
    "\n",
    "# moves columns so dataset looks better\n",
    "cols = electrical_grid.columns.tolist()\n",
    "cols = cols[-2:] + cols[:-2]\n",
    "electrical_grid = electrical_grid[cols]\n",
    "\n",
    "# drops string so grid search can work\n",
    "electrical_grid = electrical_grid.drop(columns = ['stabf'])\n",
    "    \n",
    "electrical_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "rational-pottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stores all columns except Stable in X and Stable in Y\n",
    "X_e = electrical_grid.drop(['stable'], axis = 1)\n",
    "Y_e = electrical_grid['stable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "atomic-ethiopia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets 5000 random samples\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_e, Y_e, train_size = 5000, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "alive-abuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "pipe = Pipeline([('classifier', LogisticRegression())])\n",
    "\n",
    "search_space = [{'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['saga'],\n",
    "                 'classifier__penalty': ['l1', 'l2'],\n",
    "                 'classifier__C': np.logspace(-4, 4, 9)},\n",
    "                {'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['lbfgs'],\n",
    "                 'classifier__penalty': ['l2'],\n",
    "                 'classifier__C': np.logspace(-4, 4, 9)},\n",
    "                {'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['lbfgs','saga'],\n",
    "                 'classifier__penalty': ['none']}]\n",
    "                \n",
    "clf = GridSearchCV(pipe, search_space, cv=StratifiedKFold(n_splits=5), \n",
    "                   scoring=['accuracy', 'roc_auc_ovr', 'f1_micro'], refit=False,\n",
    "                   verbose=0)\n",
    "                \n",
    "best_model = clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dependent-reality",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([1.37479782e-02, 5.03918171e-02, 4.18791771e-02, 6.90973282e-02,\n",
       "        8.87124062e-02, 1.22159481e-01, 2.55944729e-01, 2.06146955e-01,\n",
       "        5.41491699e-01, 1.58962202e-01, 9.43674088e-01, 3.38988876e-01,\n",
       "        1.08593531e+00, 7.44097948e-01, 1.09123306e+00, 8.55287075e-01,\n",
       "        1.09014015e+00, 8.68636942e-01, 4.24791017e+00, 6.28330245e+00,\n",
       "        1.09594289e+01, 1.44813404e+01, 1.76972996e+01, 2.09154312e+01,\n",
       "        1.95536808e+01, 2.09915684e+01, 1.73499521e+01, 7.31463947e+00,\n",
       "        1.32173398e+01]),\n",
       " 'std_fit_time': array([2.18820757e-03, 3.88400491e-02, 2.00414763e-03, 1.83969962e-02,\n",
       "        3.48112810e-02, 4.23193977e-02, 4.70048516e-02, 4.46390978e-02,\n",
       "        4.28876022e-02, 4.34851019e-02, 4.63664095e-02, 2.24607016e-02,\n",
       "        3.10261404e-02, 5.18818598e-02, 4.84407509e-02, 4.75792502e-02,\n",
       "        6.35519837e-02, 3.58069855e-02, 3.07760261e-01, 2.72971513e-01,\n",
       "        9.59418410e-01, 1.76025345e+00, 1.66878196e+00, 2.51664164e+00,\n",
       "        2.97320744e+00, 4.55359778e+00, 1.89216628e+00, 3.79752073e-01,\n",
       "        1.07039138e+00]),\n",
       " 'mean_score_time': array([0.37633915, 0.37032318, 0.39566479, 0.29826093, 0.33720593,\n",
       "        0.3428781 , 0.32961464, 0.34347153, 0.36411104, 0.32623587,\n",
       "        0.31363363, 0.35971322, 0.36182241, 0.25586529, 0.34172692,\n",
       "        0.35086722, 0.36333575, 0.34296055, 0.40741496, 0.43710427,\n",
       "        0.53730626, 0.40399613, 0.45126414, 0.44410954, 0.50277147,\n",
       "        0.48709884, 0.43322139, 0.58459396, 0.40028186]),\n",
       " 'std_score_time': array([0.06348804, 0.14675712, 0.06465382, 0.06983645, 0.06836998,\n",
       "        0.13580373, 0.0398653 , 0.00954513, 0.05218616, 0.04075588,\n",
       "        0.02081435, 0.03729183, 0.07423282, 0.1109622 , 0.04719768,\n",
       "        0.03741883, 0.06279303, 0.0519472 , 0.06566161, 0.03923896,\n",
       "        0.0818325 , 0.05742189, 0.07676754, 0.07863367, 0.10554369,\n",
       "        0.07579589, 0.06301746, 0.36138042, 0.09615852]),\n",
       " 'param_classifier': masked_array(data=[LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000)],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__C': masked_array(data=[0.0001, 0.0001, 0.001, 0.001, 0.01, 0.01, 0.1, 0.1,\n",
       "                    1.0, 1.0, 10.0, 10.0, 100.0, 100.0, 1000.0, 1000.0,\n",
       "                    10000.0, 10000.0, 0.0001, 0.001, 0.01, 0.1, 1.0, 10.0,\n",
       "                    100.0, 1000.0, 10000.0, --, --],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False,  True,  True],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__penalty': masked_array(data=['l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1',\n",
       "                    'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'none', 'none'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__solver': masked_array(data=['saga', 'saga', 'saga', 'saga', 'saga', 'saga', 'saga',\n",
       "                    'saga', 'saga', 'saga', 'saga', 'saga', 'saga', 'saga',\n",
       "                    'saga', 'saga', 'saga', 'saga', 'lbfgs', 'lbfgs',\n",
       "                    'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs',\n",
       "                    'lbfgs', 'lbfgs', 'saga'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__penalty': 'none',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__penalty': 'none',\n",
       "   'classifier__solver': 'saga'}],\n",
       " 'split0_test_accuracy': array([0.639, 0.715, 0.64 , 0.843, 1.   , 0.997, 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.715, 0.843, 0.997, 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split1_test_accuracy': array([0.64 , 0.699, 0.641, 0.837, 1.   , 0.997, 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.699, 0.838, 0.997, 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split2_test_accuracy': array([0.64 , 0.692, 0.64 , 0.847, 1.   , 0.995, 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.692, 0.848, 0.995, 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split3_test_accuracy': array([0.64 , 0.688, 0.642, 0.844, 1.   , 0.997, 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.688, 0.844, 0.996, 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split4_test_accuracy': array([0.64 , 0.7  , 0.641, 0.845, 1.   , 0.996, 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.7  , 0.845, 0.996, 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'mean_test_accuracy': array([0.6398, 0.6988, 0.6408, 0.8432, 1.    , 0.9964, 1.    , 1.    ,\n",
       "        1.    , 1.    , 1.    , 1.    , 1.    , 1.    , 1.    , 1.    ,\n",
       "        1.    , 1.    , 0.6988, 0.8436, 0.9962, 1.    , 1.    , 1.    ,\n",
       "        1.    , 1.    , 1.    , 1.    , 1.    ]),\n",
       " 'std_test_accuracy': array([0.0004    , 0.00923905, 0.00074833, 0.00337046, 0.        ,\n",
       "        0.0008    , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.00923905, 0.0032619 ,\n",
       "        0.00074833, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ]),\n",
       " 'rank_test_accuracy': array([29, 26, 28, 25,  1, 22,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1, 26, 24, 23,  1,  1,  1,  1,  1,  1,  1,  1], dtype=int32),\n",
       " 'split0_test_roc_auc_ovr': array([0.5       , 0.837172  , 0.78108974, 0.92367749, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.83715033, 0.92354311,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'split1_test_roc_auc_ovr': array([0.5       , 0.84700955, 0.79370226, 0.93088976, 1.        ,\n",
       "        0.99998264, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.84700521, 0.93076389,\n",
       "        0.9999783 , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'split2_test_roc_auc_ovr': array([0.5       , 0.83983073, 0.765     , 0.92298611, 1.        ,\n",
       "        0.99996962, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.83983073, 0.9228776 ,\n",
       "        0.99994792, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'split3_test_roc_auc_ovr': array([0.5       , 0.83063368, 0.77605035, 0.91391059, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.83063368, 0.91375868,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'split4_test_roc_auc_ovr': array([0.5       , 0.83598524, 0.77300347, 0.9216276 , 1.        ,\n",
       "        0.99998264, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.83597222, 0.92151042,\n",
       "        0.99998264, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'mean_test_roc_auc_ovr': array([0.5       , 0.83812624, 0.77776916, 0.92261831, 1.        ,\n",
       "        0.99998698, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.83811843, 0.92249074,\n",
       "        0.99998177, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'std_test_roc_auc_ovr': array([0.00000000e+00, 5.35632976e-03, 9.52478210e-03, 5.41257532e-03,\n",
       "        0.00000000e+00, 1.16461874e-05, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 5.35670991e-03, 5.42055394e-03,\n",
       "        1.90972222e-05, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00]),\n",
       " 'rank_test_roc_auc_ovr': array([29, 26, 28, 24,  1, 22,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1, 27, 25, 23,  1,  1,  1,  1,  1,  1,  1,  1], dtype=int32),\n",
       " 'split0_test_f1_micro': array([0.639, 0.715, 0.64 , 0.843, 1.   , 0.997, 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.715, 0.843, 0.997, 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split1_test_f1_micro': array([0.64 , 0.699, 0.641, 0.837, 1.   , 0.997, 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.699, 0.838, 0.997, 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split2_test_f1_micro': array([0.64 , 0.692, 0.64 , 0.847, 1.   , 0.995, 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.692, 0.848, 0.995, 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split3_test_f1_micro': array([0.64 , 0.688, 0.642, 0.844, 1.   , 0.997, 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.688, 0.844, 0.996, 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split4_test_f1_micro': array([0.64 , 0.7  , 0.641, 0.845, 1.   , 0.996, 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.7  , 0.845, 0.996, 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'mean_test_f1_micro': array([0.6398, 0.6988, 0.6408, 0.8432, 1.    , 0.9964, 1.    , 1.    ,\n",
       "        1.    , 1.    , 1.    , 1.    , 1.    , 1.    , 1.    , 1.    ,\n",
       "        1.    , 1.    , 0.6988, 0.8436, 0.9962, 1.    , 1.    , 1.    ,\n",
       "        1.    , 1.    , 1.    , 1.    , 1.    ]),\n",
       " 'std_test_f1_micro': array([0.0004    , 0.00923905, 0.00074833, 0.00337046, 0.        ,\n",
       "        0.0008    , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.00923905, 0.0032619 ,\n",
       "        0.00074833, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ]),\n",
       " 'rank_test_f1_micro': array([29, 26, 28, 25,  1, 22,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1, 26, 24, 23,  1,  1,  1,  1,  1,  1,  1,  1], dtype=int32)}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "selective-royal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([29, 26, 28, 25,  1, 22,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1, 26, 24, 23,  1,  1,  1,  1,  1,  1,  1,  1], dtype=int32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.cv_results_['rank_test_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fewer-lunch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 0.01,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for accuracy\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_accuracy']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "flying-mother",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 0.01,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for roc auc\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_roc_auc_ovr']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "acoustic-cheese",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 0.01,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for f1\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_f1_micro']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "inner-species",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best accuracy model\n",
    "acc_model = LogisticRegression(penalty = 'l1', C = 0.01, solver = 'saga', max_iter = 5000)\n",
    "\n",
    "# best roc auc model\n",
    "roc_model = LogisticRegression(penalty = 'l1', C = 0.01, solver = 'saga', max_iter = 5000)\n",
    "\n",
    "# best f1 model\n",
    "f1_model = LogisticRegression(penalty = 'l1', C = 0.01, solver = 'saga', max_iter = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "direct-nothing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, max_iter=5000, penalty='l1', solver='saga')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# models the data\n",
    "acc_model.fit(X_train, Y_train)\n",
    "roc_model.fit(X_train, Y_train)\n",
    "f1_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "boring-residence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>C</th>\n",
       "      <th>penalty</th>\n",
       "      <th>solver</th>\n",
       "      <th>score_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.3602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.3012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.3592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.1568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.3012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.1564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           classifier           C penalty solver  score_acc\n",
       "0   LogisticRegression(max_iter=5000)      0.0001      l1   saga     0.3602\n",
       "1   LogisticRegression(max_iter=5000)      0.0001      l2   saga     0.3012\n",
       "2   LogisticRegression(max_iter=5000)      0.0010      l1   saga     0.3592\n",
       "3   LogisticRegression(max_iter=5000)      0.0010      l2   saga     0.1568\n",
       "4   LogisticRegression(max_iter=5000)      0.0100      l1   saga     0.0000\n",
       "5   LogisticRegression(max_iter=5000)      0.0100      l2   saga     0.0036\n",
       "6   LogisticRegression(max_iter=5000)      0.1000      l1   saga     0.0000\n",
       "7   LogisticRegression(max_iter=5000)      0.1000      l2   saga     0.0000\n",
       "8   LogisticRegression(max_iter=5000)      1.0000      l1   saga     0.0000\n",
       "9   LogisticRegression(max_iter=5000)      1.0000      l2   saga     0.0000\n",
       "10  LogisticRegression(max_iter=5000)     10.0000      l1   saga     0.0000\n",
       "11  LogisticRegression(max_iter=5000)     10.0000      l2   saga     0.0000\n",
       "12  LogisticRegression(max_iter=5000)    100.0000      l1   saga     0.0000\n",
       "13  LogisticRegression(max_iter=5000)    100.0000      l2   saga     0.0000\n",
       "14  LogisticRegression(max_iter=5000)   1000.0000      l1   saga     0.0000\n",
       "15  LogisticRegression(max_iter=5000)   1000.0000      l2   saga     0.0000\n",
       "16  LogisticRegression(max_iter=5000)  10000.0000      l1   saga     0.0000\n",
       "17  LogisticRegression(max_iter=5000)  10000.0000      l2   saga     0.0000\n",
       "18  LogisticRegression(max_iter=5000)      0.0001      l2  lbfgs     0.3012\n",
       "19  LogisticRegression(max_iter=5000)      0.0010      l2  lbfgs     0.1564\n",
       "20  LogisticRegression(max_iter=5000)      0.0100      l2  lbfgs     0.0038\n",
       "21  LogisticRegression(max_iter=5000)      0.1000      l2  lbfgs     0.0000\n",
       "22  LogisticRegression(max_iter=5000)      1.0000      l2  lbfgs     0.0000\n",
       "23  LogisticRegression(max_iter=5000)     10.0000      l2  lbfgs     0.0000\n",
       "24  LogisticRegression(max_iter=5000)    100.0000      l2  lbfgs     0.0000\n",
       "25  LogisticRegression(max_iter=5000)   1000.0000      l2  lbfgs     0.0000\n",
       "26  LogisticRegression(max_iter=5000)  10000.0000      l2  lbfgs     0.0000\n",
       "27  LogisticRegression(max_iter=5000)         NaN    none  lbfgs     0.0000\n",
       "28  LogisticRegression(max_iter=5000)         NaN    none   saga     0.0000"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = pd.DataFrame( best_model.cv_results_['params'] )\n",
    "\n",
    "results['score_acc'] = 1 - best_model.cv_results_['mean_test_accuracy']\n",
    "\n",
    "cols = results.columns.to_series().str.split('__').apply(lambda x: x[-1])\n",
    "results.columns = cols\n",
    "\n",
    "# Heat map\n",
    "sns.heatmap( results.query('solver==\"saga\"').pivot('C','penalty','score_acc'),\n",
    "             annot=True, fmt='.3f')\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "intelligent-trust",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets another 5000 random samples\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_e, Y_e, train_size = 5000, random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "defensive-marking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "pipe = Pipeline([('classifier', LogisticRegression())])\n",
    "\n",
    "search_space = [{'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['saga'],\n",
    "                 'classifier__penalty': ['l1', 'l2'],\n",
    "                 'classifier__C': np.logspace(-4, 4, 9)},\n",
    "                {'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['lbfgs'],\n",
    "                 'classifier__penalty': ['l2'],\n",
    "                 'classifier__C': np.logspace(-4, 4, 9)},\n",
    "                {'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['lbfgs','saga'],\n",
    "                 'classifier__penalty': ['none']}]\n",
    "                \n",
    "clf = GridSearchCV(pipe, search_space, cv=StratifiedKFold(n_splits=5), \n",
    "                   scoring=['accuracy', 'roc_auc_ovr', 'f1_micro'], refit=False,\n",
    "                   verbose=0)\n",
    "                \n",
    "best_model = clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "sapphire-prediction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 0.030302  ,  0.05632143,  0.0684936 ,  0.08468285,  0.09605503,\n",
       "         0.15583663,  0.27367854,  0.24228244,  0.54786248,  0.16387272,\n",
       "         0.98270669,  0.34033065,  1.08175263,  0.72956386,  1.07880397,\n",
       "         1.34810314,  1.71697969,  0.84873657,  4.00383677,  6.02129035,\n",
       "        10.95708971, 17.98321676, 22.78804016, 25.47369709, 26.4383152 ,\n",
       "        23.72850428, 17.67766709,  8.12173805, 12.24841008]),\n",
       " 'std_fit_time': array([0.03680901, 0.03940837, 0.03695682, 0.02801624, 0.04169001,\n",
       "        0.04754297, 0.06814371, 0.01578433, 0.02883902, 0.02711478,\n",
       "        0.04473895, 0.01808714, 0.05369413, 0.03174991, 0.02402426,\n",
       "        0.34846736, 0.42870067, 0.05286786, 0.2533839 , 0.26445594,\n",
       "        0.82263036, 2.71433426, 2.78223401, 1.98518291, 3.35870291,\n",
       "        1.93959867, 2.15491453, 1.46364921, 0.8148947 ]),\n",
       " 'mean_score_time': array([0.35324197, 0.37744966, 0.3544517 , 0.3333395 , 0.36565976,\n",
       "        0.31982646, 0.36401954, 0.39567132, 0.36895208, 0.37473426,\n",
       "        0.34042029, 0.31822581, 0.3735219 , 0.36844649, 0.40155287,\n",
       "        0.38773222, 0.38650374, 0.39134903, 0.43373041, 0.4147871 ,\n",
       "        0.46343322, 0.63820939, 0.55968513, 0.58418312, 0.53632584,\n",
       "        0.47104154, 0.72096033, 0.42527804, 0.54285588]),\n",
       " 'std_score_time': array([0.05021725, 0.07617723, 0.07954105, 0.03582439, 0.05295656,\n",
       "        0.0297898 , 0.04468697, 0.04667636, 0.0141155 , 0.06993852,\n",
       "        0.0378907 , 0.04565393, 0.03225714, 0.0429951 , 0.16325701,\n",
       "        0.06444658, 0.05006621, 0.0924912 , 0.09808614, 0.06717204,\n",
       "        0.07863073, 0.36497917, 0.08803341, 0.24484077, 0.09411356,\n",
       "        0.08851399, 0.49063161, 0.10645445, 0.42490563]),\n",
       " 'param_classifier': masked_array(data=[LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000)],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__C': masked_array(data=[0.0001, 0.0001, 0.001, 0.001, 0.01, 0.01, 0.1, 0.1,\n",
       "                    1.0, 1.0, 10.0, 10.0, 100.0, 100.0, 1000.0, 1000.0,\n",
       "                    10000.0, 10000.0, 0.0001, 0.001, 0.01, 0.1, 1.0, 10.0,\n",
       "                    100.0, 1000.0, 10000.0, --, --],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False,  True,  True],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__penalty': masked_array(data=['l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1',\n",
       "                    'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'none', 'none'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__solver': masked_array(data=['saga', 'saga', 'saga', 'saga', 'saga', 'saga', 'saga',\n",
       "                    'saga', 'saga', 'saga', 'saga', 'saga', 'saga', 'saga',\n",
       "                    'saga', 'saga', 'saga', 'saga', 'lbfgs', 'lbfgs',\n",
       "                    'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs',\n",
       "                    'lbfgs', 'lbfgs', 'saga'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__penalty': 'none',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__penalty': 'none',\n",
       "   'classifier__solver': 'saga'}],\n",
       " 'split0_test_accuracy': array([0.638, 0.698, 0.638, 0.833, 1.   , 0.996, 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.698, 0.833, 0.996, 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split1_test_accuracy': array([0.637, 0.711, 0.639, 0.836, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.711, 0.836, 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split2_test_accuracy': array([0.637, 0.693, 0.641, 0.829, 1.   , 0.993, 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.693, 0.829, 0.993, 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split3_test_accuracy': array([0.637, 0.697, 0.638, 0.856, 1.   , 0.997, 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.697, 0.856, 0.997, 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split4_test_accuracy': array([0.637, 0.7  , 0.637, 0.835, 1.   , 0.999, 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.7  , 0.835, 0.999, 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'mean_test_accuracy': array([0.6372, 0.6998, 0.6386, 0.8378, 1.    , 0.997 , 1.    , 1.    ,\n",
       "        1.    , 1.    , 1.    , 1.    , 1.    , 1.    , 1.    , 1.    ,\n",
       "        1.    , 1.    , 0.6998, 0.8378, 0.997 , 1.    , 1.    , 1.    ,\n",
       "        1.    , 1.    , 1.    , 1.    , 1.    ]),\n",
       " 'std_test_accuracy': array([0.0004    , 0.00604649, 0.00135647, 0.00941063, 0.        ,\n",
       "        0.00244949, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.00604649, 0.00941063,\n",
       "        0.00244949, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ]),\n",
       " 'rank_test_accuracy': array([29, 26, 28, 24,  1, 22,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1, 26, 24, 22,  1,  1,  1,  1,  1,  1,  1,  1], dtype=int32),\n",
       " 'split0_test_roc_auc_ovr': array([0.5       , 0.83471744, 0.78484213, 0.92031383, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.83471744, 0.92017094,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'split1_test_roc_auc_ovr': array([0.5       , 0.8268701 , 0.77744334, 0.91887766, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.82687875, 0.91874359,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'split2_test_roc_auc_ovr': array([0.5       , 0.8248029 , 0.77528532, 0.91203602, 1.        ,\n",
       "        0.99994378, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.8248029 , 0.91193222,\n",
       "        0.99993513, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'split3_test_roc_auc_ovr': array([0.5       , 0.84602843, 0.79331059, 0.93097811, 1.        ,\n",
       "        0.99999568, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.84602411, 0.93087432,\n",
       "        0.99999568, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'split4_test_roc_auc_ovr': array([0.5       , 0.84530621, 0.78831558, 0.92769568, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.84529756, 0.92759621,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'mean_test_roc_auc_ovr': array([0.5       , 0.83554502, 0.78383939, 0.92198026, 1.        ,\n",
       "        0.99998789, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.83554415, 0.92186346,\n",
       "        0.99998616, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'std_test_roc_auc_ovr': array([0.00000000e+00, 8.90522238e-03, 6.70562349e-03, 6.70698913e-03,\n",
       "        0.00000000e+00, 2.21193730e-05, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 8.90062354e-03, 6.71249142e-03,\n",
       "        2.55705256e-05, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00]),\n",
       " 'rank_test_roc_auc_ovr': array([29, 26, 28, 24,  1, 22,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1, 27, 25, 23,  1,  1,  1,  1,  1,  1,  1,  1], dtype=int32),\n",
       " 'split0_test_f1_micro': array([0.638, 0.698, 0.638, 0.833, 1.   , 0.996, 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.698, 0.833, 0.996, 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split1_test_f1_micro': array([0.637, 0.711, 0.639, 0.836, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.711, 0.836, 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split2_test_f1_micro': array([0.637, 0.693, 0.641, 0.829, 1.   , 0.993, 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.693, 0.829, 0.993, 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split3_test_f1_micro': array([0.637, 0.697, 0.638, 0.856, 1.   , 0.997, 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.697, 0.856, 0.997, 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split4_test_f1_micro': array([0.637, 0.7  , 0.637, 0.835, 1.   , 0.999, 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.7  , 0.835, 0.999, 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'mean_test_f1_micro': array([0.6372, 0.6998, 0.6386, 0.8378, 1.    , 0.997 , 1.    , 1.    ,\n",
       "        1.    , 1.    , 1.    , 1.    , 1.    , 1.    , 1.    , 1.    ,\n",
       "        1.    , 1.    , 0.6998, 0.8378, 0.997 , 1.    , 1.    , 1.    ,\n",
       "        1.    , 1.    , 1.    , 1.    , 1.    ]),\n",
       " 'std_test_f1_micro': array([0.0004    , 0.00604649, 0.00135647, 0.00941063, 0.        ,\n",
       "        0.00244949, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.00604649, 0.00941063,\n",
       "        0.00244949, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ]),\n",
       " 'rank_test_f1_micro': array([29, 26, 28, 24,  1, 22,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1, 26, 24, 22,  1,  1,  1,  1,  1,  1,  1,  1], dtype=int32)}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "stock-express",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([29, 26, 28, 24,  1, 22,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1, 26, 24, 22,  1,  1,  1,  1,  1,  1,  1,  1], dtype=int32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.cv_results_['rank_test_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "hispanic-procedure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 0.01,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for accuracy\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_accuracy']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "scenic-maryland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 0.01,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for roc auc\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_roc_auc_ovr']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "extended-external",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 0.01,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for f1\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_f1_micro']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "willing-arabic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best accuracy model\n",
    "acc_model = LogisticRegression(penalty = 'l1', C = 0.01, solver = 'saga', max_iter = 5000)\n",
    "\n",
    "# best roc auc model\n",
    "roc_model = LogisticRegression(penalty = 'l1', C = 0.01, solver = 'saga', max_iter = 5000)\n",
    "\n",
    "# best f1 model\n",
    "f1_model = LogisticRegression(penalty = 'l1', C = 0.01, solver = 'saga', max_iter = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "material-conjunction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, max_iter=5000, penalty='l1', solver='saga')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# models the data\n",
    "acc_model.fit(X_train, Y_train)\n",
    "roc_model.fit(X_train, Y_train)\n",
    "f1_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "becoming-lloyd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>C</th>\n",
       "      <th>penalty</th>\n",
       "      <th>solver</th>\n",
       "      <th>score_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.3628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.3002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.3614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.1622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.3002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.1622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           classifier           C penalty solver  score_acc\n",
       "0   LogisticRegression(max_iter=5000)      0.0001      l1   saga     0.3628\n",
       "1   LogisticRegression(max_iter=5000)      0.0001      l2   saga     0.3002\n",
       "2   LogisticRegression(max_iter=5000)      0.0010      l1   saga     0.3614\n",
       "3   LogisticRegression(max_iter=5000)      0.0010      l2   saga     0.1622\n",
       "4   LogisticRegression(max_iter=5000)      0.0100      l1   saga     0.0000\n",
       "5   LogisticRegression(max_iter=5000)      0.0100      l2   saga     0.0030\n",
       "6   LogisticRegression(max_iter=5000)      0.1000      l1   saga     0.0000\n",
       "7   LogisticRegression(max_iter=5000)      0.1000      l2   saga     0.0000\n",
       "8   LogisticRegression(max_iter=5000)      1.0000      l1   saga     0.0000\n",
       "9   LogisticRegression(max_iter=5000)      1.0000      l2   saga     0.0000\n",
       "10  LogisticRegression(max_iter=5000)     10.0000      l1   saga     0.0000\n",
       "11  LogisticRegression(max_iter=5000)     10.0000      l2   saga     0.0000\n",
       "12  LogisticRegression(max_iter=5000)    100.0000      l1   saga     0.0000\n",
       "13  LogisticRegression(max_iter=5000)    100.0000      l2   saga     0.0000\n",
       "14  LogisticRegression(max_iter=5000)   1000.0000      l1   saga     0.0000\n",
       "15  LogisticRegression(max_iter=5000)   1000.0000      l2   saga     0.0000\n",
       "16  LogisticRegression(max_iter=5000)  10000.0000      l1   saga     0.0000\n",
       "17  LogisticRegression(max_iter=5000)  10000.0000      l2   saga     0.0000\n",
       "18  LogisticRegression(max_iter=5000)      0.0001      l2  lbfgs     0.3002\n",
       "19  LogisticRegression(max_iter=5000)      0.0010      l2  lbfgs     0.1622\n",
       "20  LogisticRegression(max_iter=5000)      0.0100      l2  lbfgs     0.0030\n",
       "21  LogisticRegression(max_iter=5000)      0.1000      l2  lbfgs     0.0000\n",
       "22  LogisticRegression(max_iter=5000)      1.0000      l2  lbfgs     0.0000\n",
       "23  LogisticRegression(max_iter=5000)     10.0000      l2  lbfgs     0.0000\n",
       "24  LogisticRegression(max_iter=5000)    100.0000      l2  lbfgs     0.0000\n",
       "25  LogisticRegression(max_iter=5000)   1000.0000      l2  lbfgs     0.0000\n",
       "26  LogisticRegression(max_iter=5000)  10000.0000      l2  lbfgs     0.0000\n",
       "27  LogisticRegression(max_iter=5000)         NaN    none  lbfgs     0.0000\n",
       "28  LogisticRegression(max_iter=5000)         NaN    none   saga     0.0000"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = pd.DataFrame( best_model.cv_results_['params'] )\n",
    "\n",
    "results['score_acc'] = 1 - best_model.cv_results_['mean_test_accuracy']\n",
    "\n",
    "cols = results.columns.to_series().str.split('__').apply(lambda x: x[-1])\n",
    "results.columns = cols\n",
    "\n",
    "# Heat map\n",
    "sns.heatmap( results.query('solver==\"saga\"').pivot('C','penalty','score_acc'),\n",
    "             annot=True, fmt='.3f')\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "christian-steel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets another 5000 random samples\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_e, Y_e, train_size = 5000, random_state = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "crazy-essence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "pipe = Pipeline([('classifier', LogisticRegression())])\n",
    "\n",
    "search_space = [{'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['saga'],\n",
    "                 'classifier__penalty': ['l1', 'l2'],\n",
    "                 'classifier__C': np.logspace(-4, 4, 9)},\n",
    "                {'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['lbfgs'],\n",
    "                 'classifier__penalty': ['l2'],\n",
    "                 'classifier__C': np.logspace(-4, 4, 9)},\n",
    "                {'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['lbfgs','saga'],\n",
    "                 'classifier__penalty': ['none']}]\n",
    "                \n",
    "clf = GridSearchCV(pipe, search_space, cv=StratifiedKFold(n_splits=5), \n",
    "                   scoring=['accuracy', 'roc_auc_ovr', 'f1_micro'], refit=False,\n",
    "                   verbose=0)\n",
    "                \n",
    "best_model = clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "novel-canal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 0.06298399,  0.29773712,  0.4560709 ,  0.75060086,  0.86251283,\n",
       "         1.71398954,  2.92315917,  2.50781269,  6.98469319,  1.68456874,\n",
       "        13.26007714,  4.87179952,  8.36909261,  0.69277425,  1.06269665,\n",
       "         0.81998377,  1.1146996 ,  0.86377592,  3.89572754,  6.13157163,\n",
       "        11.67518516, 19.07212157, 22.35729327, 24.35158229, 24.8454556 ,\n",
       "        24.71862106, 18.92820539,  8.41026821, 12.19708028]),\n",
       " 'std_fit_time': array([0.04085164, 0.40186637, 0.73603078, 0.70381087, 0.95178903,\n",
       "        0.82175917, 0.91646632, 0.62674188, 1.24485062, 0.22414079,\n",
       "        0.80339771, 0.67564355, 6.38539714, 0.03417475, 0.05046803,\n",
       "        0.03719137, 0.05595027, 0.03363895, 0.34503139, 0.38657477,\n",
       "        0.2330232 , 3.56776114, 1.97263643, 4.09753678, 2.97311089,\n",
       "        2.90953698, 2.82459877, 1.12774761, 2.31505625]),\n",
       " 'mean_score_time': array([0.39366641, 0.70262399, 0.38840284, 0.51339726, 0.37514443,\n",
       "        0.5645328 , 0.41524367, 0.3291369 , 0.32885561, 0.3754498 ,\n",
       "        0.67598419, 0.42927551, 0.41593695, 0.33588481, 0.35439968,\n",
       "        0.34789209, 0.3917274 , 0.33428726, 0.50528846, 0.43703752,\n",
       "        0.41217136, 0.45427294, 0.75893722, 0.41110439, 0.41215072,\n",
       "        0.54474983, 0.41039076, 0.42904592, 0.49136944]),\n",
       " 'std_score_time': array([0.00848864, 0.54491204, 0.09817048, 0.2695716 , 0.06819638,\n",
       "        0.44550253, 0.04950571, 0.04632045, 0.13766208, 0.05457673,\n",
       "        0.56816555, 0.08238484, 0.06281293, 0.03166978, 0.0576894 ,\n",
       "        0.05668296, 0.06643557, 0.04167473, 0.1378137 , 0.037965  ,\n",
       "        0.10121154, 0.07807551, 0.67595631, 0.05859234, 0.14333262,\n",
       "        0.27255609, 0.06352031, 0.09505916, 0.20404635]),\n",
       " 'param_classifier': masked_array(data=[LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000)],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__C': masked_array(data=[0.0001, 0.0001, 0.001, 0.001, 0.01, 0.01, 0.1, 0.1,\n",
       "                    1.0, 1.0, 10.0, 10.0, 100.0, 100.0, 1000.0, 1000.0,\n",
       "                    10000.0, 10000.0, 0.0001, 0.001, 0.01, 0.1, 1.0, 10.0,\n",
       "                    100.0, 1000.0, 10000.0, --, --],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False,  True,  True],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__penalty': masked_array(data=['l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1',\n",
       "                    'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'none', 'none'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__solver': masked_array(data=['saga', 'saga', 'saga', 'saga', 'saga', 'saga', 'saga',\n",
       "                    'saga', 'saga', 'saga', 'saga', 'saga', 'saga', 'saga',\n",
       "                    'saga', 'saga', 'saga', 'saga', 'lbfgs', 'lbfgs',\n",
       "                    'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs',\n",
       "                    'lbfgs', 'lbfgs', 'saga'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__penalty': 'none',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__penalty': 'none',\n",
       "   'classifier__solver': 'saga'}],\n",
       " 'split0_test_accuracy': array([0.636, 0.703, 0.636, 0.849, 1.   , 0.999, 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.703, 0.849, 0.999, 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split1_test_accuracy': array([0.636, 0.702, 0.639, 0.824, 1.   , 0.998, 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.702, 0.824, 0.998, 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split2_test_accuracy': array([0.635, 0.693, 0.635, 0.822, 1.   , 0.997, 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.693, 0.82 , 0.997, 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split3_test_accuracy': array([0.635, 0.689, 0.635, 0.836, 1.   , 0.997, 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.689, 0.836, 0.996, 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split4_test_accuracy': array([0.635, 0.703, 0.635, 0.858, 1.   , 0.998, 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.703, 0.858, 0.997, 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'mean_test_accuracy': array([0.6354, 0.698 , 0.636 , 0.8378, 1.    , 0.9978, 1.    , 1.    ,\n",
       "        1.    , 1.    , 1.    , 1.    , 1.    , 1.    , 1.    , 1.    ,\n",
       "        1.    , 1.    , 0.698 , 0.8374, 0.9974, 1.    , 1.    , 1.    ,\n",
       "        1.    , 1.    , 1.    , 1.    , 1.    ]),\n",
       " 'std_test_accuracy': array([0.0004899 , 0.00586515, 0.00154919, 0.01397712, 0.        ,\n",
       "        0.00074833, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.00586515, 0.01444438,\n",
       "        0.0010198 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ]),\n",
       " 'rank_test_accuracy': array([29, 26, 28, 24,  1, 22,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1, 26, 25, 23,  1,  1,  1,  1,  1,  1,  1,  1], dtype=int32),\n",
       " 'split0_test_roc_auc_ovr': array([0.5       , 0.84997235, 0.80048293, 0.93121069, 1.        ,\n",
       "        0.99999568, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.84996372, 0.93108974,\n",
       "        0.99999568, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'split1_test_roc_auc_ovr': array([0.5       , 0.81696645, 0.75246648, 0.90937954, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.81696645, 0.90926291,\n",
       "        0.99998704, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'split2_test_roc_auc_ovr': array([0.5       , 0.82766045, 0.77920828, 0.91719124, 1.        ,\n",
       "        0.99999137, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.82764319, 0.91711358,\n",
       "        0.99999137, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'split3_test_roc_auc_ovr': array([0.5       , 0.82804013, 0.76224356, 0.91807572, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.8280315 , 0.91796786,\n",
       "        0.99999569, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'split4_test_roc_auc_ovr': array([0.5       , 0.85382807, 0.78386366, 0.93914357, 1.        ,\n",
       "        0.99999569, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.85381944, 0.93904865,\n",
       "        0.99999569, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'mean_test_roc_auc_ovr': array([0.5       , 0.83529349, 0.77565298, 0.92300015, 1.        ,\n",
       "        0.99999655, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.83528486, 0.92289655,\n",
       "        0.99999309, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'std_test_roc_auc_ovr': array([0.00000000e+00, 1.41827698e-02, 1.68167077e-02, 1.06914680e-02,\n",
       "        0.00000000e+00, 3.22896858e-06, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.41814674e-02, 1.06923301e-02,\n",
       "        3.45617092e-06, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00]),\n",
       " 'rank_test_roc_auc_ovr': array([29, 26, 28, 24,  1, 22,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1, 27, 25, 23,  1,  1,  1,  1,  1,  1,  1,  1], dtype=int32),\n",
       " 'split0_test_f1_micro': array([0.636, 0.703, 0.636, 0.849, 1.   , 0.999, 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.703, 0.849, 0.999, 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split1_test_f1_micro': array([0.636, 0.702, 0.639, 0.824, 1.   , 0.998, 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.702, 0.824, 0.998, 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split2_test_f1_micro': array([0.635, 0.693, 0.635, 0.822, 1.   , 0.997, 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.693, 0.82 , 0.997, 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split3_test_f1_micro': array([0.635, 0.689, 0.635, 0.836, 1.   , 0.997, 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.689, 0.836, 0.996, 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split4_test_f1_micro': array([0.635, 0.703, 0.635, 0.858, 1.   , 0.998, 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.703, 0.858, 0.997, 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'mean_test_f1_micro': array([0.6354, 0.698 , 0.636 , 0.8378, 1.    , 0.9978, 1.    , 1.    ,\n",
       "        1.    , 1.    , 1.    , 1.    , 1.    , 1.    , 1.    , 1.    ,\n",
       "        1.    , 1.    , 0.698 , 0.8374, 0.9974, 1.    , 1.    , 1.    ,\n",
       "        1.    , 1.    , 1.    , 1.    , 1.    ]),\n",
       " 'std_test_f1_micro': array([0.0004899 , 0.00586515, 0.00154919, 0.01397712, 0.        ,\n",
       "        0.00074833, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.00586515, 0.01444438,\n",
       "        0.0010198 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ]),\n",
       " 'rank_test_f1_micro': array([29, 26, 28, 24,  1, 22,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1, 26, 25, 23,  1,  1,  1,  1,  1,  1,  1,  1], dtype=int32)}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "binding-federal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([29, 26, 28, 24,  1, 22,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1, 26, 25, 23,  1,  1,  1,  1,  1,  1,  1,  1], dtype=int32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.cv_results_['rank_test_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "formed-transmission",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 0.01,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for accuracy\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_accuracy']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "legal-elite",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 0.01,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for roc auc\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_roc_auc_ovr']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ambient-holocaust",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 0.01,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for f1\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_f1_micro']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "checked-infrastructure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best accuracy model\n",
    "acc_model = LogisticRegression(penalty = 'l1', C = 0.01, solver = 'saga', max_iter = 5000)\n",
    "\n",
    "# best roc auc model\n",
    "roc_model = LogisticRegression(penalty = 'l1', C = 0.01, solver = 'saga', max_iter = 5000)\n",
    "\n",
    "# best f1 model\n",
    "f1_model = LogisticRegression(penalty = 'l1', C = 0.01, solver = 'saga', max_iter = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "twelve-commissioner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, max_iter=5000, penalty='l1', solver='saga')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# models the data\n",
    "acc_model.fit(X_train, Y_train)\n",
    "roc_model.fit(X_train, Y_train)\n",
    "f1_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "brazilian-cooper",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>C</th>\n",
       "      <th>penalty</th>\n",
       "      <th>solver</th>\n",
       "      <th>score_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.3646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.3020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.3640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.1622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.3020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.1626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           classifier           C penalty solver  score_acc\n",
       "0   LogisticRegression(max_iter=5000)      0.0001      l1   saga     0.3646\n",
       "1   LogisticRegression(max_iter=5000)      0.0001      l2   saga     0.3020\n",
       "2   LogisticRegression(max_iter=5000)      0.0010      l1   saga     0.3640\n",
       "3   LogisticRegression(max_iter=5000)      0.0010      l2   saga     0.1622\n",
       "4   LogisticRegression(max_iter=5000)      0.0100      l1   saga     0.0000\n",
       "5   LogisticRegression(max_iter=5000)      0.0100      l2   saga     0.0022\n",
       "6   LogisticRegression(max_iter=5000)      0.1000      l1   saga     0.0000\n",
       "7   LogisticRegression(max_iter=5000)      0.1000      l2   saga     0.0000\n",
       "8   LogisticRegression(max_iter=5000)      1.0000      l1   saga     0.0000\n",
       "9   LogisticRegression(max_iter=5000)      1.0000      l2   saga     0.0000\n",
       "10  LogisticRegression(max_iter=5000)     10.0000      l1   saga     0.0000\n",
       "11  LogisticRegression(max_iter=5000)     10.0000      l2   saga     0.0000\n",
       "12  LogisticRegression(max_iter=5000)    100.0000      l1   saga     0.0000\n",
       "13  LogisticRegression(max_iter=5000)    100.0000      l2   saga     0.0000\n",
       "14  LogisticRegression(max_iter=5000)   1000.0000      l1   saga     0.0000\n",
       "15  LogisticRegression(max_iter=5000)   1000.0000      l2   saga     0.0000\n",
       "16  LogisticRegression(max_iter=5000)  10000.0000      l1   saga     0.0000\n",
       "17  LogisticRegression(max_iter=5000)  10000.0000      l2   saga     0.0000\n",
       "18  LogisticRegression(max_iter=5000)      0.0001      l2  lbfgs     0.3020\n",
       "19  LogisticRegression(max_iter=5000)      0.0010      l2  lbfgs     0.1626\n",
       "20  LogisticRegression(max_iter=5000)      0.0100      l2  lbfgs     0.0026\n",
       "21  LogisticRegression(max_iter=5000)      0.1000      l2  lbfgs     0.0000\n",
       "22  LogisticRegression(max_iter=5000)      1.0000      l2  lbfgs     0.0000\n",
       "23  LogisticRegression(max_iter=5000)     10.0000      l2  lbfgs     0.0000\n",
       "24  LogisticRegression(max_iter=5000)    100.0000      l2  lbfgs     0.0000\n",
       "25  LogisticRegression(max_iter=5000)   1000.0000      l2  lbfgs     0.0000\n",
       "26  LogisticRegression(max_iter=5000)  10000.0000      l2  lbfgs     0.0000\n",
       "27  LogisticRegression(max_iter=5000)         NaN    none  lbfgs     0.0000\n",
       "28  LogisticRegression(max_iter=5000)         NaN    none   saga     0.0000"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEGCAYAAACkQqisAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAA//klEQVR4nO3de1iU1fr4//cAkocUFJ0ZTqkF/TTFQ4nFZ7ulUETDUTwgUdHOr2bb7TbNa6tp5jYUOprZTiu1XaZJeEqFQSWxLeJnl5UpHitNFJCZUTynBg7z+4NPo6MwDAjMM3C/uua6eJ5Z98xaK5mbtZ5n1lJZLBYLQgghRA24ObsCQgghXJckESGEEDUmSUQIIUSNSRIRQghRY5JEhBBC1JiHsysghKg7Hp7+zq5Co3C9pPCO4kvP/Opw2SZt772j96ptMhIRQghRYzISEUIIZyszO7sGNSZJRAghnM183dk1qDFJIkII4WQWS5mzq1BjkkSEEMLZyiSJCCGEqKlaHolkZ2eTlJREWVkZsbGxjBs3zub5bdu2sXDhQtzc3HB3d2fmzJn06tULgIiICFq0aGF9bv369XbfS+7OEkLUmagBj3LwQDZHDuUwbeqECssseCeRI4dy2PPDV/Ts0bXK2NatvdmSkcLhgzlsyUjB29urzttR58rMjj+qYDabSUxMZNmyZej1etLT0zl69KhNmbCwMDZt2sTGjRtJTk5m1qxZNs8vX76cjRs3VplAQJKIEKKOuLm58d7CJAbrniak+2PExcXQuXOwTZlBAyMIDupIpwf6MH78dBa9/1qVsdOnTWD71zl07tKH7V/nMH1axcnJpVjKHH9UITc3l/bt2xMYGIinpyfR0dFkZWXZlGnRogUqlQqAq1evWn+uCUkiQog60Tu0J8eO5XH8+ElKS0tZvXojQ3RRNmV0uihWfL4WgG9378HL2wutVm03VqeL4rMVawD4bMUahgwZWL8NqwMW83WHH6mpqQwfPtz6SE1NtXkto9GIVqu1Hms0GoxG423v+dVXXzFw4ECef/55kpOTbZ4bM2ZMha9dEZe8JlJQUMBzzz3HQw89xI8//ohGo2Hx4sVs2rSJ1NRUSktLad++PW+++SbNmjXjpZde4u677+bAgQOcPn2aqVOnMnCg6//DE0LJ/Py15Becsh4XFBbRO7SnTRl/Py0F+TfKFBYU4e+ntRurUbfFYDABYDCYULfzqctm1I9qXFiPi4sjLi6u0ucr2iKqopFGZGQkkZGRfPfddyxcuJBPP/0UgJSUFDQaDcXFxYwePZp7772X0NDQSt/PZUciJ06c4KmnnkKv19OyZUu2bt1KZGQk69atY9OmTdx7772sXbvWWt5kMrFq1So++ugj5s+f78SaC9E4VPTBdesHXGVlHIltUGpxOkur1WIwGKzHRqMRtVpdafnQ0FBOnjzJ2bNngfKRC4CPjw+RkZHk5ubafT+XTSIBAQF07twZgC5dulBYWMgvv/zCk08+iU6nIy0tjV9++cVavn///ri5uREUFMSZM2ecVW0hGo3CgiICA/ysxwH+vhQV2U6rFBQWERB4o4x/gC+niox2Y42mM2i15R+KWq0a0+niumxG/ajFC+shISHk5eWRn59PSUkJer2eiIgImzInTpywJuWDBw9SWlpK69atuXLlCpcvXwbgypUr7Nq1i+Dg4Nve42YuOZ0F4Onpaf3Z3d2d33//nZdeeonFixfTqVMn1q9fz+7duyssL4Soe999v5egoI506BBIYaGBUaOGkvCM7UXw9PRM/jb+WVJTN/Jw7we5eOEiBoOJ06eLK41NT8vkmYRY3nxrEc8kxJKWttUZzatdtXiLr4eHB7Nnz2bs2LGYzWZGjBhBcHAwKSkpAMTHx7N161Y2btyIh4cHTZs2ZcGCBahUKoqLi5kwobyfzWYzgwcPpm/fvvbfr9ZqrgC//fYb7dq1o7S0lLS0NOuwTAhR/8xmM5MmzyJDvwp3Nzc+XZ7KoUM/M+65BACWLF1BxuYsBg6M4KfDu7hy9Spjx06xGwvwxluL+GLVh4x+Np78/ELi4p93WhtrTS0vexIeHk54eLjNufj4eOvP48aNu+27IwCBgYFs2rSpWu/VoJLIpEmTiI2Nxd/fn/vvv5/ffvvN2VUSolHbvGU7m7dstzm3ZOkKm+MXJr3scCzA2bPnGDCw8gvLLsmFv7GusjToq1VCNG6yn0j9uNP9RK7ty3C4bNPuj9/Re9W2BjUSEUIIlyQLMAohhKgxF57OkiQihBDOJiMRIYQQNWYudXYNakySiBBCOJtMZzU8pWd+dXYVGrTr21c6uwqNwqWVz9Py6Y+cXQ1RFZnOEkIo1Z3efirqgYxEhBBC1JgkESGEEDVlkQvrQgghakyuiQghhKgxmc4SQghRYzISEbUt55vvef3dDzGXlTFCN5CxCaNsnt++87/8a+lnuKnccHd356VJ43iwe1cALl66zD9ff5ejv54AlYq5M1+kR9fOLPp4Jes2baG1txcAk57/C33/p3e9t00pdv1yijf131NmsTDsoSD+X98uNs9/fTifxVm5qFQqPNxUTH38IXq2V9uNfWfLHrJ/KqSJuxsBbe7m1WFhtGome9mIKshIpHqys7NJSkqirKyM2NjY29a1t1gsJCUlsWPHDpo2bcrrr79Oly5d7MaeP3+eF198kcLCQvz9/Xn33Xfx8vLi3LlzvPDCCxw4cIBhw4Yxe/bsem9vdZnNZubNX8TSd5PRqtsSN3YSj/V5mPs6treWeeShHjzW5xFUKhU/HT3OP15JJi1lKQCvv/shf3q4FwuSZlFaWsrVa79b4xLiYhj95Mh6b5PSmMvKeC3tOz58NgJNq+Y89eEWwjsFcJ/ay1rm4Xu1PNopAJVKxc+Gc0xLzWHDJJ3d2EeCfHkhsgce7m68u/VH/p19kMlRPe3URAhceiRS79vjms1mEhMTWbZsGXq9nvT0dI4ePWpTJjs7m7y8PDIzM5k7dy5z5sypMnbJkiWEhYWRmZlJWFgYS5YsAeCuu+5i0qRJTJs2rV7beSf2H/6ZewL8CPT3pUmTJgzqF872nd/YlGnevJl1H+qr167B//18+bff+GHfAUboogBo0qQJrVreXb8NcAEHCooJ9GlJQJuWNPFwJyqkPf85nG9TpvldTW70ccl1VA7E/k+QLx7u5b9W3QLbYrx4pd7aJFzY9euOPxSm3pNIbm4u7du3JzAwEE9PT6Kjo8nKyrIpk5WVRUxMDCqVih49enDx4kVMJpPd2D9iAGJiYti2bRsAzZs3p1evXtx111312s47YTp9Bq26nfVYo25b4T7S23bsQhf/HH/7x2zmznwRgIJCA629vZiV9A4jn53A7Nfe5crVa9aYlHVpDHtmPLOS3+HCxUt13xiFMl28itarufVY49Uc06Wrt5XbfiifmIVpTFz5H+YMe6RasRv2HKNPsN9t54W4jaXM8YfC1HsSMRqNaLVa67FGo8FoNNoto9VqMRqNdmOLi4tRq8vnq9VqNWfPnq3LZtSpirYJU6luP9c//E+kpSzlvddn8/7SzwC4bjZz+OejxA2LZu2ni2jWrCkfr1gNQNywaDav/jfrPl1EO582vPX+0rpshqJZuL2TK+hiIh4IZMMkHQue7MvirFyHY5f+5wDubioe797hzisrGr6yMscfClPvSaSijRRVt3xCVlbGkdiGQKNui8F02npsNJ2hXVufSsv36hFCfmER585fQKtui6ZdW7p16QTAgEf7cOjn8im/tm1a4+7ujpubGyOHDOLA/+1Z3RhpWjXHcOHGVJPxwhXatWxWafmHOmjIP3uJc79dqzJ204+/svPnQpJH/qlB/vsUdUBGIo7TarUYDAbrsdFotI4gKitjMBhQq9V2Y318fDCZTACYTCbatGlTl82oU1073c/JglMUnDJQWlrK5qwdPNbnEZsyJwtOWZPqoZ+OUlp6HW+vVrT1aYNW3Y7jJwoA+OaHvdzX4R4ATp+5MTrL2vG/BN3bnsaqi78PJ4svUXjuMqXXzWzdf4LwTgE2ZU4WX7L28eFTZyk1l+Hd/C67sbt+OcWnOw/y7lPhNPOUmx+Fg1x4JFLv/8pDQkLIy8sjPz8fjUaDXq9n/vz5NmUiIiJYuXIl0dHR7Nu3j5YtW6JWq2nTpk2lsREREWzYsIFx48axYcMG+vXrV99NqzUeHu7MfHE8z0+ZhdlsZtjgAQTd257UL/VA+bTUV//JYdPmLDw8PGh6lydvJ75k/at35ovjmf7qm5ReLyXQz9d6vWT+4o/56ZdfQQX+Wg3/nPaC09robB7ubrw0uBfjl2+nrMzC0AfvI0jjzZrd5aOz2N73k3XwJGl7j+Ph7kbTJu68Gden/HZfd1WFsQCvp39HyfUy/vrpdgC6Bfowa8jDzmqmcBW1PMKo6g7Ybdu2sXDhQtzcyr8iMHPmTHr16uVQ7K1UlormiOrYjh07SE5Oxmw2M2LECMaPH09KSgoA8fHxWCwWEhMT2blzJ82aNSM5OZmQkJBKYwHOnTvH5MmTKSoqwtfXl4ULF+Lt7Q2UJ5jLly9TWlpKy5Yt+fe//01QUJDdOspS8HVLloKvP81GKf+29sbu6upEh8tW9f/TbDYTFRXFJ598gkajYeTIkbzzzjs2n3m//fYbzZs3R6VSceTIESZPnsyWLVscir2VU8bb4eHhhIeH25yLj4+3/qxSqfjnP//pcCxA69atWb58eYUx27dvv4PaCiFEHavFv+VvvosVsN7FenMiaNGihfXnq1evWmcxHIm9lUzaCiGEs1XjWkdqaiqpqanW47i4OOLi4qzHFd3Fmpube9vrfPXVV8yfP5+zZ8/y0UcfVSv2ZpJEhBDC2aqRROLibZPGrRy9izUyMpLIyEi+++47Fi5cyKefflqjO2AliQghhLPV4oV1R+6AvVloaCgnT57k7Nmz1Y4FJ9ziK4QQ4hZms+OPKtx8B2xJSQl6vZ6IiAibMidOnLCOOg4ePEhpaSmtW7d2KPZWMhIRTuER8TSZXV52djUahehRVZcRTlaL3//w8PBg9uzZjB071noXa3BwsM0dsFu3bmXjxo3lXxFo2pQFCxaU375eSaw9TrnF1xXILb51SxJI/Yk2pji7CqIKVz/+h8Nlm415uw5rUn0yEhFCCGdT4HImjpIkIoQQTmYpc90JIUkiQgjhbApcE8tRkkSEEMLZHLjrSqkkiQghhLPJSEQIIUSNSRIRtS3nm+95/d0PMZeVMUI3kLEJtjf7b9/5X/619DPcVOVLOb80aRwPdu8KwMVLl/nn6+9y9NcToFIxd+aL9Oja2Rr7yaq1zF/0MTv1X9Da26te26Uk7R7rzgPznkHl7kb+519z7F+bbJ5vEeRH94XP0yqkIz+/lsqvH+itz3m0ak63d8bRslMAWGDfix9x/vtf6DT7STQDHqSs1MyVPCP7Jn3IddlnXVTFhb9pobhvrGdnZxMVFUVkZCRLliy57XmLxcK8efOIjIxEp9Nx8ODBKmM3b95MdHQ0nTp1Yv/+/fXSjjthNpuZN38RH8yfy6bPPyJj2384dvyETZlHHurB+uWLWbd8EXNnvsg/X19ofe71dz/kTw/3Ii1lKeuXL+Le9oHW54qMp/nvdz/iq7G/lEGD56aiy+uj2f3kG+z48z/wG/Y/3H2/v02R0vOXOfjyco5/kH5beJd5f+H01/vY0ecfZEdM5/LPhQCc2bGf7PBp7HxsOr8dKyLohaH10hzh4lx4UypFJRGz2UxiYiLLli1Dr9eTnp7O0aNHbcpkZ2eTl5dHZmYmc+fOZc6cOVXG3n///fzrX/8iNDS0vptUI/sP/8w9AX4E+vvSpEkTBvULZ/vOb2zKNG/ezLow2tVr16ybsF/+7Td+2HeAEbooAJo0aUKrlndb49587yOm/G1MhXu2NybeDwZx5biBqydMWErNnNrwXzQDe9mUKTlzkQt7f6Ws1Paip8fdzWgT1on8z78GwFJqto42zuzYj8Vc/ot+7odfaOrnujtsinpUZnH8oTCKms5yZC37rKwsYmJiUKlU9OjRg4sXL2IymSgsLKw09r777nNKe2rKdPoMWnU767FG3Zb9B3+6rdy2HbtY+OGnFJ87z+K3yze1KSg00Nrbi1lJ7/DT0V954P8L5qXJf6V5s6Z8vfMb1O3a0in43npri1I11bbm6qli6/G1U8V4P2h/o7I/NG+vpqT4It0W/pVWXdpzIfdXDs36DPOV323KBT75KEUbvqnkVYS4iQvfnaWokUhFa9kbjUa7ZbRaLUaj0aFYV1HR9GhFI4f+4X8iLWUp770+m/eXfgbAdbOZwz8fJW5YNGs/XUSzZk35eMVqrl67xpLPvuDvYxPquPYu4g6GYioPd1qFdOTk8q/I6T8D85XfuW/iEJsyQZNjsFwvo3Bdzp3WVDQClrIyhx9Ko6gk4sha9pWVqck6+EqlUbfFYDptPTaaztCurU+l5Xv1CCG/sIhz5y+gVbdF064t3bp0AmDAo3049PNR8guLKDxlYMRf/saAEX/BePoMsf9vImeKz9Z5e5ToWtFZmvnd6NOmfj5cM5xzLPZUMddOneX8nmMAFKV9i1dIR+vz/qP6oo7syY9/e792Ky0aLheezlJUEnFkLftbyxgMBtRqdY3WwVeqrp3u52TBKQpOGSgtLWVz1g4e6/OITZmTBaesifPQT0cpLb2Ot1cr2vq0Qatux/ETBQB888Ne7utwD/ff15Fs/RdkrltO5rrlaNq1Zc2//0Vbn8Y5Z3/hx2O0uFdLs3vaoWrijl9MGMatPzgU+/vpC1w7VUyL+3wBaPvnrlz6uby/2z3Wnfv+ruP7Z96m7GpJndVfNDCWMscfCqOoayI3r2Wv0WjQ6/XMnz/fpkxERAQrV64kOjqaffv20bJlS9RqNW3atKky1lV4eLgz88XxPD9lFmazmWGDBxB0b3tSvyy/xTRuWDRf/SeHTZuzypdyvsuTtxNfso68Zr44numvvknp9VIC/XyZO/NFZzZHkSzmMg7M+JTeX8xA5e5GQcp/uPxTAfc80x+Ak59t4652XvwpMwmPls2gzEKHcYPI/vNUrl++ysGZn9Jj8d9x8/Tgygkj+yaVby/a5bVncfNsQu/VMwE4/8NRDkz72GntFC5CgSMMRyluKfgdO3aQnJxsXct+/PjxNuvgWywWEhMT2blzJ82aNSM5OZmQkJBKY6F8L+G5c+dy9uxZWrVqRefOnfn4Y/u/2LIUfN2SpeDrjywFr3y/zX7C4bItEr+ow5pUn+KSiFJIEqlbkkTqjyQR5fvtFcd3Dmsxd3Ud1qT6FDWdJYQQjZILT2dJEhFCCCdT4q27jpIkIoQQziYjESGEEDUmSaThaeb3Z2dXoUFzza+BuqZSZ1dAVM2Flz2RJCKEEE5W23usZ2dnk5SURFlZGbGxsYwbN87m+U2bNrF06VIAWrRowZw5c+jUqXyVi4iICFq0aIGbW/k2E+vXr7f7XpJEhBDC2Woxifyxovknn3yCRqNh5MiRRERE2CxkGxAQwMqVK/Hy8mLHjh288sorrFmzxvr88uXLadPGsdUsFLXsiRBCNEq1uJ/Izauhe3p6Wlc0v9mDDz6Il1f5hnQ9evSwWTKqumQkIoQQzlaNkUhqaiqpqanW47i4OOLi4qzHFa1onpubW+nrrV27lr59+9qcGzNmDCqV6rbXrogkESGEcLZqJJGqPtirs6L5N998w9q1a1m1apX1XEpKChqNhuLiYkaPHs29995rd0M/mc4SQggns5jLHH5UxdEVzY8cOcKsWbNYvHgxrVu3tp7XaDQA+Pj4EBkZaXcUA5JEFCtqwKMcPJDNkUM5TJs6ocIyC95J5MihHPb88BU9e3StMrZ1a2+2ZKRw+GAOWzJS8Pb2qvN2KNmAAY9y4EA2hw/lMNVOHx+uoI8ri339tVns37+DPT98xZo1y/DyalXn7RANQC3uJ3LzauglJSXo9XoiIiJsypw6dYqJEyfy5ptv0rHjjb1wrly5wuXLl60/79q1i+DgYLvv5zJJJDs7m6ioKCIjI1myZMltz1ssFubNm0dkZCQ6nY6DBw9an5sxYwZhYWEMHjy4PqtcY25ubry3MInBuqcJ6f4YcXExdO5s+z9y0MAIgoM60umBPowfP51F779WZez0aRPY/nUOnbv0YfvXOUyfVvEHZ2PwRz/pdE/TrftjPFFBHw8cGEFQUEc6/18fv39LH1cUuy0rmx49InjwoUh++eVXpk//e723TbgeS5nF4UdVPDw8mD17NmPHjuXxxx9n0KBBBAcHk5KSYl0RfdGiRZw/f55XX32VoUOHMnz4cACKi4t58sknGTJkCLGxsYSHh992veS297vz5tc9R25Zy87OJi8vj8zMTPbt28ecOXOst6wNHz6cp59+munTpzurCdXSO7Qnx47lcfz4SQBWr97IEF0Uhw//Yi2j00Wx4vO1AHy7ew9e3l5otWo6tA+sNFani6Jf/5EAfLZiDVnb1jJjZnI9t04Zbu3j1NUb0d3Sx0N0Uax0oI9vjt22Ldsa/+23exgxPLoeWyVcVi1/TyQ8PJzw8HCbc/Hx8dafk5KSSEpKui0uMDCQTZs2Veu9XGIk4sgta1lZWcTExKBSqejRowcXL17EZDIBEBoaar2dzRX4+WvJLzhlPS4oLMLPT2tTxt9PS0H+jTKFBUX4+2ntxmrUbTEYyvvEYDChblf5lrsNnZ+/loKb+qmwsLz/bMrY6eOqYgGeffYJtmz9ug5qLxqcsmo8FMYlkkhFt6wZjUa7ZbRa7W1lXEVFd1LcesdFZWUciRV138cvvfQC169fZ9Uq+9/2FQLAcr3M4YfSuMR0liO3rFXntjalKywoIjDAz3oc4O9LUZFtQiwoLCIg8EYZ/wBfThUZ8fT0rDTWaDqDVqvGYDCh1aoxnS6u45YoV2FBEQE39ZO/f3n/2ZSx08f2YhMSYol+vD8DohzfaEg0csrLDQ5ziZGII7es3VrGYDBUeFubK/ju+70EBXWkQ4dAmjRpwqhRQ0lLz7Qpk56eScJT5dc3Hu79IBcvXMRgMNmNTU/L5JmEWACeSYglLW1r/TZMQW7tp7hRQ0m/pY/T0jN52oE+vjl2wIBH+cc//saw4c9y9eq1em+XcE21eWG9vrnESOTmW9Y0Gg16vZ758+fblImIiGDlypVER0ezb98+WrZs6bJJxGw2M2nyLDL0q3B3c+PT5akcOvQz455LAGDJ0hVkbM5i4MAIfjq8iytXrzJ27BS7sQBvvLWIL1Z9yOhn48nPLyQu/nmntdHZ/ugnvZ0+3rw5i0EDIzhyeBdXK+jjW2MBFr47j7vuuostm8v3wf722z1M+PtLzmmkcB0uPBJxmT3Wd+zYQXJyMmazmREjRjB+/Hjr7Wrx8fFYLBYSExPZuXMnzZo1Izk5mZCQEACmTJnC7t27OXfuHD4+PkycOJHY2Fi77+fh6V/nbWrMXHOi0TWVlhQ6uwqiCmeHhVdd6P+0+XJHHdak+lwmidQ3SSJ1S5JI/ZEkonxnh1YjiWxUVhJxieksIYRoyCzXnV2DmpMkIoQQTmZx4WsikkSEEMLZJIkIIYSoKRmJCCGEqDFJIkJUk9wSKMQNFrPr3q8oSUQIIZxMRiJCCCFqzFImIxEhhBA1JCMRIYQQNWaxyEhECCFEDclIRAghRI2VufDdWS6xn0hjFDXgUQ4eyObIoRymTZ1QYZkF7yRy5FAOe374ip49ulYZ27q1N1syUjh8MIctGSl4e7vOlsF1QfpYKIWlTOXwQ2lcPolkZ2cTFRVFZGQkS5Ysue35Y8eOERcXR9euXfn444+dUMPqc3Nz472FSQzWPU1I98eIi4uhc+dgmzKDBkYQHNSRTg/0Yfz46Sx6/7UqY6dPm8D2r3Po3KUP27/OYfq0ij84GwPpY6EktZ1Eqvpc3LRpEzqdDp1OxxNPPMGRI0ccjr2VSycRs9lMYmIiy5YtQ6/Xk56eztGjR23KeHt78/LLLzNmzBgn1bL6eof25NixPI4fP0lpaSmrV29kiC7KpoxOF8WKz9cC8O3uPXh5e6HVqu3G6nRRfLZiDQCfrVjDkCED67dhCiJ9LJTEYnH8URVHPhcDAgJYuXIlaWlpjB8/nldeecXh2Fu5dBLJzc2lffv2BAYG4unpSXR0NFlZWTZlfHx86NatGx4ernP5x89fS37BKetxQWERfn5amzL+floK8m+UKSwowt9PazdWo26LwWACwGAwoW7nU5fNUDTpY6EktTkSceRz8cEHH8TLq3yqtUePHtatxR2JvZVLJxGj0YhWe+MXX6PRYDQanVij2qFS3f4P5da9wyor40iskD4WymKxqBx+VKW6n4tr166lb9++NYoFF787q6Jf3Ip+wV1NYUERgQF+1uMAf1+Kimz/RxYUFhEQeKOMf4Avp4qMeHp6VhprNJ1Bq1VjMJjQatWYThfXcUuUS/pYKIm5Gndnpaamkpqaaj2Oi4sjLi7Oelydz8VvvvmGtWvXsmrVqmrH/sGlRyJardY6DIPyLKpWq51Yo9rx3fd7CQrqSIcOgTRp0oRRo4aSlp5pUyY9PZOEp0YC8HDvB7l44SIGg8lubHpaJs8klO8t/0xCLGlpW+u3YQoifSyUpDojkbi4ONavX2993JxAwPHPxSNHjjBr1iwWL15M69atqxV7M5ceiYSEhJCXl0d+fj4ajQa9Xs/8+fOdXa07ZjabmTR5Fhn6Vbi7ufHp8lQOHfqZcc8lALBk6QoyNmcxcGAEPx3exZWrVxk7dordWIA33lrEF6s+ZPSz8eTnFxIX/7zT2uhs0sdCSWrz1l1HPhdPnTrFxIkTefPNN+nYsWO1Ym+lsrj4ZO6OHTtITk7GbDYzYsQIxo8fT0pKCgDx8fGcPn2aESNGcPnyZdzc3GjevDkZGRncfffddl/Xw9O/PqovRJ27XlLo7CqIKhwOftzhsp1/yaiyTFWfiy+//DKZmZn4+ZVPy7q7u7N+/fpKY+1x+SRSVySJiIZCkojyHbov2uGyDxzT12FNqs+lp7OEEKIhMJe57uVpSSJCCOFkrjwfJElECCGcrMyFl4K3O4Y6ceIEP/zww23nv//+e06ePFlnlRJCiMakNr9sWN/sJpHk5GRatGhx2/m77rqL5OTkOquUEEI0JrW5dlZ9szudVVhYSKdOnW47HxISQmGh3PEhhBC1wZWns+wmkd9//73S565du1brlRFCiMbIle/OslvzkJAQVq9efdv5NWvW0KVLlzqrlBBCNCaWajyUxu6XDc+cOcPf//53mjRpYk0aBw4coLS0lPfff5927drVW0Xrm3zZUDQU8mVD5ftf3xEOl/2fonV1WJPqszud1bZtW7744gu++eYbfvnlFwDCw8MJCwurl8oJIURjoMS7rhzl0PdEHnnkER555JG6rosQQjRKZc6uwB2QLxsKIYSTWXDdkYjr3hLQwEUNeJSDB7I5ciiHaVMnVFhmwTuJHDmUw54fvqJnj65VxrZu7c2WjBQOH8xhS0YK3t5edd4OJZM+Fkpx3aJy+KE0Lp9EZsyYQVhYGIMHD67weYvFwrx584iMjESn03Hw4MF6rmH1ubm58d7CJAbrniak+2PExcXQuXOwTZlBAyMIDupIpwf6MH78dBa9/1qVsdOnTWD71zl07tKH7V/nMH1axR+cjYH0sVASCyqHH0rj8klk+PDhLFu2rNLns7OzycvLIzMzk7lz5zJnzpz6q1wN9Q7tybFjeRw/fpLS0lJWr97IEF2UTRmdLooVn68F4Nvde/Dy9kKrVduN1emi+GzFGgA+W7GGIUMG1m/DFET6WChJWTUeSuPySSQ0NBQvr8qnDLKysoiJiUGlUtGjRw8uXryIyWSqxxpWn5+/lvyCU9bjgsIi/Py0NmX8/bQU5N8oU1hQhL+f1m6sRt0Wg6G87QaDCXU7n7pshqJJHwslkZGIghmNRrTaGx8OWq0Wo9HoxBpVTaW6/R/KrV/nqayMI7FC+lgoiyuPRBr83VkV/XJX9CGgJIUFRQQG+FmPA/x9KSqyTXwFhUUEBN4o4x/gy6kiI56enpXGGk1n0GrVGAwmtFo1ptPFddwS5ZI+FkpiVuAIw1ENfiSi1WoxGAzWY4PBgFqtdmKNqvbd93sJCupIhw6BNGnShFGjhpKWnmlTJj09k4SnRgLwcO8HuXjhIgaDyW5selomzyTEAvBMQixpaVvrt2EKIn0slKRM5fhDaRr8SCQiIoKVK1cSHR3Nvn37aNmypeKTiNlsZtLkWWToV+Hu5sany1M5dOhnxj2XAMCSpSvI2JzFwIER/HR4F1euXmXs2Cl2YwHeeGsRX6z6kNHPxpOfX0hc/PNOa6OzSR8LJSlz4ZGI3bWzXMGUKVPYvXs3586dw8fHh4kTJ3L9+nUA4uPjsVgsJCYmsnPnTpo1a0ZycjIhISFVvq6snSUaClk7S/k2aJ90uGyMYVUd1qT6XD6J1BVJIqKhkCSifOurkUSGO5BEsrOzSUpKoqysjNjYWMaNG2fz/LFjx5g5cyYHDx7kxRdfZMyYMdbnIiIiaNGiBW5ubri7u7N+/Xq779Xgp7OEEELpymrxZh+z2UxiYiKffPIJGo2GkSNHEhERQVBQkLWMt7c3L7/8MllZWRW+xvLly2nTpo1D79fgL6wLIYTSmavxqEpubi7t27cnMDAQT09PoqOjb0sWPj4+dOvWDQ+POx9HyEhECCGcrDp3XaWmppKammo9jouLIy4uznp863fjNBoNubm51arPmDFjUKlUt712RSSJCCGEk1Xn7qz4Kj7Y7/S7cSkpKWg0GoqLixk9ejT33nsvoaGhlZaX6SwhhHCy2twe99bvxhmNxmp9rUGj0QDlU16RkZFVjmIkiQghhJPV5pcNQ0JCyMvLIz8/n5KSEvR6PREREQ7V48qVK1y+fNn6865duwgODrYbI9NZQgjhZLW5JpaHhwezZ89m7NixmM1mRowYQXBwMCkpKUD59+dOnz7NiBEjuHz5Mm5ubixfvpyMjAzOnTvHhAnl2xeYzWYGDx5M37597b6ffE+kEvI9EdFQyPdElO/jgKcdLjumYGUd1qT6ZCQihBBOpsTVeR0lSUQIIZxMkogQQogaU+DW6Q6TJCKEEE7myiMRucVXoaIGPMrBA9kcOZTDtKkTKiyz4J1EjhzKYc8PX9GzR9cqY1u39mZLRgqHD+awJSMFb+/KtxVuDKSPhVLU5rIn9c0lksiMGTMICwtj8ODB1nPnz59n9OjRDBgwgNGjR3PhwoUKY7Ozs4mKiiIyMpIlS5bUV5XviJubG+8tTGKw7mlCuj9GXFwMnTvb3qs9aGAEwUEd6fRAH8aPn86i91+rMnb6tAls/zqHzl36sP3rHKZPq/iDszGQPhZK4sqbUrlEEhk+fDjLli2zObdkyRLCwsLIzMwkLCyswgTxx2qWy5YtQ6/Xk56eztGjR+ur2jXWO7Qnx47lcfz4SUpLS1m9eiNDdFE2ZXS6KFZ8vhaAb3fvwcvbC61WbTdWp4visxVrAPhsxRqGDBlYvw1TEOljoSSuvMe6SySR0NBQvLxspwWysrKIiYkBICYmhm3btt0W58hqlkrk568lv+CU9bigsAg/P61NGX8/LQX5N8oUFhTh76e1G6tRt8VgMAFgMJhQt/Opy2YomvSxUBJJIk5QXFxsXQ9GrVZz9uzZ28pUtJql0WistzrWVEWLpd36ndDKyjgSK6SPhbLU5tpZ9a1B3511p6tZOkthQRGBAX7W4wB/X4qKbJNfQWERAYE3yvgH+HKqyIinp2elsUbTGbRaNQaDCa1Wjel0cR23RLmkj4WSKPFah6NcdiTi4+ODyVQ+bWAymSrchetOV7N0lu++30tQUEc6dAikSZMmjBo1lLT0TJsy6emZJDw1EoCHez/IxQsXMRhMdmPT0zJ5JiEWgGcSYklL21q/DVMQ6WOhJK58d5bLjkQiIiLYsGED48aNY8OGDfTr1++2MjevZqnRaNDr9cyfP98Jta0es9nMpMmzyNCvwt3NjU+Xp3Lo0M+Mey4BgCVLV5CxOYuBAyP46fAurly9ytixU+zGArzx1iK+WPUho5+NJz+/kLj4553WRmeTPhZKUqbIiSrHuMQCjFOmTGH37t2cO3cOHx8fJk6cSP/+/Zk8eTJFRUX4+vqycOFCvL29MRqNzJo1i6VLlwKwY8cOkpOTratZjh8/3qH3lAUYRUMhCzAq39z2Tzlc9pUTn9dhTarPJZKIM0gSEQ2FJBHlS6xGEpmtsCTistNZQgjRUCjx1l1HSRIRQggnu65y3QkhSSJCCOFkrptCJIkIIYTTyXSWEEKIGnPlW3wliQghhJO5bgqRJCKEEE7nytNZLrvsiRBCNBRmLA4/HFHVPkrHjh0jLi6Orl278vHHH1cr9lYyEhFCCCerzZHIH/soffLJJ2g0GkaOHElERARBQUHWMt7e3rz88su3bY3hSOytZCQihBBOZqnGf1VxZB8lHx8funXrhoeHR7VjbyUjESGEcLLqjERSU1NJTU21HsfFxREXF2c9rmgfpdzcXIdeuyaxMhJRqKgBj3LwQDZHDuUwbWrF+3QveCeRI4dy2PPDV/Ts0bXK2NatvdmSkcLhgzlsyUjB29uropdtNKSPhVKUYXH4ERcXx/r1662PmxMI3Nk+SjWJVVQSmTFjBmFhYQwePNh67vz584wePZoBAwYwevRoLly4YH3uo48+IjIykqioKHbu3Fnha9qLVyo3NzfeW5jEYN3ThHR/jLi4GDp3DrYpM2hgBMFBHen0QB/Gj5/OovdfqzJ2+rQJbP86h85d+rD96xymT6v4g7MxkD4WSlKbOxveyT5KNYlVVBIZPnw4y5Ytszm3ZMkSwsLCyMzMJCwszHq3wNGjR9Hr9ej1epYtW8arr76K2Xz7li2VxStZ79CeHDuWx/HjJyktLWX16o0M0UXZlNHpoljx+VoAvt29By9vL7Ratd1YnS6Kz1asAeCzFWsYMmRg/TZMQaSPhZJcx+Lwoyo376NUUlKCXq8nIiLCoXrUJFZRSSQ0NBQvL9vhf1ZWFjExMQDExMSwbds26/no6OjyrUoDA2nfvn2Fc3eVxSuZn7+W/IJT1uOCwiL8/LQ2Zfz9tBTk3yhTWFCEv5/WbqxG3RaDoXw3SIPBhLqdT102Q9Gkj4WS1OaFdQ8PD2bPns3YsWN5/PHHGTRoEMHBwaSkpJCSkgLA6dOn6du3L5988gkffPABffv25fLly5XG2n2/WumBOlRcXGwdTqnVas6ePQuUD7O6d+9uLafRaDAajQ7HK1lFc5C3zlVWVsaRWCF9LJSltr9sGB4eTnh4uM25+Ph468/t2rUjOzvb4Vh7FJ9EKnMnF4+UrrCgiMAAP+txgL8vRUW2CbKgsIiAwBtl/AN8OVVkLB+ZVRJrNJ1Bq1VjMJjQatWYThfXcUuUS/pYKIkjIwylUtR0VkV8fHwwmcqnB0wmE23atAEcvwBUWbySfff9XoKCOtKhQyBNmjRh1KihpKVn2pRJT88k4amRADzc+0EuXriIwWCyG5uelskzCbEAPJMQS1ra1vptmIJIHwslKavGQ2kUn0QiIiLYsGEDABs2bKBfv37W83q9npKSEvLz88nLy6Nbt24OxyuZ2Wxm0uRZZOhXcSD3P6xdm8ahQz8z7rkExj2XAEDG5ix+PX6Snw7v4sMP3+TvE2fajQV4461F9O/Xl8MHc+jfry9vvLnIaW10NuljoSRmi8Xhh9Ioao/1KVOmsHv3bs6dO4ePjw8TJ06kf//+TJ48maKiInx9fVm4cCHe3t4AfPDBB6xbtw53d3dmzpxpncd7+eWXeeKJJwgJCeHcuXOVxtsje6yLhkL2WFe+J9sPc7jsqhNf1mFNqk9RSURJJImIhkKSiPLFt49xuGzKiQ11Vo+acNkL60II0VAo8VqHoySJCCGEk8nOhkIIIWrMlW/xlSQihBBOpsS7rhwlSUQIIZxMprOEEELUmFxYF0IIUWNyTUQIIUSNyXSWEEKIGnPl73xLEhFCCCczy0hECCFETcl0lhBCiBpz5eksxS8F31hFDXiUgweyOXIoh2lTJ1RYZsE7iRw5lMOeH76iZ4+uVca2bu3NlowUDh/MYUtGCt7eXhW9bKMhfSyUogyLww+lcUoSmTFjBmFhYQwePNh67vz584wePZoBAwYwevRoLly4YH3uo48+IjIykqioKHbu3Gk9f+DAAXQ6HZGRkcybN6/SbF5ZvFK5ubnx3sIkBuueJqT7Y8TFxdC5s+0+x4MGRhAc1JFOD/Rh/PjpLHr/tSpjp0+bwPavc+jcpQ/bv85h+rSKPzgbA+ljoSS1ucd6fXNKEhk+fDjLli2zObdkyRLCwsLIzMwkLCyMJUuWAHD06FH0ej16vZ5ly5bx6quvYjabAZgzZw6JiYlkZmaSl5dX4Z7B9uKVqndoT44dy+P48ZOUlpayevVGhuiibMrodFGs+HwtAN/u3oOXtxdardpurE4XxWcr1gDw2Yo1DBkysH4bpiDSx0JJXHlTKqckkdDQULy8bIf5WVlZxMTEABATE8O2bdus56Ojo8v3tQ4MpH379uTm5mIymbh8+TI9e/ZEpVIRExNDVlbWbe9VWbyS+flryS84ZT0uKCzCz09rU8bfT0tB/o0yhQVF+Ptp7cZq1G0xGMq3CjYYTKjb+dRlMxRN+lgoiStPZynmwnpxcbF1j3S1Ws3Zs2eB8r3Tu3fvbi2n0WgwGo14eHig1d74pddqtRiNxttet7J4JVOpVLedu3WqrrIyjsQK6WOhLLWdHLKzs0lKSqKsrIzY2FjGjRtn87zFYiEpKYkdO3bQtGlTXn/9dbp06QKUbyneokUL3NzccHd3Z/369XbfSzFJpDIV/XKqVKpKzzsar2SFBUUEBvhZjwP8fSkqsk18BYVFBATeKOMf4MupImP5iKuSWKPpDFqtGoPBhFarxnS6uI5bolzSx0JJavOPELPZTGJiIp988gkajYaRI0cSERFBUFCQtUx2djZ5eXlkZmayb98+5syZw5o1a6zPL1++nDZt2jj0foq5O8vHxweTqXwawGQyWRug1WoxGAzWckajEbVafdt5g8FgHcncrLJ4Jfvu+70EBXWkQ4dAmjRpwqhRQ0lLz7Qpk56eScJTIwF4uPeDXLxwEYPBZDc2PS2TZxJiAXgmIZa0tK312zAFkT4WSlKb01m5ubm0b9+ewMBAPD09iY6Ovm2q/4/LByqVih49enDx4kXr5291KSaJREREsGHDBgA2bNhAv379rOf1ej0lJSXk5+eTl5dHt27dUKvVtGjRgr1792KxWGxibn3diuKVzGw2M2nyLDL0qziQ+x/Wrk3j0KGfGfdcAuOeSwAgY3MWvx4/yU+Hd/Hhh2/y94kz7cYCvPHWIvr368vhgzn079eXN95c5LQ2Opv0sVCS6tydlZqayvDhw62P1NRUm9cyGo02U/0VTeHfWubWywFjxoyp8LUrorI4YTJ3ypQp7N69m3PnzuHj48PEiRPp378/kydPpqioCF9fXxYuXIi3tzcAH3zwAevWrcPd3Z2ZM2cSHh4OwP79+5kxYwbXrl2jb9++vPLKK6hUKrKysjhw4ACTJk2yG2+Ph6d/nbVfiPp0vaTQ2VUQVXjQt4/DZfcU5dh9fvPmzeTk5JCUlASU/1G+f/9+XnnlFWuZcePGMW7cOHr16gXAX/7yF6ZOnUrXrl0xGo1oNBqKi4sZPXo0r7zyCqGhoZW+n1OSiCuQJCIaCkkiytdT+yeHy/5o2GX/+R9/5P333+fjjz8Gyr8nB/D8889by8yePZvevXtbv6sXFRXFihUrbpvq/9e//kXz5s0ZM2ZMpe+nmOksIYRorGrzmkhISAh5eXnk5+dTUlKCXq8nIiLCpswflw8sFgt79+6lZcuWqNVqrly5wuXLlwG4cuUKu3btIjg4uKK3sVL83VlCCNHQ1eY30T08PJg9ezZjx47FbDYzYsQIgoODSUlJASA+Pp7w8HB27NhBZGQkzZo1Izk5GSj/qsWECeWrLJjNZgYPHkzfvn3tvp9MZ1VCprNEQyHTWcrXVfOIw2UPGL+pw5pUn4xEhBDCyZS4JpajJIkIIYSTmS1lzq5CjUkSEUIIJytz4asKkkSEEMLJZDpLCCFEjclIRAghRI3JSEQIIUSNmS3K3ijPHkkiQgjhZK78dT1JIkII4WRK3LHQUbJ2lkJFDXiUgweyOXIoh2lTJ1RYZsE7iRw5lMOeH76iZ4+uVca2bu3NlowUDh/MYUtGCt7eXhW9bKMhfSyUwmKxOPxQmjpLIjNmzCAsLMy6SiTA+fPnGT16NAMGDGD06NFcuHDB+txHH31EZGQkUVFR7Ny503r+wIED6HQ6IiMjmTdvnrUTS0pKmDx5MpGRkcTGxlJQUFBhPSqLVzI3NzfeW5jEYN3ThHR/jLi4GDp3tl0EbdDACIKDOtLpgT6MHz+dRe+/VmXs9GkT2P51Dp279GH71zlMn1bxB2djIH0slKTMYnH4oTR1lkSGDx/OsmXLbM4tWbKEsLAwMjMzCQsLY8mSJQAcPXoUvV6PXq9n2bJlvPrqq5jN5Rea5syZQ2JiIpmZmeTl5ZGdnQ3AmjVraNWqFV999RXPPvssb7/9doX1qCxeyXqH9uTYsTyOHz9JaWkpq1dvZIguyqaMThfFis/XAvDt7j14eXuh1artxup0UXy2onwLzM9WrGHIkIH12zAFkT4WSlKdTamUps6SSGhoKF5etkP5P7ZkBIiJiWHbtm3W89HR0eV7VwcG0r59e3JzczGZTFy+fJmePXuiUqmIiYmxbvO4fft2hg0bBpSvhf/f//73tlGGvXgl8/PXkl9wynpcUFiEn5/Wpoy/n5aC/BtlCguK8PfT2o3VqNtiMJRvgWkwmFC386nLZiia9LFQErOlzOGH0tTrNZHi4mLrpidqtZqzZ88ClW/naG8LR6PRiK+vL1C+9HHLli05d+6czftVtQWkUqlUqtvO3ZogKyvjSKyQPhbK4srXRBRxd1ZFHaNSqSo9by/GkddVusKCIgID/KzHAf6+FBXZJr+CwiICAm+U8Q/w5VSRsXw0V0ms0XQGrVaNwWBCq1VjOl1cxy1RLuljoSRKvNbhqHodifj4+GAylQ/1TSYTbdq0AcpHCAaDwVrOaDSiVqtvO28wGKwjGa1WS1FREQDXr1/n0qVL1j3Z/2AvXsm++34vQUEd6dAhkCZNmjBq1FDS0jNtyqSnZ5Lw1EgAHu79IBcvXMRgMNmNTU/L5JmEWACeSYglLW1r/TZMQaSPhZK48kikXpPIH1syQvnm8f369bOe1+v1lJSUkJ+fT15eHt26dUOtVtOiRQv27t2LxWK5LebLL78EYOvWrTzyyCO3jTLsxSuZ2Wxm0uRZZOhXcSD3P6xdm8ahQz8z7rkExj2XAEDG5ix+PX6Snw7v4sMP3+TvE2fajQV4461F9O/Xl8MHc+jfry9vvLnIaW10NuljoSS1uT1ufauznQ2nTJnC7t27OXfuHD4+PkycOJH+/fszefJkioqK8PX1ZeHChdbRwwcffMC6detwd3dn5syZhIeHA7B//35mzJjBtWvX6Nu3L6+88goqlYrff/+dqVOncvjwYby8vFiwYAGBgYEADB06lI0bN9qNr4rsbCgaCtnZUPlatbjX4bIXf/u1DmtSfbI9biUkiYiGQpKI8rVo3sHhsr9dyauzetSEIi6sCyFEY+bKF9YliQghhJO58oSQrJ0lhBBOVtvfWM/OziYqKorIyEjryiA272exMG/ePCIjI9HpdBw8eNDh2FtJEhFCCCerzVt8zWYziYmJLFu2DL1eT3p6OkePHrUpk52dTV5eHpmZmcydO5c5c+Y4HHsrSSJCCOFktbkAY25uLu3btycwMBBPT0+io6NvW+7pjyWoVCoVPXr04OLFi5hMJodibyXXRCohd7QIIepLdT5vUlNTSU1NtR7HxcURFxdnPa5oGanc3Fyb16hsSShHYm8lSUQIIVzIrUnjVneyJFRNloqSJCKEEA1IZctI2Svzx5JQpaWlVcbeSq6JCCFEAxISEkJeXh75+fmUlJSg1+uJiIiwKfPHElQWi4W9e/fSsmVL1Gq1Q7G3kpGIEEI0IB4eHsyePZuxY8diNpsZMWIEwcHBpKSkABAfH094eDg7duwgMjKSZs2akZycbDfWHln2RAghRI3JdJYQQogakyQihBCixiSJuLCePXtafx4zZgy9evXi+eefd2KNGp4/+vjw4cPExcURHR2NTqcjIyPDyTUTQhnkwnoDMXbsWK5evWrzJSRRe5o2bcobb7xBhw4dMBqNjBgxgj59+tCqVStnV00Ip5Ik0kCEhYXx7bffOrsaDVbHjh2tP2s0Gtq0acPZs2cliTigoKCA5557joceeogff/wRjUbD4sWLOX78OP/85z+5evUq99xzD8nJyXh5eZGQkEC3bt349ttvuXTpEklJSfTq1Quz2czbb7/N7t27KSkp4amnnuKJJ55wdvMaPZnOEqKacnNzKS0t5Z577nF2VVzGiRMneOqpp9Dr9bRs2ZKtW7cybdo0/vGPf5CWlsb999/P+++/by1vNptZu3YtM2fOtJ5fu3YtLVu2ZN26daxbt47Vq1eTn5/vrCaJ/yMjESGqwWQyMXXqVN544w3c3ORvMEcFBATQuXNnALp06UJ+fj6XLl2id+/eAAwbNoxJkyZZy0dGRlrLFhaWryu1a9cufvrpJ7Zu3QrApUuXOHHihHVbbOEckkSEcNDly5d5/vnnmTx5Mj169HB2dVyKp6en9Wd3d3cuXrzoUHk3NzfMZjNQvt7TrFmz+POf/1x3FRXVJn9KCeGAkpISJkyYwNChQxk0aJCzq+PyWrZsSatWrfj+++8B2LhxI6GhoXZj+vTpQ0pKCqWlpQAcP36cK1eu1HldhX0yEmkgnnzySX799VeuXLlC3759SUpKkr/YatHmzZv5/vvvOX/+PF9++SUAr7/+unWKRlTfG2+8Yb2wHhgYyGuvvWa3fGxsLIWFhQwfPhyLxULr1q1ZvHhxPdVWVEaWPRFCCFFjMp0lhBCixiSJCCGEqDFJIkIIIWpMkogQQogakyQihBCixiSJCFELCgoKGDx4MFC+4u+OHTucXCMh6ockESFqmSQR0ZhIEhGNQkFBAQMHDmT69OnodDpeeOEFrl69yoEDB3j66acZPnw4Y8aMwWQyAZCQkMBbb73FyJEjiYqKsn6zuqCggCeffJJhw4YxbNgw9uzZY/M+JSUlvPfee2RkZDB06FAyMjIYMGAAZ8+eBaCsrIzIyEjrsRCuTpKIaDSOHz/OqFGjSEtLo0WLFnz++efMmzeP9957j/Xr1zNixAgWLFhgLV/RSrI+Pj588sknfPnllyxYsIB58+bZvIenpycvvPACjz/+OBs3buTxxx9nyJAhbNq0CYD//d//pVOnTrRp06b+Gi5EHZJlT0Sj4evry0MPPQTAkCFD+Oijj/j5558ZPXo0UD5KaNeunbV8RSvJXr9+ncTERI4cOYKbmxt5eXlVvu+IESP429/+xrPPPsu6desYPnx4LbdMCOeRJCIaDZVKZXPcokULgoODK90NsqKVZD/99FPatm3Lxo0bKSsro1u3blW+r6+vLz4+Pvz3v/9l3759vP3223fYEiGUQ6azRKNx6tQpfvzxRwD0ej3du3fn7Nmz1nOlpaX88ssvdl/j0qVLtGvXDjc3NzZu3GhNLjdr0aIFv/32m8252NhYpk6dyqBBg3B3d6+lFgnhfJJERKNx33338eWXX6LT6bhw4QIJCQm89957vP322wwZMoSYmBhrQqnMk08+yZdffsmoUaPIy8ujefPmt5V5+OGHOXr0qPXCOkBERARXrlyRqSzR4MgqvqJRKCgo4K9//Svp6elOef/9+/fz2muvsWrVKqe8vxB1Ra6JCFHHlixZQkpKCm+99ZazqyJErZORiBBCiBqTayJCCCFqTJKIEEKIGpMkIoQQosYkiQghhKgxSSJCCCFq7P8H9Zf8Gz0adGQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = pd.DataFrame( best_model.cv_results_['params'] )\n",
    "\n",
    "results['score_acc'] = 1 - best_model.cv_results_['mean_test_accuracy']\n",
    "\n",
    "cols = results.columns.to_series().str.split('__').apply(lambda x: x[-1])\n",
    "results.columns = cols\n",
    "\n",
    "# Heat map\n",
    "sns.heatmap( results.query('solver==\"saga\"').pivot('C','penalty','score_acc'),\n",
    "             annot=True, fmt='.3f')\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "drawn-latvia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets another 5000 random samples\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_e, Y_e, train_size = 5000, random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "developing-handy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "pipe = Pipeline([('classifier', LogisticRegression())])\n",
    "\n",
    "search_space = [{'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['saga'],\n",
    "                 'classifier__penalty': ['l1', 'l2'],\n",
    "                 'classifier__C': np.logspace(-4, 4, 9)},\n",
    "                {'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['lbfgs'],\n",
    "                 'classifier__penalty': ['l2'],\n",
    "                 'classifier__C': np.logspace(-4, 4, 9)},\n",
    "                {'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['lbfgs','saga'],\n",
    "                 'classifier__penalty': ['none']}]\n",
    "                \n",
    "clf = GridSearchCV(pipe, search_space, cv=StratifiedKFold(n_splits=5), \n",
    "                   scoring=['accuracy', 'roc_auc_ovr', 'f1_micro'], refit=False,\n",
    "                   verbose=0)\n",
    "                \n",
    "best_model = clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "modified-catholic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 0.22601151,  0.43601012,  0.64634614,  0.71485868,  1.10584936,\n",
       "         1.74551649,  3.67404103,  2.7894186 ,  8.01760473,  1.67055182,\n",
       "        15.42340331,  4.36484365, 18.05366025, 11.50476575, 16.31682878,\n",
       "        12.20116477, 16.39952965, 15.07746878,  4.97312016,  8.98158865,\n",
       "        13.00464673, 17.5458405 , 21.74188638, 26.85414324, 23.7325973 ,\n",
       "        18.389572  , 13.51846571,  6.39971919,  0.94647779]),\n",
       " 'std_fit_time': array([0.38713257, 0.69753975, 0.68070008, 0.71990872, 1.09409468,\n",
       "        0.8271255 , 1.34997576, 0.57564888, 1.59598079, 0.21948737,\n",
       "        1.9742616 , 0.77477336, 1.41249437, 1.98902154, 1.54230985,\n",
       "        0.91302608, 0.98933015, 4.60149001, 1.05697639, 1.0206786 ,\n",
       "        0.84195885, 1.41616236, 3.33271607, 3.29170386, 1.61607244,\n",
       "        1.60767509, 1.18052309, 0.16459014, 0.04366687]),\n",
       " 'mean_score_time': array([0.48056769, 0.78992801, 0.43832202, 0.77516913, 0.89150686,\n",
       "        0.37270823, 0.58940787, 0.54913793, 0.64118943, 0.3458034 ,\n",
       "        0.36068692, 0.79057226, 0.31389341, 0.37280493, 1.07671595,\n",
       "        1.25566368, 0.40134935, 0.61857371, 0.44232373, 0.3791172 ,\n",
       "        0.75328641, 1.13708997, 0.49806585, 0.48695149, 0.36508799,\n",
       "        0.39887862, 0.45965629, 0.37983289, 0.40213041]),\n",
       " 'std_score_time': array([0.13445386, 0.64778025, 0.08682126, 0.60118816, 0.64343784,\n",
       "        0.16356046, 0.42791587, 0.32940116, 0.57250212, 0.08602463,\n",
       "        0.088228  , 0.60742978, 0.02348504, 0.05441306, 0.73309929,\n",
       "        0.88427933, 0.05323949, 0.49141096, 0.08263944, 0.0423036 ,\n",
       "        0.63240354, 0.72000117, 0.0977368 , 0.0703281 , 0.07795175,\n",
       "        0.05250278, 0.14180847, 0.05360548, 0.04239809]),\n",
       " 'param_classifier': masked_array(data=[LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000)],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__C': masked_array(data=[0.0001, 0.0001, 0.001, 0.001, 0.01, 0.01, 0.1, 0.1,\n",
       "                    1.0, 1.0, 10.0, 10.0, 100.0, 100.0, 1000.0, 1000.0,\n",
       "                    10000.0, 10000.0, 0.0001, 0.001, 0.01, 0.1, 1.0, 10.0,\n",
       "                    100.0, 1000.0, 10000.0, --, --],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False,  True,  True],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__penalty': masked_array(data=['l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1',\n",
       "                    'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'none', 'none'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__solver': masked_array(data=['saga', 'saga', 'saga', 'saga', 'saga', 'saga', 'saga',\n",
       "                    'saga', 'saga', 'saga', 'saga', 'saga', 'saga', 'saga',\n",
       "                    'saga', 'saga', 'saga', 'saga', 'lbfgs', 'lbfgs',\n",
       "                    'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs',\n",
       "                    'lbfgs', 'lbfgs', 'saga'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__penalty': 'none',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__penalty': 'none',\n",
       "   'classifier__solver': 'saga'}],\n",
       " 'split0_test_accuracy': array([0.636, 0.707, 0.639, 0.825, 1.   , 0.996, 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.707, 0.825, 0.996, 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split1_test_accuracy': array([0.636, 0.705, 0.638, 0.844, 1.   , 0.998, 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.705, 0.843, 0.998, 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split2_test_accuracy': array([0.636, 0.713, 0.636, 0.845, 1.   , 0.996, 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.713, 0.845, 0.996, 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split3_test_accuracy': array([0.636, 0.694, 0.639, 0.839, 1.   , 0.997, 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.694, 0.838, 0.997, 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split4_test_accuracy': array([0.636, 0.702, 0.637, 0.83 , 1.   , 0.999, 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.702, 0.83 , 0.999, 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'mean_test_accuracy': array([0.636 , 0.7042, 0.6378, 0.8366, 1.    , 0.9972, 1.    , 1.    ,\n",
       "        1.    , 1.    , 1.    , 1.    , 1.    , 1.    , 1.    , 1.    ,\n",
       "        1.    , 1.    , 0.7042, 0.8362, 0.9972, 1.    , 1.    , 1.    ,\n",
       "        1.    , 1.    , 1.    , 1.    , 1.    ]),\n",
       " 'std_test_accuracy': array([0.        , 0.00624179, 0.00116619, 0.00786384, 0.        ,\n",
       "        0.00116619, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.00624179, 0.00762627,\n",
       "        0.00116619, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ]),\n",
       " 'rank_test_accuracy': array([29, 26, 28, 24,  1, 22,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1, 26, 25, 22,  1,  1,  1,  1,  1,  1,  1,  1], dtype=int32),\n",
       " 'split0_test_roc_auc_ovr': array([0.5       , 0.82695763, 0.77293697, 0.91308574, 1.        ,\n",
       "        0.9999568 , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.82694899, 0.91295615,\n",
       "        0.99993953, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'split1_test_roc_auc_ovr': array([0.5       , 0.83916909, 0.79389125, 0.92142684, 1.        ,\n",
       "        0.99998272, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.83915613, 0.92129294,\n",
       "        0.99996976, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'split2_test_roc_auc_ovr': array([0.5       , 0.84985573, 0.80110495, 0.93127549, 1.        ,\n",
       "        0.99999568, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.84986005, 0.93117614,\n",
       "        0.99999568, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'split3_test_roc_auc_ovr': array([0.5       , 0.82881505, 0.77660429, 0.91780704, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.82881073, 0.91767745,\n",
       "        0.99999136, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'split4_test_roc_auc_ovr': array([0.5       , 0.84957927, 0.80109631, 0.93057571, 1.        ,\n",
       "        0.99999136, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.84958359, 0.9304634 ,\n",
       "        0.99998272, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'mean_test_roc_auc_ovr': array([0.5       , 0.83887535, 0.78912675, 0.92283416, 1.        ,\n",
       "        0.99998531, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.8388719 , 0.92271321,\n",
       "        0.99997581, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'std_test_roc_auc_ovr': array([0.00000000e+00, 9.78233559e-03, 1.20695404e-02, 7.11999910e-03,\n",
       "        0.00000000e+00, 1.53573060e-05, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 9.78716750e-03, 7.13110028e-03,\n",
       "        2.01868157e-05, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00]),\n",
       " 'rank_test_roc_auc_ovr': array([29, 26, 28, 24,  1, 22,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1, 27, 25, 23,  1,  1,  1,  1,  1,  1,  1,  1], dtype=int32),\n",
       " 'split0_test_f1_micro': array([0.636, 0.707, 0.639, 0.825, 1.   , 0.996, 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.707, 0.825, 0.996, 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split1_test_f1_micro': array([0.636, 0.705, 0.638, 0.844, 1.   , 0.998, 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.705, 0.843, 0.998, 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split2_test_f1_micro': array([0.636, 0.713, 0.636, 0.845, 1.   , 0.996, 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.713, 0.845, 0.996, 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split3_test_f1_micro': array([0.636, 0.694, 0.639, 0.839, 1.   , 0.997, 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.694, 0.838, 0.997, 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split4_test_f1_micro': array([0.636, 0.702, 0.637, 0.83 , 1.   , 0.999, 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.702, 0.83 , 0.999, 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'mean_test_f1_micro': array([0.636 , 0.7042, 0.6378, 0.8366, 1.    , 0.9972, 1.    , 1.    ,\n",
       "        1.    , 1.    , 1.    , 1.    , 1.    , 1.    , 1.    , 1.    ,\n",
       "        1.    , 1.    , 0.7042, 0.8362, 0.9972, 1.    , 1.    , 1.    ,\n",
       "        1.    , 1.    , 1.    , 1.    , 1.    ]),\n",
       " 'std_test_f1_micro': array([0.        , 0.00624179, 0.00116619, 0.00786384, 0.        ,\n",
       "        0.00116619, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.00624179, 0.00762627,\n",
       "        0.00116619, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ]),\n",
       " 'rank_test_f1_micro': array([29, 26, 28, 24,  1, 22,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1, 26, 25, 22,  1,  1,  1,  1,  1,  1,  1,  1], dtype=int32)}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "liked-shopping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([29, 26, 28, 24,  1, 22,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1, 26, 25, 22,  1,  1,  1,  1,  1,  1,  1,  1], dtype=int32)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.cv_results_['rank_test_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "another-tampa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 0.01,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for accuracy\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_accuracy']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "grave-allocation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 0.01,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for roc auc\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_roc_auc_ovr']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "signal-citation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 0.01,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for f1\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_f1_micro']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "executive-stupid",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best accuracy model\n",
    "acc_model = LogisticRegression(penalty = 'l1', C = 0.01, solver = 'saga', max_iter = 5000)\n",
    "\n",
    "# best roc auc model\n",
    "roc_model = LogisticRegression(penalty = 'l1', C = 0.01, solver = 'saga', max_iter = 5000)\n",
    "\n",
    "# best f1 model\n",
    "f1_model = LogisticRegression(penalty = 'l1', C = 0.01, solver = 'saga', max_iter = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "quick-forwarding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, max_iter=5000, penalty='l1', solver='saga')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# models the data\n",
    "acc_model.fit(X_train, Y_train)\n",
    "roc_model.fit(X_train, Y_train)\n",
    "f1_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "lovely-sector",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>C</th>\n",
       "      <th>penalty</th>\n",
       "      <th>solver</th>\n",
       "      <th>score_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.3640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.3622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.1634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.2958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.1638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           classifier           C penalty solver  score_acc\n",
       "0   LogisticRegression(max_iter=5000)      0.0001      l1   saga     0.3640\n",
       "1   LogisticRegression(max_iter=5000)      0.0001      l2   saga     0.2958\n",
       "2   LogisticRegression(max_iter=5000)      0.0010      l1   saga     0.3622\n",
       "3   LogisticRegression(max_iter=5000)      0.0010      l2   saga     0.1634\n",
       "4   LogisticRegression(max_iter=5000)      0.0100      l1   saga     0.0000\n",
       "5   LogisticRegression(max_iter=5000)      0.0100      l2   saga     0.0028\n",
       "6   LogisticRegression(max_iter=5000)      0.1000      l1   saga     0.0000\n",
       "7   LogisticRegression(max_iter=5000)      0.1000      l2   saga     0.0000\n",
       "8   LogisticRegression(max_iter=5000)      1.0000      l1   saga     0.0000\n",
       "9   LogisticRegression(max_iter=5000)      1.0000      l2   saga     0.0000\n",
       "10  LogisticRegression(max_iter=5000)     10.0000      l1   saga     0.0000\n",
       "11  LogisticRegression(max_iter=5000)     10.0000      l2   saga     0.0000\n",
       "12  LogisticRegression(max_iter=5000)    100.0000      l1   saga     0.0000\n",
       "13  LogisticRegression(max_iter=5000)    100.0000      l2   saga     0.0000\n",
       "14  LogisticRegression(max_iter=5000)   1000.0000      l1   saga     0.0000\n",
       "15  LogisticRegression(max_iter=5000)   1000.0000      l2   saga     0.0000\n",
       "16  LogisticRegression(max_iter=5000)  10000.0000      l1   saga     0.0000\n",
       "17  LogisticRegression(max_iter=5000)  10000.0000      l2   saga     0.0000\n",
       "18  LogisticRegression(max_iter=5000)      0.0001      l2  lbfgs     0.2958\n",
       "19  LogisticRegression(max_iter=5000)      0.0010      l2  lbfgs     0.1638\n",
       "20  LogisticRegression(max_iter=5000)      0.0100      l2  lbfgs     0.0028\n",
       "21  LogisticRegression(max_iter=5000)      0.1000      l2  lbfgs     0.0000\n",
       "22  LogisticRegression(max_iter=5000)      1.0000      l2  lbfgs     0.0000\n",
       "23  LogisticRegression(max_iter=5000)     10.0000      l2  lbfgs     0.0000\n",
       "24  LogisticRegression(max_iter=5000)    100.0000      l2  lbfgs     0.0000\n",
       "25  LogisticRegression(max_iter=5000)   1000.0000      l2  lbfgs     0.0000\n",
       "26  LogisticRegression(max_iter=5000)  10000.0000      l2  lbfgs     0.0000\n",
       "27  LogisticRegression(max_iter=5000)         NaN    none  lbfgs     0.0000\n",
       "28  LogisticRegression(max_iter=5000)         NaN    none   saga     0.0000"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = pd.DataFrame( best_model.cv_results_['params'] )\n",
    "\n",
    "results['score_acc'] = 1 - best_model.cv_results_['mean_test_accuracy']\n",
    "\n",
    "cols = results.columns.to_series().str.split('__').apply(lambda x: x[-1])\n",
    "results.columns = cols\n",
    "\n",
    "# Heat map\n",
    "sns.heatmap( results.query('solver==\"saga\"').pivot('C','penalty','score_acc'),\n",
    "             annot=True, fmt='.3f')\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "intended-fundamental",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets another 5000 random samples\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_e, Y_e, train_size = 5000, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "romantic-aging",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "pipe = Pipeline([('classifier', LogisticRegression())])\n",
    "\n",
    "search_space = [{'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['saga'],\n",
    "                 'classifier__penalty': ['l1', 'l2'],\n",
    "                 'classifier__C': np.logspace(-4, 4, 9)},\n",
    "                {'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['lbfgs'],\n",
    "                 'classifier__penalty': ['l2'],\n",
    "                 'classifier__C': np.logspace(-4, 4, 9)},\n",
    "                {'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['lbfgs','saga'],\n",
    "                 'classifier__penalty': ['none']}]\n",
    "                \n",
    "clf = GridSearchCV(pipe, search_space, cv=StratifiedKFold(n_splits=5), \n",
    "                   scoring=['accuracy', 'roc_auc_ovr', 'f1_micro'], refit=False,\n",
    "                   verbose=0)\n",
    "                \n",
    "best_model = clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "hindu-transaction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([4.30516243e-02, 1.17904139e-01, 1.23922586e-01, 1.40566206e-01,\n",
       "        1.38671064e-01, 1.89089632e-01, 3.39349747e-01, 2.73952246e-01,\n",
       "        6.38592720e-01, 1.99400806e-01, 1.17141428e+00, 5.08151722e-01,\n",
       "        1.47335196e+00, 9.49660444e-01, 1.46009569e+00, 1.16829481e+00,\n",
       "        1.49472070e+00, 1.12128978e+00, 6.09624987e+00, 1.32592333e+01,\n",
       "        2.22997622e+01, 3.34607073e+01, 3.89386249e+01, 4.28993760e+01,\n",
       "        4.42402589e+01, 4.81786952e+01, 3.33375563e+01, 1.51765368e+01,\n",
       "        2.66842277e+01]),\n",
       " 'std_fit_time': array([4.39174038e-02, 3.87294076e-03, 4.85092426e-02, 5.76245472e-03,\n",
       "        4.27709874e-02, 2.04154709e-02, 6.27869023e-02, 4.93434897e-02,\n",
       "        6.84749986e-02, 3.28024238e-02, 2.72935522e-02, 3.65277294e-02,\n",
       "        1.54197381e-01, 7.23445310e-02, 1.33350620e-01, 3.50563910e-02,\n",
       "        1.38261961e-01, 3.80532832e-02, 7.53067226e-01, 3.83945277e+00,\n",
       "        2.30734580e+00, 3.50325615e+00, 6.28184523e+00, 2.87015679e+00,\n",
       "        5.07757465e+00, 6.37623355e+00, 2.79089928e+00, 1.98563266e+00,\n",
       "        3.10294348e+00]),\n",
       " 'mean_score_time': array([0.40428619, 0.48333921, 0.51716914, 0.50046477, 0.44071422,\n",
       "        0.55051932, 0.49923191, 0.50688376, 0.48131213, 0.56015816,\n",
       "        0.5070291 , 0.5911696 , 0.52564216, 0.5092741 , 0.54009905,\n",
       "        0.63036103, 0.64339976, 0.57945919, 0.48249588, 0.6208909 ,\n",
       "        1.72249203, 1.04001608, 2.67987003, 1.34090772, 0.79974513,\n",
       "        1.06065502, 0.58205247, 1.58317513, 0.61365142]),\n",
       " 'std_score_time': array([0.14237566, 0.00443953, 0.09589463, 0.08156795, 0.01323619,\n",
       "        0.08051544, 0.06733465, 0.07173375, 0.08014194, 0.10121272,\n",
       "        0.07743436, 0.11855626, 0.04523677, 0.14796529, 0.12194038,\n",
       "        0.11542484, 0.14009659, 0.07936786, 0.09701882, 0.07604932,\n",
       "        0.99478982, 0.87901787, 1.86679491, 0.85474799, 0.24468627,\n",
       "        1.01973164, 0.07400785, 1.47137974, 0.10119723]),\n",
       " 'param_classifier': masked_array(data=[LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000)],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__C': masked_array(data=[0.0001, 0.0001, 0.001, 0.001, 0.01, 0.01, 0.1, 0.1,\n",
       "                    1.0, 1.0, 10.0, 10.0, 100.0, 100.0, 1000.0, 1000.0,\n",
       "                    10000.0, 10000.0, 0.0001, 0.001, 0.01, 0.1, 1.0, 10.0,\n",
       "                    100.0, 1000.0, 10000.0, --, --],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False,  True,  True],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__penalty': masked_array(data=['l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1',\n",
       "                    'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'none', 'none'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__solver': masked_array(data=['saga', 'saga', 'saga', 'saga', 'saga', 'saga', 'saga',\n",
       "                    'saga', 'saga', 'saga', 'saga', 'saga', 'saga', 'saga',\n",
       "                    'saga', 'saga', 'saga', 'saga', 'lbfgs', 'lbfgs',\n",
       "                    'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs',\n",
       "                    'lbfgs', 'lbfgs', 'saga'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__penalty': 'none',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__penalty': 'none',\n",
       "   'classifier__solver': 'saga'}],\n",
       " 'split0_test_accuracy': array([0.635, 0.712, 0.636, 0.845, 1.   , 0.999, 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.712, 0.845, 0.999, 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split1_test_accuracy': array([0.635, 0.702, 0.642, 0.833, 1.   , 0.997, 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.702, 0.833, 0.997, 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split2_test_accuracy': array([0.635, 0.688, 0.642, 0.825, 1.   , 0.998, 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.688, 0.825, 0.998, 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split3_test_accuracy': array([0.634, 0.71 , 0.638, 0.844, 1.   , 0.998, 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.71 , 0.844, 0.998, 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split4_test_accuracy': array([0.634, 0.709, 0.639, 0.842, 1.   , 0.999, 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.709, 0.842, 0.999, 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'mean_test_accuracy': array([0.6346, 0.7042, 0.6394, 0.8378, 1.    , 0.9982, 1.    , 1.    ,\n",
       "        1.    , 1.    , 1.    , 1.    , 1.    , 1.    , 1.    , 1.    ,\n",
       "        1.    , 1.    , 0.7042, 0.8378, 0.9982, 1.    , 1.    , 1.    ,\n",
       "        1.    , 1.    , 1.    , 1.    , 1.    ]),\n",
       " 'std_test_accuracy': array([0.0004899 , 0.00877268, 0.00233238, 0.00767854, 0.        ,\n",
       "        0.00074833, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.00877268, 0.00767854,\n",
       "        0.00074833, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ]),\n",
       " 'rank_test_accuracy': array([29, 26, 28, 24,  1, 22,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1, 26, 24, 22,  1,  1,  1,  1,  1,  1,  1,  1], dtype=int32),\n",
       " 'split0_test_roc_auc_ovr': array([0.5       , 0.8519685 , 0.78671988, 0.93155862, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.85196419, 0.93143782,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'split1_test_roc_auc_ovr': array([0.5       , 0.8353964 , 0.76980261, 0.92349908, 1.        ,\n",
       "        0.99999137, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.83536188, 0.92339985,\n",
       "        0.99999137, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'split2_test_roc_auc_ovr': array([0.5       , 0.82742746, 0.7797476 , 0.91417539, 1.        ,\n",
       "        0.99999137, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.82741883, 0.91408047,\n",
       "        0.99998706, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'split3_test_roc_auc_ovr': array([0.5       , 0.83933651, 0.77708107, 0.92319129, 1.        ,\n",
       "        0.99999569, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.83932789, 0.92308355,\n",
       "        0.99999569, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'split4_test_roc_auc_ovr': array([0.5       , 0.84065522, 0.79721087, 0.9228336 , 1.        ,\n",
       "        0.99998707, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.8406466 , 0.92266553,\n",
       "        0.99998707, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'mean_test_roc_auc_ovr': array([0.5       , 0.83895682, 0.78211241, 0.9230516 , 1.        ,\n",
       "        0.9999931 , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.83894388, 0.92293344,\n",
       "        0.99999224, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'std_test_roc_auc_ovr': array([0.00000000e+00, 7.97415011e-03, 9.29118131e-03, 5.50316113e-03,\n",
       "        0.00000000e+00, 4.39644487e-06, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 7.97787697e-03, 5.49566051e-03,\n",
       "        5.02916344e-06, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00]),\n",
       " 'rank_test_roc_auc_ovr': array([29, 26, 28, 24,  1, 22,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1, 27, 25, 23,  1,  1,  1,  1,  1,  1,  1,  1], dtype=int32),\n",
       " 'split0_test_f1_micro': array([0.635, 0.712, 0.636, 0.845, 1.   , 0.999, 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.712, 0.845, 0.999, 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split1_test_f1_micro': array([0.635, 0.702, 0.642, 0.833, 1.   , 0.997, 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.702, 0.833, 0.997, 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split2_test_f1_micro': array([0.635, 0.688, 0.642, 0.825, 1.   , 0.998, 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.688, 0.825, 0.998, 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split3_test_f1_micro': array([0.634, 0.71 , 0.638, 0.844, 1.   , 0.998, 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.71 , 0.844, 0.998, 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split4_test_f1_micro': array([0.634, 0.709, 0.639, 0.842, 1.   , 0.999, 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.709, 0.842, 0.999, 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'mean_test_f1_micro': array([0.6346, 0.7042, 0.6394, 0.8378, 1.    , 0.9982, 1.    , 1.    ,\n",
       "        1.    , 1.    , 1.    , 1.    , 1.    , 1.    , 1.    , 1.    ,\n",
       "        1.    , 1.    , 0.7042, 0.8378, 0.9982, 1.    , 1.    , 1.    ,\n",
       "        1.    , 1.    , 1.    , 1.    , 1.    ]),\n",
       " 'std_test_f1_micro': array([0.0004899 , 0.00877268, 0.00233238, 0.00767854, 0.        ,\n",
       "        0.00074833, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.00877268, 0.00767854,\n",
       "        0.00074833, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ]),\n",
       " 'rank_test_f1_micro': array([29, 26, 28, 24,  1, 22,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1, 26, 24, 22,  1,  1,  1,  1,  1,  1,  1,  1], dtype=int32)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "unlike-throw",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([29, 26, 28, 24,  1, 22,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1, 26, 24, 22,  1,  1,  1,  1,  1,  1,  1,  1], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.cv_results_['rank_test_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "controversial-anderson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 0.01,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for accuracy\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_accuracy']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "allied-governor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 0.01,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for roc auc\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_roc_auc_ovr']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "naval-complaint",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 0.01,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for f1\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_f1_micro']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "promotional-romantic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best accuracy model\n",
    "acc_model = LogisticRegression(penalty = 'l1', C = 0.01, solver = 'saga', max_iter = 5000)\n",
    "\n",
    "# best roc auc model\n",
    "roc_model = LogisticRegression(penalty = 'l1', C = 0.01, solver = 'saga', max_iter = 5000)\n",
    "\n",
    "# best f1 model\n",
    "f1_model = LogisticRegression(penalty = 'l1', C = 0.01, solver = 'saga', max_iter = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dated-killing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, max_iter=5000, penalty='l1', solver='saga')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# models the data\n",
    "acc_model.fit(X_train, Y_train)\n",
    "roc_model.fit(X_train, Y_train)\n",
    "f1_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "lightweight-shoulder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>C</th>\n",
       "      <th>penalty</th>\n",
       "      <th>solver</th>\n",
       "      <th>score_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.3654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.2958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.3606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.1622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.2958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.1622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           classifier           C penalty solver  score_acc\n",
       "0   LogisticRegression(max_iter=5000)      0.0001      l1   saga     0.3654\n",
       "1   LogisticRegression(max_iter=5000)      0.0001      l2   saga     0.2958\n",
       "2   LogisticRegression(max_iter=5000)      0.0010      l1   saga     0.3606\n",
       "3   LogisticRegression(max_iter=5000)      0.0010      l2   saga     0.1622\n",
       "4   LogisticRegression(max_iter=5000)      0.0100      l1   saga     0.0000\n",
       "5   LogisticRegression(max_iter=5000)      0.0100      l2   saga     0.0018\n",
       "6   LogisticRegression(max_iter=5000)      0.1000      l1   saga     0.0000\n",
       "7   LogisticRegression(max_iter=5000)      0.1000      l2   saga     0.0000\n",
       "8   LogisticRegression(max_iter=5000)      1.0000      l1   saga     0.0000\n",
       "9   LogisticRegression(max_iter=5000)      1.0000      l2   saga     0.0000\n",
       "10  LogisticRegression(max_iter=5000)     10.0000      l1   saga     0.0000\n",
       "11  LogisticRegression(max_iter=5000)     10.0000      l2   saga     0.0000\n",
       "12  LogisticRegression(max_iter=5000)    100.0000      l1   saga     0.0000\n",
       "13  LogisticRegression(max_iter=5000)    100.0000      l2   saga     0.0000\n",
       "14  LogisticRegression(max_iter=5000)   1000.0000      l1   saga     0.0000\n",
       "15  LogisticRegression(max_iter=5000)   1000.0000      l2   saga     0.0000\n",
       "16  LogisticRegression(max_iter=5000)  10000.0000      l1   saga     0.0000\n",
       "17  LogisticRegression(max_iter=5000)  10000.0000      l2   saga     0.0000\n",
       "18  LogisticRegression(max_iter=5000)      0.0001      l2  lbfgs     0.2958\n",
       "19  LogisticRegression(max_iter=5000)      0.0010      l2  lbfgs     0.1622\n",
       "20  LogisticRegression(max_iter=5000)      0.0100      l2  lbfgs     0.0018\n",
       "21  LogisticRegression(max_iter=5000)      0.1000      l2  lbfgs     0.0000\n",
       "22  LogisticRegression(max_iter=5000)      1.0000      l2  lbfgs     0.0000\n",
       "23  LogisticRegression(max_iter=5000)     10.0000      l2  lbfgs     0.0000\n",
       "24  LogisticRegression(max_iter=5000)    100.0000      l2  lbfgs     0.0000\n",
       "25  LogisticRegression(max_iter=5000)   1000.0000      l2  lbfgs     0.0000\n",
       "26  LogisticRegression(max_iter=5000)  10000.0000      l2  lbfgs     0.0000\n",
       "27  LogisticRegression(max_iter=5000)         NaN    none  lbfgs     0.0000\n",
       "28  LogisticRegression(max_iter=5000)         NaN    none   saga     0.0000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = pd.DataFrame( best_model.cv_results_['params'] )\n",
    "\n",
    "results['score_acc'] = 1 - best_model.cv_results_['mean_test_accuracy']\n",
    "\n",
    "cols = results.columns.to_series().str.split('__').apply(lambda x: x[-1])\n",
    "results.columns = cols\n",
    "\n",
    "# Heat map\n",
    "sns.heatmap( results.query('solver==\"saga\"').pivot('C','penalty','score_acc'),\n",
    "             annot=True, fmt='.3f')\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sophisticated-carroll",
   "metadata": {},
   "source": [
    "## Chess Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "european-vanilla",
   "metadata": {},
   "source": [
    "https://archive.ics.uci.edu/ml/machine-learning-databases/chess/king-rook-vs-king/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "sound-africa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>3</th>\n",
       "      <th>2</th>\n",
       "      <th>draw</th>\n",
       "      <th>eight</th>\n",
       "      <th>eleven</th>\n",
       "      <th>fifteen</th>\n",
       "      <th>five</th>\n",
       "      <th>four</th>\n",
       "      <th>fourteen</th>\n",
       "      <th>...</th>\n",
       "      <th>one</th>\n",
       "      <th>seven</th>\n",
       "      <th>six</th>\n",
       "      <th>sixteen</th>\n",
       "      <th>ten</th>\n",
       "      <th>thirteen</th>\n",
       "      <th>three</th>\n",
       "      <th>twelve</th>\n",
       "      <th>two</th>\n",
       "      <th>zero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28050</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28051</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28052</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28053</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28054</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28055 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       1  3  2  draw  eight  eleven  fifteen  five  four  fourteen  ...  one  \\\n",
       "0      1  1  2   1.0    0.0     0.0      0.0   0.0   0.0       0.0  ...  0.0   \n",
       "1      1  1  1   1.0    0.0     0.0      0.0   0.0   0.0       0.0  ...  0.0   \n",
       "2      1  1  2   1.0    0.0     0.0      0.0   0.0   0.0       0.0  ...  0.0   \n",
       "3      1  2  1   1.0    0.0     0.0      0.0   0.0   0.0       0.0  ...  0.0   \n",
       "4      1  2  3   1.0    0.0     0.0      0.0   0.0   0.0       0.0  ...  0.0   \n",
       "...   .. .. ..   ...    ...     ...      ...   ...   ...       ...  ...  ...   \n",
       "28050  1  7  5   0.0    0.0     0.0      0.0   0.0   0.0       0.0  ...  0.0   \n",
       "28051  1  7  6   0.0    0.0     0.0      0.0   0.0   0.0       0.0  ...  0.0   \n",
       "28052  1  7  7   0.0    0.0     0.0      0.0   0.0   0.0       0.0  ...  0.0   \n",
       "28053  1  7  5   0.0    0.0     0.0      0.0   0.0   0.0       0.0  ...  0.0   \n",
       "28054  1  7  5   0.0    0.0     0.0      0.0   0.0   0.0       0.0  ...  0.0   \n",
       "\n",
       "       seven  six  sixteen  ten  thirteen  three  twelve  two  zero  \n",
       "0        0.0  0.0      0.0  0.0       0.0    0.0     0.0  0.0   0.0  \n",
       "1        0.0  0.0      0.0  0.0       0.0    0.0     0.0  0.0   0.0  \n",
       "2        0.0  0.0      0.0  0.0       0.0    0.0     0.0  0.0   0.0  \n",
       "3        0.0  0.0      0.0  0.0       0.0    0.0     0.0  0.0   0.0  \n",
       "4        0.0  0.0      0.0  0.0       0.0    0.0     0.0  0.0   0.0  \n",
       "...      ...  ...      ...  ...       ...    ...     ...  ...   ...  \n",
       "28050    0.0  0.0      1.0  0.0       0.0    0.0     0.0  0.0   0.0  \n",
       "28051    0.0  0.0      1.0  0.0       0.0    0.0     0.0  0.0   0.0  \n",
       "28052    0.0  0.0      1.0  0.0       0.0    0.0     0.0  0.0   0.0  \n",
       "28053    0.0  0.0      1.0  0.0       0.0    0.0     0.0  0.0   0.0  \n",
       "28054    0.0  0.0      1.0  0.0       0.0    0.0     0.0  0.0   0.0  \n",
       "\n",
       "[28055 rows x 21 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chess = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/chess/king-rook-vs-king/krkopt.data')\n",
    "\n",
    "# One hot encoding categorical features\n",
    "encoder = OneHotEncoder().fit(chess[['draw']])\n",
    "encoder.categories_\n",
    "\n",
    "transformed = encoder.transform(chess[['draw']] ).toarray() \n",
    "transformed\n",
    "\n",
    "for index, category in enumerate( np.concatenate(encoder.categories_) ):\n",
    "    chess[category] = transformed[:,index]\n",
    "\n",
    "# Drops strings and NaN so works in Grid Search\n",
    "chess = chess.drop(columns = ['a', 'b', 'c'])\n",
    "chess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "protected-price",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stores all columns except draw in X and draw in Y\n",
    "X_c = chess.drop(['draw'], axis=1)\n",
    "Y_c = chess['draw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "changed-velvet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets 5000 random samples\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_c, Y_c, train_size = 5000, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "union-brown",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "pipe = Pipeline([('classifier', LogisticRegression())])\n",
    "\n",
    "search_space = [{'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['saga'],\n",
    "                 'classifier__penalty': ['l1', 'l2'],\n",
    "                 'classifier__C': np.logspace(-4, 4, 9)},\n",
    "                {'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['lbfgs'],\n",
    "                 'classifier__penalty': ['l2'],\n",
    "                 'classifier__C': np.logspace(-4, 4, 9)},\n",
    "                {'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['lbfgs','saga'],\n",
    "                 'classifier__penalty': ['none']}]\n",
    "                \n",
    "clf = GridSearchCV(pipe, search_space, cv=StratifiedKFold(n_splits=5), \n",
    "                   scoring=['accuracy', 'roc_auc_ovr', 'f1_micro'], refit=False,\n",
    "                   verbose=0)\n",
    "                \n",
    "best_model = clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "labeled-vaccine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([4.30783272e-02, 5.13204098e-01, 5.66349840e-01, 9.56201077e-02,\n",
       "        1.02936792e+00, 2.61469984e-01, 5.32197552e+00, 3.12132397e+00,\n",
       "        1.92838960e+01, 5.23759432e+00, 3.82463245e+01, 1.74995532e+01,\n",
       "        5.20610068e+01, 1.16100789e+01, 2.32483387e+00, 1.68704591e+00,\n",
       "        3.94978600e+00, 1.86819730e+00, 4.23526974e+00, 6.07757001e+00,\n",
       "        1.13179618e+01, 2.04779655e+01, 3.00786271e+01, 3.44175791e+01,\n",
       "        3.64756916e+01, 3.84185766e+01, 3.95975865e+01, 1.42975267e+01,\n",
       "        1.37881291e+01]),\n",
       " 'std_fit_time': array([ 0.04625285,  0.7939397 ,  1.01603564,  0.03342901,  1.20272228,\n",
       "         0.26744238,  1.44389764,  2.50018192,  3.16311127,  1.30389968,\n",
       "         4.25169442,  2.59544034,  3.55106053, 12.46458347,  0.09178186,\n",
       "         0.03543865,  3.30050505,  0.11790524,  0.52442104,  2.17668542,\n",
       "         1.40974349,  4.36966305,  4.5377706 ,  3.74443855,  5.8566035 ,\n",
       "         5.11337329,  5.56397755,  3.12567891,  3.06645363]),\n",
       " 'mean_score_time': array([0.4955184 , 1.08558755, 0.83439279, 1.08451691, 0.93299098,\n",
       "        1.19816618, 0.57687364, 0.67857752, 0.89521079, 1.02318749,\n",
       "        0.81326618, 1.46085253, 0.67772546, 0.56879301, 0.51453142,\n",
       "        0.49206314, 0.69036436, 0.56936822, 0.50200028, 0.46174641,\n",
       "        1.24133167, 1.5014698 , 0.52166557, 0.60143709, 0.70278344,\n",
       "        0.50097728, 0.58205118, 0.56273651, 0.61157365]),\n",
       " 'std_score_time': array([0.06290444, 1.05585384, 0.49068215, 1.15103774, 0.52869245,\n",
       "        1.30246464, 0.0174247 , 0.11737147, 0.42816341, 0.65280889,\n",
       "        0.48712974, 0.66983043, 0.1163939 , 0.14549229, 0.10361954,\n",
       "        0.05947854, 0.06794307, 0.10844653, 0.12443025, 0.07873601,\n",
       "        1.28706493, 1.75214692, 0.07475415, 0.14091606, 0.12656868,\n",
       "        0.1256215 , 0.23942495, 0.18678139, 0.11287671]),\n",
       " 'param_classifier': masked_array(data=[LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000)],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__C': masked_array(data=[0.0001, 0.0001, 0.001, 0.001, 0.01, 0.01, 0.1, 0.1,\n",
       "                    1.0, 1.0, 10.0, 10.0, 100.0, 100.0, 1000.0, 1000.0,\n",
       "                    10000.0, 10000.0, 0.0001, 0.001, 0.01, 0.1, 1.0, 10.0,\n",
       "                    100.0, 1000.0, 10000.0, --, --],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False,  True,  True],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__penalty': masked_array(data=['l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1',\n",
       "                    'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'none', 'none'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__solver': masked_array(data=['saga', 'saga', 'saga', 'saga', 'saga', 'saga', 'saga',\n",
       "                    'saga', 'saga', 'saga', 'saga', 'saga', 'saga', 'saga',\n",
       "                    'saga', 'saga', 'saga', 'saga', 'lbfgs', 'lbfgs',\n",
       "                    'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs',\n",
       "                    'lbfgs', 'lbfgs', 'saga'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__penalty': 'none',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__penalty': 'none',\n",
       "   'classifier__solver': 'saga'}],\n",
       " 'split0_test_accuracy': array([0.902, 0.902, 0.902, 0.902, 0.902, 0.902, 0.993, 0.902, 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.902, 0.902, 0.902, 0.902, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split1_test_accuracy': array([0.902, 0.902, 0.902, 0.902, 0.902, 0.902, 0.976, 0.906, 0.998,\n",
       "        0.998, 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.902, 0.902, 0.902, 0.906, 0.998, 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split2_test_accuracy': array([0.902, 0.902, 0.902, 0.902, 0.902, 0.902, 0.98 , 0.905, 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.902, 0.902, 0.902, 0.905, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split3_test_accuracy': array([0.901, 0.901, 0.901, 0.901, 0.901, 0.901, 0.982, 0.904, 0.999,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.901, 0.901, 0.901, 0.904, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split4_test_accuracy': array([0.901, 0.901, 0.901, 0.901, 0.901, 0.901, 0.979, 0.904, 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.901, 0.901, 0.901, 0.904, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'mean_test_accuracy': array([0.9016, 0.9016, 0.9016, 0.9016, 0.9016, 0.9016, 0.982 , 0.9042,\n",
       "        0.9994, 0.9996, 1.    , 1.    , 1.    , 1.    , 1.    , 1.    ,\n",
       "        1.    , 1.    , 0.9016, 0.9016, 0.9016, 0.9042, 0.9996, 1.    ,\n",
       "        1.    , 1.    , 1.    , 1.    , 1.    ]),\n",
       " 'std_test_accuracy': array([0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.00583095, 0.00132665, 0.0008    , 0.0008    ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.00132665, 0.0008    , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ]),\n",
       " 'rank_test_accuracy': array([21, 21, 21, 21, 21, 21, 18, 19, 17, 15,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1, 21, 21, 21, 19, 15,  1,  1,  1,  1,  1,  1], dtype=int32),\n",
       " 'split0_test_roc_auc_ovr': array([0.5       , 0.74748857, 0.5       , 0.87448527, 0.5       ,\n",
       "        0.99028237, 0.99992081, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.74759039, 0.87454183,\n",
       "        0.99032762, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'split1_test_roc_auc_ovr': array([0.5       , 0.57159826, 0.5       , 0.65282366, 0.5       ,\n",
       "        0.92833386, 0.99874994, 0.99954749, 0.99997737, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.57159826, 0.65282366,\n",
       "        0.92789266, 0.99954749, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'split2_test_roc_auc_ovr': array([0.5       , 0.61101181, 0.5       , 0.69177338, 0.5       ,\n",
       "        0.94333454, 0.99934386, 0.99967193, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.61101181, 0.69177338,\n",
       "        0.94310829, 0.99967193, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'split3_test_roc_auc_ovr': array([0.5       , 0.61882981, 0.5       , 0.7023285 , 0.5       ,\n",
       "        0.94392314, 0.99924327, 0.99971973, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.61882981, 0.70226124,\n",
       "        0.94391193, 0.99971973, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'split4_test_roc_auc_ovr': array([0.5       , 0.52780861, 0.5       , 0.59032052, 0.5       ,\n",
       "        0.90580612, 0.99937219, 0.99974215, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.52780861, 0.59032052,\n",
       "        0.90572764, 0.99974215, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'mean_test_roc_auc_ovr': array([0.5       , 0.61534741, 0.5       , 0.70234627, 0.5       ,\n",
       "        0.942336  , 0.99932601, 0.99973626, 0.99999547, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.61536778, 0.70234413,\n",
       "        0.94219363, 0.99973626, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'std_test_roc_auc_ovr': array([0.00000000e+00, 7.35788578e-02, 0.00000000e+00, 9.46000844e-02,\n",
       "        0.00000000e+00, 2.76870445e-02, 3.72810627e-04, 1.48080265e-04,\n",
       "        9.05018327e-06, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 7.36154300e-02, 9.46206780e-02,\n",
       "        2.77667270e-02, 1.48080265e-04, 0.00000000e+00, 0.00000000e+00,\n",
       "        4.96506831e-17, 4.96506831e-17, 0.00000000e+00, 7.02166694e-17,\n",
       "        0.00000000e+00]),\n",
       " 'rank_test_roc_auc_ovr': array([27, 26, 27, 23, 27, 21, 20, 18, 17,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1, 25, 24, 22, 18,  1,  1,  1,  1,  1,  1,  1], dtype=int32),\n",
       " 'split0_test_f1_micro': array([0.902, 0.902, 0.902, 0.902, 0.902, 0.902, 0.993, 0.902, 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.902, 0.902, 0.902, 0.902, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split1_test_f1_micro': array([0.902, 0.902, 0.902, 0.902, 0.902, 0.902, 0.976, 0.906, 0.998,\n",
       "        0.998, 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.902, 0.902, 0.902, 0.906, 0.998, 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split2_test_f1_micro': array([0.902, 0.902, 0.902, 0.902, 0.902, 0.902, 0.98 , 0.905, 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.902, 0.902, 0.902, 0.905, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split3_test_f1_micro': array([0.901, 0.901, 0.901, 0.901, 0.901, 0.901, 0.982, 0.904, 0.999,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.901, 0.901, 0.901, 0.904, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split4_test_f1_micro': array([0.901, 0.901, 0.901, 0.901, 0.901, 0.901, 0.979, 0.904, 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.901, 0.901, 0.901, 0.904, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'mean_test_f1_micro': array([0.9016, 0.9016, 0.9016, 0.9016, 0.9016, 0.9016, 0.982 , 0.9042,\n",
       "        0.9994, 0.9996, 1.    , 1.    , 1.    , 1.    , 1.    , 1.    ,\n",
       "        1.    , 1.    , 0.9016, 0.9016, 0.9016, 0.9042, 0.9996, 1.    ,\n",
       "        1.    , 1.    , 1.    , 1.    , 1.    ]),\n",
       " 'std_test_f1_micro': array([0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.00583095, 0.00132665, 0.0008    , 0.0008    ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.0004899 , 0.0004899 ,\n",
       "        0.0004899 , 0.00132665, 0.0008    , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ]),\n",
       " 'rank_test_f1_micro': array([21, 21, 21, 21, 21, 21, 18, 19, 17, 15,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1, 21, 21, 21, 19, 15,  1,  1,  1,  1,  1,  1], dtype=int32)}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "convenient-russia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21, 21, 21, 21, 21, 21, 18, 19, 17, 15,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1, 21, 21, 21, 19, 15,  1,  1,  1,  1,  1,  1], dtype=int32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.cv_results_['rank_test_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "prospective-position",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 10.0,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for accuracy\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_accuracy'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "super-promise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 1.0,\n",
       " 'classifier__penalty': 'l2',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for roc auc\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_roc_auc_ovr'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "taken-spencer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 10.0,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for f1\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_f1_micro'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "invalid-latex",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best accuracy model\n",
    "acc_model = LogisticRegression(penalty = 'l1', C = 10.0, solver = 'saga', max_iter = 5000)\n",
    "\n",
    "# best roc auc model\n",
    "roc_model = LogisticRegression(penalty = 'l2', C = 1.0, solver = 'saga', max_iter = 5000)\n",
    "\n",
    "# best f1 model\n",
    "f1_model = LogisticRegression(penalty = 'l1', C = 10.0, solver = 'saga', max_iter = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "banner-greene",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10.0, max_iter=5000, penalty='l1', solver='saga')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# models the data\n",
    "acc_model.fit(X_train, Y_train)\n",
    "roc_model.fit(X_train, Y_train)\n",
    "f1_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "regular-canvas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>C</th>\n",
       "      <th>penalty</th>\n",
       "      <th>solver</th>\n",
       "      <th>score_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           classifier           C penalty solver  score_acc\n",
       "0   LogisticRegression(max_iter=5000)      0.0001      l1   saga     0.0984\n",
       "1   LogisticRegression(max_iter=5000)      0.0001      l2   saga     0.0984\n",
       "2   LogisticRegression(max_iter=5000)      0.0010      l1   saga     0.0984\n",
       "3   LogisticRegression(max_iter=5000)      0.0010      l2   saga     0.0984\n",
       "4   LogisticRegression(max_iter=5000)      0.0100      l1   saga     0.0984\n",
       "5   LogisticRegression(max_iter=5000)      0.0100      l2   saga     0.0984\n",
       "6   LogisticRegression(max_iter=5000)      0.1000      l1   saga     0.0180\n",
       "7   LogisticRegression(max_iter=5000)      0.1000      l2   saga     0.0958\n",
       "8   LogisticRegression(max_iter=5000)      1.0000      l1   saga     0.0006\n",
       "9   LogisticRegression(max_iter=5000)      1.0000      l2   saga     0.0004\n",
       "10  LogisticRegression(max_iter=5000)     10.0000      l1   saga     0.0000\n",
       "11  LogisticRegression(max_iter=5000)     10.0000      l2   saga     0.0000\n",
       "12  LogisticRegression(max_iter=5000)    100.0000      l1   saga     0.0000\n",
       "13  LogisticRegression(max_iter=5000)    100.0000      l2   saga     0.0000\n",
       "14  LogisticRegression(max_iter=5000)   1000.0000      l1   saga     0.0000\n",
       "15  LogisticRegression(max_iter=5000)   1000.0000      l2   saga     0.0000\n",
       "16  LogisticRegression(max_iter=5000)  10000.0000      l1   saga     0.0000\n",
       "17  LogisticRegression(max_iter=5000)  10000.0000      l2   saga     0.0000\n",
       "18  LogisticRegression(max_iter=5000)      0.0001      l2  lbfgs     0.0984\n",
       "19  LogisticRegression(max_iter=5000)      0.0010      l2  lbfgs     0.0984\n",
       "20  LogisticRegression(max_iter=5000)      0.0100      l2  lbfgs     0.0984\n",
       "21  LogisticRegression(max_iter=5000)      0.1000      l2  lbfgs     0.0958\n",
       "22  LogisticRegression(max_iter=5000)      1.0000      l2  lbfgs     0.0004\n",
       "23  LogisticRegression(max_iter=5000)     10.0000      l2  lbfgs     0.0000\n",
       "24  LogisticRegression(max_iter=5000)    100.0000      l2  lbfgs     0.0000\n",
       "25  LogisticRegression(max_iter=5000)   1000.0000      l2  lbfgs     0.0000\n",
       "26  LogisticRegression(max_iter=5000)  10000.0000      l2  lbfgs     0.0000\n",
       "27  LogisticRegression(max_iter=5000)         NaN    none  lbfgs     0.0000\n",
       "28  LogisticRegression(max_iter=5000)         NaN    none   saga     0.0000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = pd.DataFrame( best_model.cv_results_['params'] )\n",
    "\n",
    "results['score_acc'] = 1 - best_model.cv_results_['mean_test_accuracy']\n",
    "\n",
    "cols = results.columns.to_series().str.split('__').apply(lambda x: x[-1])\n",
    "results.columns = cols\n",
    "\n",
    "# Heat map\n",
    "sns.heatmap( results.query('solver==\"saga\"').pivot('C','penalty','score_acc'),\n",
    "             annot=True, fmt='.3f')\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "controlled-emerald",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets another 5000 random samples\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_c, Y_c, train_size = 5000, random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "registered-envelope",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "pipe = Pipeline([('classifier', LogisticRegression())])\n",
    "\n",
    "search_space = [{'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['saga'],\n",
    "                 'classifier__penalty': ['l1', 'l2'],\n",
    "                 'classifier__C': np.logspace(-4, 4, 9)},\n",
    "                {'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['lbfgs'],\n",
    "                 'classifier__penalty': ['l2'],\n",
    "                 'classifier__C': np.logspace(-4, 4, 9)},\n",
    "                {'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['lbfgs','saga'],\n",
    "                 'classifier__penalty': ['none']}]\n",
    "                \n",
    "clf = GridSearchCV(pipe, search_space, cv=StratifiedKFold(n_splits=5), \n",
    "                   scoring=['accuracy', 'roc_auc_ovr', 'f1_micro'], refit=False,\n",
    "                   verbose=0)\n",
    "                \n",
    "best_model = clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "comparable-crack",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 0.80042415,  0.11212091,  0.04531898,  0.10198822,  0.07958603,\n",
       "         0.13964453,  2.02637191,  0.17073874,  4.49351277,  1.74289808,\n",
       "        12.26901627,  3.47521749, 16.70730047,  7.7133009 , 15.20556655,\n",
       "         8.99008555, 13.48700066,  3.59776387,  3.6565412 ,  4.85322309,\n",
       "         9.27632165, 17.21895804, 29.1579525 , 30.27811656, 36.03672252,\n",
       "        40.84031682, 41.06009965, 14.49555106, 15.14666839]),\n",
       " 'std_fit_time': array([0.89965565, 0.00637474, 0.04631426, 0.06542048, 0.03957204,\n",
       "        0.03843156, 3.49083324, 0.03835293, 2.97056018, 2.67762896,\n",
       "        3.28205855, 3.26370133, 1.92498217, 0.88344179, 4.66852341,\n",
       "        2.66028035, 3.58414568, 3.62398664, 0.3061207 , 0.61324729,\n",
       "        1.02907263, 2.99570785, 3.72638739, 3.2100791 , 6.00892527,\n",
       "        4.77024277, 5.66208239, 3.09355568, 5.19754021]),\n",
       " 'mean_score_time': array([1.28021722, 0.5067255 , 0.51384678, 0.59939389, 0.62180862,\n",
       "        0.4998167 , 0.47230239, 0.5496253 , 0.52621741, 0.6959106 ,\n",
       "        0.55040278, 0.64387279, 0.59281807, 0.6466053 , 0.65534453,\n",
       "        0.55096607, 0.65551939, 0.60186033, 0.58429742, 0.60454664,\n",
       "        0.46222477, 0.5019598 , 0.502987  , 0.56231027, 1.50113106,\n",
       "        0.7199317 , 1.76168351, 0.6030076 , 0.77138472]),\n",
       " 'std_score_time': array([0.85630993, 0.03969555, 0.07385243, 0.08153168, 0.05492111,\n",
       "        0.02903216, 0.06258085, 0.06241634, 0.07625479, 0.27548902,\n",
       "        0.10782493, 0.0769507 , 0.11369602, 0.096826  , 0.22360125,\n",
       "        0.14831986, 0.18657876, 0.05110642, 0.18366806, 0.12719128,\n",
       "        0.07988249, 0.09058658, 0.15485975, 0.16178015, 1.9503923 ,\n",
       "        0.1321554 , 2.36959622, 0.12666576, 0.19086584]),\n",
       " 'param_classifier': masked_array(data=[LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000)],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__C': masked_array(data=[0.0001, 0.0001, 0.001, 0.001, 0.01, 0.01, 0.1, 0.1,\n",
       "                    1.0, 1.0, 10.0, 10.0, 100.0, 100.0, 1000.0, 1000.0,\n",
       "                    10000.0, 10000.0, 0.0001, 0.001, 0.01, 0.1, 1.0, 10.0,\n",
       "                    100.0, 1000.0, 10000.0, --, --],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False,  True,  True],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__penalty': masked_array(data=['l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1',\n",
       "                    'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'none', 'none'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__solver': masked_array(data=['saga', 'saga', 'saga', 'saga', 'saga', 'saga', 'saga',\n",
       "                    'saga', 'saga', 'saga', 'saga', 'saga', 'saga', 'saga',\n",
       "                    'saga', 'saga', 'saga', 'saga', 'lbfgs', 'lbfgs',\n",
       "                    'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs',\n",
       "                    'lbfgs', 'lbfgs', 'saga'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__penalty': 'none',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__penalty': 'none',\n",
       "   'classifier__solver': 'saga'}],\n",
       " 'split0_test_accuracy': array([0.912, 0.912, 0.912, 0.912, 0.912, 0.912, 0.973, 0.914, 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.912, 0.912, 0.912, 0.914, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split1_test_accuracy': array([0.911, 0.911, 0.911, 0.911, 0.911, 0.911, 0.985, 0.911, 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.911, 0.911, 0.911, 0.911, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split2_test_accuracy': array([0.911, 0.911, 0.911, 0.911, 0.911, 0.911, 0.981, 0.911, 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.911, 0.911, 0.911, 0.911, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split3_test_accuracy': array([0.911, 0.911, 0.911, 0.911, 0.911, 0.911, 0.975, 0.912, 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.911, 0.911, 0.911, 0.912, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split4_test_accuracy': array([0.911, 0.911, 0.911, 0.911, 0.911, 0.911, 0.976, 0.911, 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.911, 0.911, 0.911, 0.911, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'mean_test_accuracy': array([0.9112, 0.9112, 0.9112, 0.9112, 0.9112, 0.9112, 0.978 , 0.9118,\n",
       "        1.    , 1.    , 1.    , 1.    , 1.    , 1.    , 1.    , 1.    ,\n",
       "        1.    , 1.    , 0.9112, 0.9112, 0.9112, 0.9118, 1.    , 1.    ,\n",
       "        1.    , 1.    , 1.    , 1.    , 1.    ]),\n",
       " 'std_test_accuracy': array([0.0004    , 0.0004    , 0.0004    , 0.0004    , 0.0004    ,\n",
       "        0.0004    , 0.00438178, 0.00116619, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.0004    , 0.0004    ,\n",
       "        0.0004    , 0.00116619, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ]),\n",
       " 'rank_test_accuracy': array([21, 21, 21, 21, 21, 21, 18, 19,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1, 21, 21, 21, 19,  1,  1,  1,  1,  1,  1,  1], dtype=int32),\n",
       " 'split0_test_roc_auc_ovr': array([0.5       , 0.55558463, 0.5       , 0.6075309 , 0.5       ,\n",
       "        0.90919059, 0.99843625, 0.99963866, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.55558463, 0.6075309 ,\n",
       "        0.90899123, 0.99965112, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'split1_test_roc_auc_ovr': array([0.5       , 0.67896743, 0.5       , 0.77339385, 0.5       ,\n",
       "        0.97721975, 0.99936482, 0.999926  , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.67896743, 0.77333218,\n",
       "        0.97724442, 0.999926  , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'split2_test_roc_auc_ovr': array([0.5       , 0.60671691, 0.5       , 0.67403397, 0.5       ,\n",
       "        0.93944178, 0.99933398, 0.99965466, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.60671691, 0.67403397,\n",
       "        0.93899777, 0.99965466, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'split3_test_roc_auc_ovr': array([0.5       , 0.53040861, 0.5       , 0.57857152, 0.49693509,\n",
       "        0.87744052, 0.99795261, 0.99927231, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.53040861, 0.57857152,\n",
       "        0.87714451, 0.99927231, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'split4_test_roc_auc_ovr': array([0.5       , 0.57896619, 0.5       , 0.6349733 , 0.5       ,\n",
       "        0.91134572, 0.99903181, 0.99965466, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.57896619, 0.63502263,\n",
       "        0.91113605, 0.99965466, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'mean_test_roc_auc_ovr': array([0.5       , 0.59012875, 0.5       , 0.65370071, 0.49938702,\n",
       "        0.92292767, 0.9988239 , 0.99962926, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.59012875, 0.65369824,\n",
       "        0.9227028 , 0.99963175, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'std_test_roc_auc_ovr': array([0.00000000e+00, 5.10918213e-02, 0.00000000e+00, 6.76264033e-02,\n",
       "        1.22596480e-03, 3.35030600e-02, 5.48709443e-04, 2.08250746e-04,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 4.96506831e-17, 0.00000000e+00,\n",
       "        4.96506831e-17, 0.00000000e+00, 5.10918213e-02, 6.76018461e-02,\n",
       "        3.35787676e-02, 2.08422794e-04, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.96506831e-17,\n",
       "        7.02166694e-17]),\n",
       " 'rank_test_roc_auc_ovr': array([27, 25, 27, 23, 29, 21, 20, 19,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1, 25, 24, 22, 18,  1,  1,  1,  1,  1,  1,  1], dtype=int32),\n",
       " 'split0_test_f1_micro': array([0.912, 0.912, 0.912, 0.912, 0.912, 0.912, 0.973, 0.914, 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.912, 0.912, 0.912, 0.914, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split1_test_f1_micro': array([0.911, 0.911, 0.911, 0.911, 0.911, 0.911, 0.985, 0.911, 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.911, 0.911, 0.911, 0.911, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split2_test_f1_micro': array([0.911, 0.911, 0.911, 0.911, 0.911, 0.911, 0.981, 0.911, 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.911, 0.911, 0.911, 0.911, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split3_test_f1_micro': array([0.911, 0.911, 0.911, 0.911, 0.911, 0.911, 0.975, 0.912, 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.911, 0.911, 0.911, 0.912, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split4_test_f1_micro': array([0.911, 0.911, 0.911, 0.911, 0.911, 0.911, 0.976, 0.911, 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.911, 0.911, 0.911, 0.911, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'mean_test_f1_micro': array([0.9112, 0.9112, 0.9112, 0.9112, 0.9112, 0.9112, 0.978 , 0.9118,\n",
       "        1.    , 1.    , 1.    , 1.    , 1.    , 1.    , 1.    , 1.    ,\n",
       "        1.    , 1.    , 0.9112, 0.9112, 0.9112, 0.9118, 1.    , 1.    ,\n",
       "        1.    , 1.    , 1.    , 1.    , 1.    ]),\n",
       " 'std_test_f1_micro': array([0.0004    , 0.0004    , 0.0004    , 0.0004    , 0.0004    ,\n",
       "        0.0004    , 0.00438178, 0.00116619, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.0004    , 0.0004    ,\n",
       "        0.0004    , 0.00116619, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ]),\n",
       " 'rank_test_f1_micro': array([21, 21, 21, 21, 21, 21, 18, 19,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1, 21, 21, 21, 19,  1,  1,  1,  1,  1,  1,  1], dtype=int32)}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "timely-experiment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21, 21, 21, 21, 21, 21, 18, 19,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1, 21, 21, 21, 19,  1,  1,  1,  1,  1,  1,  1], dtype=int32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.cv_results_['rank_test_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "modular-emperor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 1.0,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for accuracy\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_accuracy'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "acting-forth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 1.0,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for roc auc\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_roc_auc_ovr'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "increasing-junction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 1.0,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for f1\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_f1_micro'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "sorted-andorra",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best accuracy model\n",
    "acc_model = LogisticRegression(penalty = 'l1', C = 1.0, solver = 'saga', max_iter = 5000)\n",
    "\n",
    "# best roc auc model\n",
    "roc_model = LogisticRegression(penalty = 'l1', C = 1.0, solver = 'saga', max_iter = 5000)\n",
    "\n",
    "# best f1 model\n",
    "f1_model = LogisticRegression(penalty = 'l1', C = 1.0, solver = 'saga', max_iter = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "vietnamese-tractor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=5000, penalty='l1', solver='saga')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# models the data\n",
    "acc_model.fit(X_train, Y_train)\n",
    "roc_model.fit(X_train, Y_train)\n",
    "f1_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "diverse-knife",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>C</th>\n",
       "      <th>penalty</th>\n",
       "      <th>solver</th>\n",
       "      <th>score_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           classifier           C penalty solver  score_acc\n",
       "0   LogisticRegression(max_iter=5000)      0.0001      l1   saga     0.0888\n",
       "1   LogisticRegression(max_iter=5000)      0.0001      l2   saga     0.0888\n",
       "2   LogisticRegression(max_iter=5000)      0.0010      l1   saga     0.0888\n",
       "3   LogisticRegression(max_iter=5000)      0.0010      l2   saga     0.0888\n",
       "4   LogisticRegression(max_iter=5000)      0.0100      l1   saga     0.0888\n",
       "5   LogisticRegression(max_iter=5000)      0.0100      l2   saga     0.0888\n",
       "6   LogisticRegression(max_iter=5000)      0.1000      l1   saga     0.0220\n",
       "7   LogisticRegression(max_iter=5000)      0.1000      l2   saga     0.0882\n",
       "8   LogisticRegression(max_iter=5000)      1.0000      l1   saga     0.0000\n",
       "9   LogisticRegression(max_iter=5000)      1.0000      l2   saga     0.0000\n",
       "10  LogisticRegression(max_iter=5000)     10.0000      l1   saga     0.0000\n",
       "11  LogisticRegression(max_iter=5000)     10.0000      l2   saga     0.0000\n",
       "12  LogisticRegression(max_iter=5000)    100.0000      l1   saga     0.0000\n",
       "13  LogisticRegression(max_iter=5000)    100.0000      l2   saga     0.0000\n",
       "14  LogisticRegression(max_iter=5000)   1000.0000      l1   saga     0.0000\n",
       "15  LogisticRegression(max_iter=5000)   1000.0000      l2   saga     0.0000\n",
       "16  LogisticRegression(max_iter=5000)  10000.0000      l1   saga     0.0000\n",
       "17  LogisticRegression(max_iter=5000)  10000.0000      l2   saga     0.0000\n",
       "18  LogisticRegression(max_iter=5000)      0.0001      l2  lbfgs     0.0888\n",
       "19  LogisticRegression(max_iter=5000)      0.0010      l2  lbfgs     0.0888\n",
       "20  LogisticRegression(max_iter=5000)      0.0100      l2  lbfgs     0.0888\n",
       "21  LogisticRegression(max_iter=5000)      0.1000      l2  lbfgs     0.0882\n",
       "22  LogisticRegression(max_iter=5000)      1.0000      l2  lbfgs     0.0000\n",
       "23  LogisticRegression(max_iter=5000)     10.0000      l2  lbfgs     0.0000\n",
       "24  LogisticRegression(max_iter=5000)    100.0000      l2  lbfgs     0.0000\n",
       "25  LogisticRegression(max_iter=5000)   1000.0000      l2  lbfgs     0.0000\n",
       "26  LogisticRegression(max_iter=5000)  10000.0000      l2  lbfgs     0.0000\n",
       "27  LogisticRegression(max_iter=5000)         NaN    none  lbfgs     0.0000\n",
       "28  LogisticRegression(max_iter=5000)         NaN    none   saga     0.0000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = pd.DataFrame( best_model.cv_results_['params'] )\n",
    "\n",
    "results['score_acc'] = 1 - best_model.cv_results_['mean_test_accuracy']\n",
    "\n",
    "cols = results.columns.to_series().str.split('__').apply(lambda x: x[-1])\n",
    "results.columns = cols\n",
    "\n",
    "# Heat map\n",
    "sns.heatmap( results.query('solver==\"saga\"').pivot('C','penalty','score_acc'),\n",
    "             annot=True, fmt='.3f')\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "piano-transportation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets another 5000 random samples\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_c, Y_c, train_size = 5000, random_state = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "returning-graham",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "pipe = Pipeline([('classifier', LogisticRegression())])\n",
    "\n",
    "search_space = [{'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['saga'],\n",
    "                 'classifier__penalty': ['l1', 'l2'],\n",
    "                 'classifier__C': np.logspace(-4, 4, 9)},\n",
    "                {'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['lbfgs'],\n",
    "                 'classifier__penalty': ['l2'],\n",
    "                 'classifier__C': np.logspace(-4, 4, 9)},\n",
    "                {'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['lbfgs','saga'],\n",
    "                 'classifier__penalty': ['none']}]\n",
    "                \n",
    "clf = GridSearchCV(pipe, search_space, cv=StratifiedKFold(n_splits=5), \n",
    "                   scoring=['accuracy', 'roc_auc_ovr', 'f1_micro'], refit=False,\n",
    "                   verbose=0)\n",
    "                \n",
    "best_model = clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "informed-relation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([2.64175892e-02, 1.36323738e-01, 1.01972532e-01, 1.21361780e-01,\n",
       "        1.07807827e-01, 1.38226938e-01, 1.28756328e+00, 9.61018467e-01,\n",
       "        4.10175061e+00, 1.72039118e+00, 1.04832869e+01, 3.18701367e+00,\n",
       "        1.40050549e+01, 8.16633511e+00, 1.32994553e+01, 1.16142991e+01,\n",
       "        7.14657483e+00, 1.77673092e+00, 3.57774687e+00, 4.31523819e+00,\n",
       "        1.48781845e+01, 2.99594692e+01, 4.60183530e+01, 4.30373270e+01,\n",
       "        4.45988726e+01, 5.54757504e+01, 4.74802027e+01, 2.09975017e+01,\n",
       "        4.91698267e+01]),\n",
       " 'std_fit_time': array([3.55075734e-02, 3.84208525e-02, 4.15863885e-03, 5.56173060e-02,\n",
       "        2.23549981e-03, 3.18602675e-02, 2.03629081e+00, 1.57016971e+00,\n",
       "        2.97226528e+00, 2.71709672e+00, 4.67939133e+00, 2.98427748e+00,\n",
       "        2.98728934e+00, 3.22873968e+00, 3.79358681e+00, 6.11507461e+00,\n",
       "        6.03762570e+00, 5.07860135e-02, 4.71142062e-01, 3.48332277e-01,\n",
       "        3.26131990e+00, 5.11950637e+00, 3.24710462e+00, 2.44917840e+00,\n",
       "        5.29831314e+00, 4.58005063e+00, 5.95259323e+00, 4.61278709e+00,\n",
       "        6.87924440e+00]),\n",
       " 'mean_score_time': array([0.61460295, 0.68240013, 0.53638525, 0.61724811, 0.57342834,\n",
       "        0.68164845, 0.63391509, 0.57773585, 0.61867862, 0.63859944,\n",
       "        0.57657304, 0.61463952, 0.61295085, 0.55227184, 1.14054508,\n",
       "        0.6461246 , 0.71392617, 0.62270379, 0.46224966, 0.46314044,\n",
       "        2.02092543, 1.67933536, 0.5620553 , 1.16418171, 0.59921765,\n",
       "        1.18179197, 1.19987392, 1.48234096, 0.62972841]),\n",
       " 'std_score_time': array([0.09915226, 0.06813204, 0.07874307, 0.09411623, 0.0729758 ,\n",
       "        0.09268241, 0.14053127, 0.07384158, 0.05553193, 0.1876979 ,\n",
       "        0.11102023, 0.1375421 , 0.06091381, 0.12737992, 0.93515502,\n",
       "        0.08707176, 0.09839613, 0.09811234, 0.07898367, 0.13570642,\n",
       "        1.33500822, 1.25421664, 0.13641316, 0.97411487, 0.14251244,\n",
       "        1.01041729, 1.00529273, 1.37352246, 0.16188045]),\n",
       " 'param_classifier': masked_array(data=[LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000)],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__C': masked_array(data=[0.0001, 0.0001, 0.001, 0.001, 0.01, 0.01, 0.1, 0.1,\n",
       "                    1.0, 1.0, 10.0, 10.0, 100.0, 100.0, 1000.0, 1000.0,\n",
       "                    10000.0, 10000.0, 0.0001, 0.001, 0.01, 0.1, 1.0, 10.0,\n",
       "                    100.0, 1000.0, 10000.0, --, --],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False,  True,  True],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__penalty': masked_array(data=['l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1',\n",
       "                    'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'none', 'none'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__solver': masked_array(data=['saga', 'saga', 'saga', 'saga', 'saga', 'saga', 'saga',\n",
       "                    'saga', 'saga', 'saga', 'saga', 'saga', 'saga', 'saga',\n",
       "                    'saga', 'saga', 'saga', 'saga', 'lbfgs', 'lbfgs',\n",
       "                    'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs',\n",
       "                    'lbfgs', 'lbfgs', 'saga'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__penalty': 'none',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__penalty': 'none',\n",
       "   'classifier__solver': 'saga'}],\n",
       " 'split0_test_accuracy': array([0.904, 0.904, 0.904, 0.904, 0.904, 0.904, 0.987, 0.904, 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.904, 0.904, 0.904, 0.904, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split1_test_accuracy': array([0.904, 0.904, 0.904, 0.904, 0.904, 0.904, 0.978, 0.909, 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.904, 0.904, 0.904, 0.909, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split2_test_accuracy': array([0.904, 0.904, 0.904, 0.904, 0.904, 0.904, 0.991, 0.904, 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.904, 0.904, 0.904, 0.904, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split3_test_accuracy': array([0.904, 0.904, 0.904, 0.904, 0.904, 0.904, 0.987, 0.904, 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.904, 0.904, 0.904, 0.904, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split4_test_accuracy': array([0.904, 0.904, 0.904, 0.904, 0.904, 0.904, 0.986, 0.904, 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.904, 0.904, 0.904, 0.904, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'mean_test_accuracy': array([0.904 , 0.904 , 0.904 , 0.904 , 0.904 , 0.904 , 0.9858, 0.905 ,\n",
       "        1.    , 1.    , 1.    , 1.    , 1.    , 1.    , 1.    , 1.    ,\n",
       "        1.    , 1.    , 0.904 , 0.904 , 0.904 , 0.905 , 1.    , 1.    ,\n",
       "        1.    , 1.    , 1.    , 1.    , 1.    ]),\n",
       " 'std_test_accuracy': array([1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 4.26145515e-03, 2.00000000e-03,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 2.00000000e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00]),\n",
       " 'rank_test_accuracy': array([21, 21, 21, 21, 21, 21, 18, 19,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1, 21, 21, 21, 19,  1,  1,  1,  1,  1,  1,  1], dtype=int32),\n",
       " 'split0_test_roc_auc_ovr': array([0.5       , 0.59350802, 0.5       , 0.69023092, 0.5       ,\n",
       "        0.96652609, 0.99985596, 0.99994239, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.59350802, 0.69023092,\n",
       "        0.96646847, 0.99994239, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'split1_test_roc_auc_ovr': array([0.5       , 0.50467828, 0.5       , 0.57382697, 0.5       ,\n",
       "        0.91369377, 0.99970617, 0.99979259, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.50467828, 0.57382697,\n",
       "        0.91344027, 0.99979259, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'split2_test_roc_auc_ovr': array([0.5       , 0.66680494, 0.5       , 0.79074484, 0.5       ,\n",
       "        0.98319967, 0.99987325, 0.99993086, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.66702388, 0.79072179,\n",
       "        0.98308444, 0.99993086, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'split3_test_roc_auc_ovr': array([0.5       , 0.75995575, 0.5       , 0.86547059, 0.5       ,\n",
       "        0.97769174, 0.99953909, 0.99967736, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.76001337, 0.86533232,\n",
       "        0.97776088, 0.99967736, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'split4_test_roc_auc_ovr': array([0.5       , 0.61787887, 0.5       , 0.70962389, 0.5       ,\n",
       "        0.95841399, 0.99996543, 0.99994239, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.61787887, 0.70955476,\n",
       "        0.95832181, 0.99994239, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'mean_test_roc_auc_ovr': array([0.5       , 0.62856517, 0.5       , 0.72597944, 0.5       ,\n",
       "        0.95990505, 0.99978798, 0.99985712, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.62862048, 0.72593335,\n",
       "        0.95981517, 0.99985712, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'std_test_roc_auc_ovr': array([0.00000000e+00, 8.41628505e-02, 0.00000000e+00, 9.83342999e-02,\n",
       "        0.00000000e+00, 2.46598845e-02, 1.49681925e-04, 1.06260526e-04,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 4.96506831e-17, 0.00000000e+00, 0.00000000e+00,\n",
       "        4.96506831e-17, 0.00000000e+00, 8.42007683e-02, 9.82943405e-02,\n",
       "        2.47412031e-02, 1.06260526e-04, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.96506831e-17,\n",
       "        4.96506831e-17]),\n",
       " 'rank_test_roc_auc_ovr': array([27, 26, 27, 23, 27, 21, 20, 18,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1, 25, 24, 22, 18,  1,  1,  1,  1,  1,  1,  1], dtype=int32),\n",
       " 'split0_test_f1_micro': array([0.904, 0.904, 0.904, 0.904, 0.904, 0.904, 0.987, 0.904, 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.904, 0.904, 0.904, 0.904, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split1_test_f1_micro': array([0.904, 0.904, 0.904, 0.904, 0.904, 0.904, 0.978, 0.909, 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.904, 0.904, 0.904, 0.909, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split2_test_f1_micro': array([0.904, 0.904, 0.904, 0.904, 0.904, 0.904, 0.991, 0.904, 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.904, 0.904, 0.904, 0.904, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split3_test_f1_micro': array([0.904, 0.904, 0.904, 0.904, 0.904, 0.904, 0.987, 0.904, 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.904, 0.904, 0.904, 0.904, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split4_test_f1_micro': array([0.904, 0.904, 0.904, 0.904, 0.904, 0.904, 0.986, 0.904, 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.904, 0.904, 0.904, 0.904, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'mean_test_f1_micro': array([0.904 , 0.904 , 0.904 , 0.904 , 0.904 , 0.904 , 0.9858, 0.905 ,\n",
       "        1.    , 1.    , 1.    , 1.    , 1.    , 1.    , 1.    , 1.    ,\n",
       "        1.    , 1.    , 0.904 , 0.904 , 0.904 , 0.905 , 1.    , 1.    ,\n",
       "        1.    , 1.    , 1.    , 1.    , 1.    ]),\n",
       " 'std_test_f1_micro': array([1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 4.26145515e-03, 2.00000000e-03,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 2.00000000e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00]),\n",
       " 'rank_test_f1_micro': array([21, 21, 21, 21, 21, 21, 18, 19,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1, 21, 21, 21, 19,  1,  1,  1,  1,  1,  1,  1], dtype=int32)}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "particular-abortion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21, 21, 21, 21, 21, 21, 18, 19,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1, 21, 21, 21, 19,  1,  1,  1,  1,  1,  1,  1], dtype=int32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.cv_results_['rank_test_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "mechanical-kingdom",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 1.0,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for accuracy\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_accuracy'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "polyphonic-symposium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 1.0,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for roc auc\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_roc_auc_ovr'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "thick-hammer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 1.0,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for f1\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_f1_micro'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "czech-biodiversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best accuracy model\n",
    "acc_model = LogisticRegression(penalty = 'l1', C = 1.0, solver = 'saga', max_iter = 5000)\n",
    "\n",
    "# best roc auc model\n",
    "roc_model = LogisticRegression(penalty = 'l1', C = 1.0, solver = 'saga', max_iter = 5000)\n",
    "\n",
    "# best f1 model\n",
    "f1_model = LogisticRegression(penalty = 'l1', C = 1.0, solver = 'saga', max_iter = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "manufactured-principal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=5000, penalty='l1', solver='saga')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# models the data\n",
    "acc_model.fit(X_train, Y_train)\n",
    "roc_model.fit(X_train, Y_train)\n",
    "f1_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "compatible-nation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>C</th>\n",
       "      <th>penalty</th>\n",
       "      <th>solver</th>\n",
       "      <th>score_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           classifier           C penalty solver  score_acc\n",
       "0   LogisticRegression(max_iter=5000)      0.0001      l1   saga     0.0960\n",
       "1   LogisticRegression(max_iter=5000)      0.0001      l2   saga     0.0960\n",
       "2   LogisticRegression(max_iter=5000)      0.0010      l1   saga     0.0960\n",
       "3   LogisticRegression(max_iter=5000)      0.0010      l2   saga     0.0960\n",
       "4   LogisticRegression(max_iter=5000)      0.0100      l1   saga     0.0960\n",
       "5   LogisticRegression(max_iter=5000)      0.0100      l2   saga     0.0960\n",
       "6   LogisticRegression(max_iter=5000)      0.1000      l1   saga     0.0142\n",
       "7   LogisticRegression(max_iter=5000)      0.1000      l2   saga     0.0950\n",
       "8   LogisticRegression(max_iter=5000)      1.0000      l1   saga     0.0000\n",
       "9   LogisticRegression(max_iter=5000)      1.0000      l2   saga     0.0000\n",
       "10  LogisticRegression(max_iter=5000)     10.0000      l1   saga     0.0000\n",
       "11  LogisticRegression(max_iter=5000)     10.0000      l2   saga     0.0000\n",
       "12  LogisticRegression(max_iter=5000)    100.0000      l1   saga     0.0000\n",
       "13  LogisticRegression(max_iter=5000)    100.0000      l2   saga     0.0000\n",
       "14  LogisticRegression(max_iter=5000)   1000.0000      l1   saga     0.0000\n",
       "15  LogisticRegression(max_iter=5000)   1000.0000      l2   saga     0.0000\n",
       "16  LogisticRegression(max_iter=5000)  10000.0000      l1   saga     0.0000\n",
       "17  LogisticRegression(max_iter=5000)  10000.0000      l2   saga     0.0000\n",
       "18  LogisticRegression(max_iter=5000)      0.0001      l2  lbfgs     0.0960\n",
       "19  LogisticRegression(max_iter=5000)      0.0010      l2  lbfgs     0.0960\n",
       "20  LogisticRegression(max_iter=5000)      0.0100      l2  lbfgs     0.0960\n",
       "21  LogisticRegression(max_iter=5000)      0.1000      l2  lbfgs     0.0950\n",
       "22  LogisticRegression(max_iter=5000)      1.0000      l2  lbfgs     0.0000\n",
       "23  LogisticRegression(max_iter=5000)     10.0000      l2  lbfgs     0.0000\n",
       "24  LogisticRegression(max_iter=5000)    100.0000      l2  lbfgs     0.0000\n",
       "25  LogisticRegression(max_iter=5000)   1000.0000      l2  lbfgs     0.0000\n",
       "26  LogisticRegression(max_iter=5000)  10000.0000      l2  lbfgs     0.0000\n",
       "27  LogisticRegression(max_iter=5000)         NaN    none  lbfgs     0.0000\n",
       "28  LogisticRegression(max_iter=5000)         NaN    none   saga     0.0000"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = pd.DataFrame( best_model.cv_results_['params'] )\n",
    "\n",
    "results['score_acc'] = 1 - best_model.cv_results_['mean_test_accuracy']\n",
    "\n",
    "cols = results.columns.to_series().str.split('__').apply(lambda x: x[-1])\n",
    "results.columns = cols\n",
    "\n",
    "# Heat map\n",
    "sns.heatmap( results.query('solver==\"saga\"').pivot('C','penalty','score_acc'),\n",
    "             annot=True, fmt='.3f')\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "announced-scoop",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets another 5000 random samples\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_c, Y_c, train_size = 5000, random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "corporate-jacket",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "pipe = Pipeline([('classifier', LogisticRegression())])\n",
    "\n",
    "search_space = [{'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['saga'],\n",
    "                 'classifier__penalty': ['l1', 'l2'],\n",
    "                 'classifier__C': np.logspace(-4, 4, 9)},\n",
    "                {'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['lbfgs'],\n",
    "                 'classifier__penalty': ['l2'],\n",
    "                 'classifier__C': np.logspace(-4, 4, 9)},\n",
    "                {'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['lbfgs','saga'],\n",
    "                 'classifier__penalty': ['none']}]\n",
    "                \n",
    "clf = GridSearchCV(pipe, search_space, cv=StratifiedKFold(n_splits=5), \n",
    "                   scoring=['accuracy', 'roc_auc_ovr', 'f1_micro'], refit=False,\n",
    "                   verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "minute-adult",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "light-english",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([2.98724079e-01, 1.17199612e-01, 2.59222507e-02, 1.04938793e-01,\n",
       "        7.15816498e-02, 1.22502232e-01, 4.38808641e+00, 1.81634521e-01,\n",
       "        2.83593240e+00, 3.72183180e-01, 1.84304080e+00, 6.95680618e-01,\n",
       "        2.07776217e+00, 1.39328465e+00, 2.24462891e+00, 2.53270350e+00,\n",
       "        9.39907298e+00, 1.43103057e+01, 4.85460725e+00, 4.41808095e+00,\n",
       "        9.25717044e+00, 1.95153400e+01, 2.79591665e+01, 2.77384836e+01,\n",
       "        3.19960293e+01, 3.42925065e+01, 3.26389670e+01, 1.19768934e+01,\n",
       "        1.84302649e+00]),\n",
       " 'std_fit_time': array([3.55015844e-01, 7.24629179e-03, 3.54761151e-02, 3.77887244e-02,\n",
       "        4.42922862e-02, 6.98501545e-03, 8.23860806e+00, 4.24177706e-02,\n",
       "        2.48036018e+00, 4.50620388e-02, 8.98087418e-02, 6.52144949e-02,\n",
       "        9.07458140e-02, 3.38998223e-02, 2.21953687e-01, 1.38740129e+00,\n",
       "        6.98898503e+00, 6.30227010e+00, 2.00440395e+00, 3.64057244e-01,\n",
       "        1.41570691e+00, 1.32076164e+00, 4.92173318e+00, 4.13085136e+00,\n",
       "        8.01177554e+00, 3.93515519e+00, 1.91862217e+00, 8.14394488e-01,\n",
       "        2.64997532e-02]),\n",
       " 'mean_score_time': array([0.72109914, 0.52198925, 0.5754323 , 0.65566239, 0.72933321,\n",
       "        0.63587222, 0.59186411, 0.67608209, 0.66373649, 0.62775974,\n",
       "        0.65627823, 0.58311238, 0.58252563, 0.5474967 , 0.59581079,\n",
       "        0.62572365, 0.63944149, 0.68819418, 0.54333911, 0.68196707,\n",
       "        0.52287045, 0.52250834, 0.60363264, 0.54241595, 0.54338374,\n",
       "        0.5242053 , 0.52115984, 0.60274   , 0.7347137 ]),\n",
       " 'std_score_time': array([0.29086529, 0.04294422, 0.07580611, 0.0736479 , 0.10256648,\n",
       "        0.12907296, 0.06676153, 0.14945036, 0.1369545 , 0.08986049,\n",
       "        0.12781236, 0.03921426, 0.10617728, 0.05691706, 0.13604036,\n",
       "        0.11458966, 0.08298206, 0.05100423, 0.14937054, 0.17006966,\n",
       "        0.11595239, 0.07298456, 0.12767704, 0.07941689, 0.13560451,\n",
       "        0.11757324, 0.11713307, 0.10835319, 0.06530398]),\n",
       " 'param_classifier': masked_array(data=[LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000)],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__C': masked_array(data=[0.0001, 0.0001, 0.001, 0.001, 0.01, 0.01, 0.1, 0.1,\n",
       "                    1.0, 1.0, 10.0, 10.0, 100.0, 100.0, 1000.0, 1000.0,\n",
       "                    10000.0, 10000.0, 0.0001, 0.001, 0.01, 0.1, 1.0, 10.0,\n",
       "                    100.0, 1000.0, 10000.0, --, --],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False,  True,  True],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__penalty': masked_array(data=['l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1',\n",
       "                    'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'none', 'none'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__solver': masked_array(data=['saga', 'saga', 'saga', 'saga', 'saga', 'saga', 'saga',\n",
       "                    'saga', 'saga', 'saga', 'saga', 'saga', 'saga', 'saga',\n",
       "                    'saga', 'saga', 'saga', 'saga', 'lbfgs', 'lbfgs',\n",
       "                    'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs',\n",
       "                    'lbfgs', 'lbfgs', 'saga'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__penalty': 'none',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__penalty': 'none',\n",
       "   'classifier__solver': 'saga'}],\n",
       " 'split0_test_accuracy': array([0.905, 0.905, 0.905, 0.905, 0.905, 0.905, 0.971, 0.908, 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.905, 0.905, 0.905, 0.908, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.998, 1.   ]),\n",
       " 'split1_test_accuracy': array([0.904, 0.904, 0.904, 0.904, 0.904, 0.904, 0.981, 0.906, 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.904, 0.904, 0.904, 0.906, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split2_test_accuracy': array([0.904, 0.904, 0.904, 0.904, 0.904, 0.904, 0.98 , 0.904, 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.904, 0.904, 0.904, 0.904, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split3_test_accuracy': array([0.904, 0.904, 0.904, 0.904, 0.904, 0.904, 0.976, 0.907, 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.904, 0.904, 0.904, 0.907, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split4_test_accuracy': array([0.904, 0.904, 0.904, 0.904, 0.904, 0.904, 0.993, 0.904, 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.904, 0.904, 0.904, 0.904, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'mean_test_accuracy': array([0.9042, 0.9042, 0.9042, 0.9042, 0.9042, 0.9042, 0.9802, 0.9058,\n",
       "        1.    , 1.    , 1.    , 1.    , 1.    , 1.    , 1.    , 1.    ,\n",
       "        1.    , 1.    , 0.9042, 0.9042, 0.9042, 0.9058, 1.    , 1.    ,\n",
       "        1.    , 1.    , 1.    , 0.9996, 1.    ]),\n",
       " 'std_test_accuracy': array([0.0004    , 0.0004    , 0.0004    , 0.0004    , 0.0004    ,\n",
       "        0.0004    , 0.00730479, 0.0016    , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.0004    , 0.0004    ,\n",
       "        0.0004    , 0.0016    , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.0008    , 0.        ]),\n",
       " 'rank_test_accuracy': array([21, 21, 21, 21, 21, 21, 18, 19,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1, 21, 21, 21, 19,  1,  1,  1,  1,  1, 17,  1], dtype=int32),\n",
       " 'split0_test_roc_auc_ovr': array([0.5       , 0.47055539, 0.5       , 0.52173306, 0.5       ,\n",
       "        0.8623786 , 0.99916836, 0.9992556 , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.47055539, 0.52180285,\n",
       "        0.86225065, 0.9992556 , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'split1_test_roc_auc_ovr': array([0.5       , 0.55732624, 0.5       , 0.62653254, 0.5       ,\n",
       "        0.941026  , 0.99951604, 0.99995391, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.55732624, 0.62653254,\n",
       "        0.941026  , 0.99995391, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'split2_test_roc_auc_ovr': array([0.5       , 0.61969948, 0.5       , 0.70531434, 0.5       ,\n",
       "        0.95359744, 0.99946419, 0.99989629, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.61964187, 0.70531434,\n",
       "        0.95357439, 0.99989629, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'split3_test_roc_auc_ovr': array([0.5       , 0.53302452, 0.5       , 0.59122649, 0.5       ,\n",
       "        0.91460407, 0.99927406, 0.99995391, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.53302452, 0.59122649,\n",
       "        0.91460407, 0.99995391, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'split4_test_roc_auc_ovr': array([0.5       , 0.62269543, 0.5       , 0.86769451, 0.5       ,\n",
       "        0.99918188, 0.99963127, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.62269543, 0.86836283,\n",
       "        0.9991934 , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'mean_test_roc_auc_ovr': array([0.5       , 0.56066021, 0.5       , 0.66250019, 0.5       ,\n",
       "        0.9341576 , 0.99941078, 0.99981194, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.56064869, 0.66264781,\n",
       "        0.9341297 , 0.99981194, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'std_test_roc_auc_ovr': array([0.00000000e+00, 5.69696914e-02, 0.00000000e+00, 1.18428675e-01,\n",
       "        0.00000000e+00, 4.51393490e-02, 1.67335332e-04, 2.80110427e-04,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 7.02166694e-17, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 5.69577533e-02, 1.18643772e-01,\n",
       "        4.51813838e-02, 2.80110427e-04, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 4.96506831e-17, 4.96506831e-17, 4.96506831e-17,\n",
       "        0.00000000e+00]),\n",
       " 'rank_test_roc_auc_ovr': array([27, 25, 27, 24, 27, 21, 20, 18,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1, 26, 23, 22, 18,  1,  1,  1,  1,  1,  1,  1], dtype=int32),\n",
       " 'split0_test_f1_micro': array([0.905, 0.905, 0.905, 0.905, 0.905, 0.905, 0.971, 0.908, 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.905, 0.905, 0.905, 0.908, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.998, 1.   ]),\n",
       " 'split1_test_f1_micro': array([0.904, 0.904, 0.904, 0.904, 0.904, 0.904, 0.981, 0.906, 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.904, 0.904, 0.904, 0.906, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split2_test_f1_micro': array([0.904, 0.904, 0.904, 0.904, 0.904, 0.904, 0.98 , 0.904, 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.904, 0.904, 0.904, 0.904, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split3_test_f1_micro': array([0.904, 0.904, 0.904, 0.904, 0.904, 0.904, 0.976, 0.907, 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.904, 0.904, 0.904, 0.907, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split4_test_f1_micro': array([0.904, 0.904, 0.904, 0.904, 0.904, 0.904, 0.993, 0.904, 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.904, 0.904, 0.904, 0.904, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'mean_test_f1_micro': array([0.9042, 0.9042, 0.9042, 0.9042, 0.9042, 0.9042, 0.9802, 0.9058,\n",
       "        1.    , 1.    , 1.    , 1.    , 1.    , 1.    , 1.    , 1.    ,\n",
       "        1.    , 1.    , 0.9042, 0.9042, 0.9042, 0.9058, 1.    , 1.    ,\n",
       "        1.    , 1.    , 1.    , 0.9996, 1.    ]),\n",
       " 'std_test_f1_micro': array([0.0004    , 0.0004    , 0.0004    , 0.0004    , 0.0004    ,\n",
       "        0.0004    , 0.00730479, 0.0016    , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.0004    , 0.0004    ,\n",
       "        0.0004    , 0.0016    , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.0008    , 0.        ]),\n",
       " 'rank_test_f1_micro': array([21, 21, 21, 21, 21, 21, 18, 19,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1, 21, 21, 21, 19,  1,  1,  1,  1,  1, 17,  1], dtype=int32)}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "initial-participant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21, 21, 21, 21, 21, 21, 18, 19,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1, 21, 21, 21, 19,  1,  1,  1,  1,  1, 17,  1], dtype=int32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.cv_results_['rank_test_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "afraid-convenience",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 1.0,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for accuracy\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_accuracy'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "isolated-majority",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 1.0,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for roc auc\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_roc_auc_ovr'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "decimal-voice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 1.0,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for f1\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_f1_micro'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "headed-license",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best accuracy model\n",
    "acc_model = LogisticRegression(penalty = 'l1', C = 1.0, solver = 'saga', max_iter = 5000)\n",
    "\n",
    "# best roc auc model\n",
    "roc_model = LogisticRegression(penalty = 'l1', C = 1.0, solver = 'saga', max_iter = 5000)\n",
    "\n",
    "# best f1 model\n",
    "f1_model = LogisticRegression(penalty = 'l1', C = 1.0, solver = 'saga', max_iter = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "accepted-slovak",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=5000, penalty='l1', solver='saga')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# models the data\n",
    "acc_model.fit(X_train, Y_train)\n",
    "roc_model.fit(X_train, Y_train)\n",
    "f1_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "differential-journalist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>C</th>\n",
       "      <th>penalty</th>\n",
       "      <th>solver</th>\n",
       "      <th>score_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           classifier           C penalty solver  score_acc\n",
       "0   LogisticRegression(max_iter=5000)      0.0001      l1   saga     0.0958\n",
       "1   LogisticRegression(max_iter=5000)      0.0001      l2   saga     0.0958\n",
       "2   LogisticRegression(max_iter=5000)      0.0010      l1   saga     0.0958\n",
       "3   LogisticRegression(max_iter=5000)      0.0010      l2   saga     0.0958\n",
       "4   LogisticRegression(max_iter=5000)      0.0100      l1   saga     0.0958\n",
       "5   LogisticRegression(max_iter=5000)      0.0100      l2   saga     0.0958\n",
       "6   LogisticRegression(max_iter=5000)      0.1000      l1   saga     0.0198\n",
       "7   LogisticRegression(max_iter=5000)      0.1000      l2   saga     0.0942\n",
       "8   LogisticRegression(max_iter=5000)      1.0000      l1   saga     0.0000\n",
       "9   LogisticRegression(max_iter=5000)      1.0000      l2   saga     0.0000\n",
       "10  LogisticRegression(max_iter=5000)     10.0000      l1   saga     0.0000\n",
       "11  LogisticRegression(max_iter=5000)     10.0000      l2   saga     0.0000\n",
       "12  LogisticRegression(max_iter=5000)    100.0000      l1   saga     0.0000\n",
       "13  LogisticRegression(max_iter=5000)    100.0000      l2   saga     0.0000\n",
       "14  LogisticRegression(max_iter=5000)   1000.0000      l1   saga     0.0000\n",
       "15  LogisticRegression(max_iter=5000)   1000.0000      l2   saga     0.0000\n",
       "16  LogisticRegression(max_iter=5000)  10000.0000      l1   saga     0.0000\n",
       "17  LogisticRegression(max_iter=5000)  10000.0000      l2   saga     0.0000\n",
       "18  LogisticRegression(max_iter=5000)      0.0001      l2  lbfgs     0.0958\n",
       "19  LogisticRegression(max_iter=5000)      0.0010      l2  lbfgs     0.0958\n",
       "20  LogisticRegression(max_iter=5000)      0.0100      l2  lbfgs     0.0958\n",
       "21  LogisticRegression(max_iter=5000)      0.1000      l2  lbfgs     0.0942\n",
       "22  LogisticRegression(max_iter=5000)      1.0000      l2  lbfgs     0.0000\n",
       "23  LogisticRegression(max_iter=5000)     10.0000      l2  lbfgs     0.0000\n",
       "24  LogisticRegression(max_iter=5000)    100.0000      l2  lbfgs     0.0000\n",
       "25  LogisticRegression(max_iter=5000)   1000.0000      l2  lbfgs     0.0000\n",
       "26  LogisticRegression(max_iter=5000)  10000.0000      l2  lbfgs     0.0000\n",
       "27  LogisticRegression(max_iter=5000)         NaN    none  lbfgs     0.0004\n",
       "28  LogisticRegression(max_iter=5000)         NaN    none   saga     0.0000"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = pd.DataFrame( best_model.cv_results_['params'] )\n",
    "\n",
    "results['score_acc'] = 1 - best_model.cv_results_['mean_test_accuracy']\n",
    "\n",
    "cols = results.columns.to_series().str.split('__').apply(lambda x: x[-1])\n",
    "results.columns = cols\n",
    "\n",
    "# Heat map\n",
    "sns.heatmap( results.query('solver==\"saga\"').pivot('C','penalty','score_acc'),\n",
    "             annot=True, fmt='.3f')\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "later-seafood",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets another 5000 random samples\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_c, Y_c, train_size = 5000, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "tribal-stability",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "pipe = Pipeline([('classifier', LogisticRegression())])\n",
    "\n",
    "search_space = [{'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['saga'],\n",
    "                 'classifier__penalty': ['l1', 'l2'],\n",
    "                 'classifier__C': np.logspace(-4, 4, 9)},\n",
    "                {'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['lbfgs'],\n",
    "                 'classifier__penalty': ['l2'],\n",
    "                 'classifier__C': np.logspace(-4, 4, 9)},\n",
    "                {'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['lbfgs','saga'],\n",
    "                 'classifier__penalty': ['none']}]\n",
    "                \n",
    "clf = GridSearchCV(pipe, search_space, cv=StratifiedKFold(n_splits=5), \n",
    "                   scoring=['accuracy', 'roc_auc_ovr', 'f1_micro'], refit=False,\n",
    "                   verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "silver-tongue",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "entertaining-waters",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 0.06358843,  0.13208117,  0.0469718 ,  0.11630583,  0.10741534,\n",
       "         0.13033977,  0.3198153 ,  0.23095579,  1.21135917,  0.37684665,\n",
       "         2.35480804,  1.04758859,  2.60616703,  1.46021519,  2.18445492,\n",
       "         1.73411989,  2.21238532,  1.76545348,  3.99604645,  4.59531302,\n",
       "         9.31666317, 16.85812306, 30.25956426, 25.65653133, 29.1978878 ,\n",
       "        36.81690893, 37.81651921, 13.43811092,  1.90062747]),\n",
       " 'std_fit_time': array([0.04417081, 0.03242355, 0.04477615, 0.07548336, 0.00677959,\n",
       "        0.01866057, 0.03539519, 0.0127245 , 0.14381522, 0.04190533,\n",
       "        0.06836611, 0.10082914, 0.47430039, 0.03905466, 0.09385948,\n",
       "        0.06907562, 0.05415656, 0.01149096, 0.37611377, 0.37033755,\n",
       "        0.82575733, 2.47446024, 2.02578991, 2.51151975, 3.10566311,\n",
       "        2.43073175, 2.99948932, 1.13850093, 0.11168148]),\n",
       " 'mean_score_time': array([0.7314774 , 0.74708323, 0.67386236, 0.66311398, 0.71254234,\n",
       "        0.63048906, 0.70108018, 0.58786654, 0.68670287, 0.66059136,\n",
       "        0.72562442, 0.69199858, 0.71423168, 0.55831671, 0.65339713,\n",
       "        0.60663414, 0.6086463 , 0.69239635, 0.52306223, 0.56382647,\n",
       "        0.56291256, 0.58086371, 0.61854057, 0.66176162, 0.54031382,\n",
       "        0.58148465, 0.68396983, 0.66233659, 0.63915939]),\n",
       " 'std_score_time': array([0.05093468, 0.08953008, 0.07657371, 0.03026265, 0.1147611 ,\n",
       "        0.10148726, 0.12182093, 0.07684832, 0.15397868, 0.13224911,\n",
       "        0.07431822, 0.13175591, 0.02661311, 0.04550182, 0.12881061,\n",
       "        0.17175987, 0.07139341, 0.09905076, 0.15894467, 0.13781907,\n",
       "        0.16127933, 0.07484409, 0.17016547, 0.10326097, 0.17238394,\n",
       "        0.07559758, 0.04043275, 0.13652991, 0.10348357]),\n",
       " 'param_classifier': masked_array(data=[LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000),\n",
       "                    LogisticRegression(max_iter=5000)],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__C': masked_array(data=[0.0001, 0.0001, 0.001, 0.001, 0.01, 0.01, 0.1, 0.1,\n",
       "                    1.0, 1.0, 10.0, 10.0, 100.0, 100.0, 1000.0, 1000.0,\n",
       "                    10000.0, 10000.0, 0.0001, 0.001, 0.01, 0.1, 1.0, 10.0,\n",
       "                    100.0, 1000.0, 10000.0, --, --],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False,  True,  True],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__penalty': masked_array(data=['l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1',\n",
       "                    'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'none', 'none'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__solver': masked_array(data=['saga', 'saga', 'saga', 'saga', 'saga', 'saga', 'saga',\n",
       "                    'saga', 'saga', 'saga', 'saga', 'saga', 'saga', 'saga',\n",
       "                    'saga', 'saga', 'saga', 'saga', 'lbfgs', 'lbfgs',\n",
       "                    'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs',\n",
       "                    'lbfgs', 'lbfgs', 'saga'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.0001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.001,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.01,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 100.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 1000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__C': 10000.0,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__penalty': 'none',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier': LogisticRegression(max_iter=5000),\n",
       "   'classifier__penalty': 'none',\n",
       "   'classifier__solver': 'saga'}],\n",
       " 'split0_test_accuracy': array([0.902, 0.902, 0.902, 0.902, 0.902, 0.902, 0.99 , 0.902, 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.902, 0.902, 0.902, 0.902, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split1_test_accuracy': array([0.902, 0.902, 0.902, 0.902, 0.902, 0.902, 0.988, 0.902, 0.999,\n",
       "        0.999, 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.902, 0.902, 0.902, 0.902, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split2_test_accuracy': array([0.902, 0.902, 0.902, 0.902, 0.902, 0.902, 0.987, 0.902, 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.902, 0.902, 0.902, 0.902, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.999, 1.   ]),\n",
       " 'split3_test_accuracy': array([0.902, 0.902, 0.902, 0.902, 0.902, 0.902, 0.981, 0.902, 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.902, 0.902, 0.902, 0.902, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split4_test_accuracy': array([0.901, 0.901, 0.901, 0.901, 0.901, 0.901, 0.984, 0.901, 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.901, 0.901, 0.901, 0.901, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'mean_test_accuracy': array([0.9018, 0.9018, 0.9018, 0.9018, 0.9018, 0.9018, 0.986 , 0.9018,\n",
       "        0.9998, 0.9998, 1.    , 1.    , 1.    , 1.    , 1.    , 1.    ,\n",
       "        1.    , 1.    , 0.9018, 0.9018, 0.9018, 0.9018, 1.    , 1.    ,\n",
       "        1.    , 1.    , 1.    , 0.9998, 1.    ]),\n",
       " 'std_test_accuracy': array([0.0004    , 0.0004    , 0.0004    , 0.0004    , 0.0004    ,\n",
       "        0.0004    , 0.00316228, 0.0004    , 0.0004    , 0.0004    ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.0004    , 0.0004    ,\n",
       "        0.0004    , 0.0004    , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.0004    , 0.        ]),\n",
       " 'rank_test_accuracy': array([19, 19, 19, 19, 19, 19, 18, 19, 15, 15,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1, 19, 19, 19, 19,  1,  1,  1,  1,  1, 15,  1], dtype=int32),\n",
       " 'split0_test_roc_auc_ovr': array([0.5       , 0.64692973, 0.5       , 0.79904068, 0.5       ,\n",
       "        0.97614145, 0.99945699, 0.99979637, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.64692973, 0.79910856,\n",
       "        0.97616408, 0.99979637, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'split1_test_roc_auc_ovr': array([0.5       , 0.94034798, 0.5       , 0.99030499, 0.5       ,\n",
       "        0.99652699, 0.9998699 , 0.99996606, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.94042717, 0.99030499,\n",
       "        0.9965383 , 0.99996606, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'split2_test_roc_auc_ovr': array([0.5       , 0.62526585, 0.5       , 0.75823567, 0.5       ,\n",
       "        0.98312141, 0.99953618, 0.99998869, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.62526585, 0.75822435,\n",
       "        0.98309878, 0.99998869, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'split3_test_roc_auc_ovr': array([0.5       , 0.60323997, 0.5       , 0.73682067, 0.5       ,\n",
       "        0.97794018, 0.99940043, 0.9999095 , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.60323997, 0.73682067,\n",
       "        0.97792887, 0.9999095 , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'split4_test_roc_auc_ovr': array([0.5       , 0.68274308, 0.5       , 0.83234117, 0.5       ,\n",
       "        0.98819493, 0.99973094, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.68274308, 0.8323748 ,\n",
       "        0.98818372, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'mean_test_roc_auc_ovr': array([0.5       , 0.69970532, 0.5       , 0.82334864, 0.5       ,\n",
       "        0.98438499, 0.99959889, 0.99993212, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.69972116, 0.82336668,\n",
       "        0.98438275, 0.99993212, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'std_test_roc_auc_ovr': array([0.00000000e+00, 1.23149235e-01, 0.00000000e+00, 8.97473726e-02,\n",
       "        0.00000000e+00, 7.38961452e-03, 1.75694123e-04, 7.46982851e-05,\n",
       "        4.96506831e-17, 0.00000000e+00, 0.00000000e+00, 4.96506831e-17,\n",
       "        0.00000000e+00, 4.96506831e-17, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.23180183e-01, 8.97460160e-02,\n",
       "        7.38989383e-03, 7.46982851e-05, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00]),\n",
       " 'rank_test_roc_auc_ovr': array([27, 26, 27, 24, 27, 21, 20, 19,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1, 25, 23, 22, 18,  1,  1,  1,  1,  1,  1,  1], dtype=int32),\n",
       " 'split0_test_f1_micro': array([0.902, 0.902, 0.902, 0.902, 0.902, 0.902, 0.99 , 0.902, 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.902, 0.902, 0.902, 0.902, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split1_test_f1_micro': array([0.902, 0.902, 0.902, 0.902, 0.902, 0.902, 0.988, 0.902, 0.999,\n",
       "        0.999, 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.902, 0.902, 0.902, 0.902, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split2_test_f1_micro': array([0.902, 0.902, 0.902, 0.902, 0.902, 0.902, 0.987, 0.902, 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.902, 0.902, 0.902, 0.902, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.999, 1.   ]),\n",
       " 'split3_test_f1_micro': array([0.902, 0.902, 0.902, 0.902, 0.902, 0.902, 0.981, 0.902, 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.902, 0.902, 0.902, 0.902, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'split4_test_f1_micro': array([0.901, 0.901, 0.901, 0.901, 0.901, 0.901, 0.984, 0.901, 1.   ,\n",
       "        1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        0.901, 0.901, 0.901, 0.901, 1.   , 1.   , 1.   , 1.   , 1.   ,\n",
       "        1.   , 1.   ]),\n",
       " 'mean_test_f1_micro': array([0.9018, 0.9018, 0.9018, 0.9018, 0.9018, 0.9018, 0.986 , 0.9018,\n",
       "        0.9998, 0.9998, 1.    , 1.    , 1.    , 1.    , 1.    , 1.    ,\n",
       "        1.    , 1.    , 0.9018, 0.9018, 0.9018, 0.9018, 1.    , 1.    ,\n",
       "        1.    , 1.    , 1.    , 0.9998, 1.    ]),\n",
       " 'std_test_f1_micro': array([0.0004    , 0.0004    , 0.0004    , 0.0004    , 0.0004    ,\n",
       "        0.0004    , 0.00316228, 0.0004    , 0.0004    , 0.0004    ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.0004    , 0.0004    ,\n",
       "        0.0004    , 0.0004    , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.0004    , 0.        ]),\n",
       " 'rank_test_f1_micro': array([19, 19, 19, 19, 19, 19, 18, 19, 15, 15,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1, 19, 19, 19, 19,  1,  1,  1,  1,  1, 15,  1], dtype=int32)}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "sexual-italian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19, 19, 19, 19, 19, 19, 18, 19, 15, 15,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1, 19, 19, 19, 19,  1,  1,  1,  1,  1, 15,  1], dtype=int32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.cv_results_['rank_test_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "coral-company",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 10.0,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for accuracy\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_accuracy'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "popular-range",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 1.0,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for roc auc\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_roc_auc_ovr'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "controlled-captain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(max_iter=5000),\n",
       " 'classifier__C': 10.0,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds best model for f1\n",
    "best_model.cv_results_['params'][ np.argmin(best_model.cv_results_['rank_test_f1_micro'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "dense-civilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best accuracy model\n",
    "acc_model = LogisticRegression(penalty = 'l1', C = 10.0, solver = 'saga', max_iter = 5000)\n",
    "\n",
    "# best roc auc model\n",
    "roc_model = LogisticRegression(penalty = 'l1', C = 1.0, solver = 'saga', max_iter = 5000)\n",
    "\n",
    "# best f1 model\n",
    "f1_model = LogisticRegression(penalty = 'l1', C = 10.0, solver = 'saga', max_iter = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "deluxe-hamburg",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10.0, max_iter=5000, penalty='l1', solver='saga')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# models the data\n",
    "acc_model.fit(X_train, Y_train)\n",
    "roc_model.fit(X_train, Y_train)\n",
    "f1_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "pregnant-relations",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>C</th>\n",
       "      <th>penalty</th>\n",
       "      <th>solver</th>\n",
       "      <th>score_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>LogisticRegression(max_iter=5000)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           classifier           C penalty solver  score_acc\n",
       "0   LogisticRegression(max_iter=5000)      0.0001      l1   saga     0.0982\n",
       "1   LogisticRegression(max_iter=5000)      0.0001      l2   saga     0.0982\n",
       "2   LogisticRegression(max_iter=5000)      0.0010      l1   saga     0.0982\n",
       "3   LogisticRegression(max_iter=5000)      0.0010      l2   saga     0.0982\n",
       "4   LogisticRegression(max_iter=5000)      0.0100      l1   saga     0.0982\n",
       "5   LogisticRegression(max_iter=5000)      0.0100      l2   saga     0.0982\n",
       "6   LogisticRegression(max_iter=5000)      0.1000      l1   saga     0.0140\n",
       "7   LogisticRegression(max_iter=5000)      0.1000      l2   saga     0.0982\n",
       "8   LogisticRegression(max_iter=5000)      1.0000      l1   saga     0.0002\n",
       "9   LogisticRegression(max_iter=5000)      1.0000      l2   saga     0.0002\n",
       "10  LogisticRegression(max_iter=5000)     10.0000      l1   saga     0.0000\n",
       "11  LogisticRegression(max_iter=5000)     10.0000      l2   saga     0.0000\n",
       "12  LogisticRegression(max_iter=5000)    100.0000      l1   saga     0.0000\n",
       "13  LogisticRegression(max_iter=5000)    100.0000      l2   saga     0.0000\n",
       "14  LogisticRegression(max_iter=5000)   1000.0000      l1   saga     0.0000\n",
       "15  LogisticRegression(max_iter=5000)   1000.0000      l2   saga     0.0000\n",
       "16  LogisticRegression(max_iter=5000)  10000.0000      l1   saga     0.0000\n",
       "17  LogisticRegression(max_iter=5000)  10000.0000      l2   saga     0.0000\n",
       "18  LogisticRegression(max_iter=5000)      0.0001      l2  lbfgs     0.0982\n",
       "19  LogisticRegression(max_iter=5000)      0.0010      l2  lbfgs     0.0982\n",
       "20  LogisticRegression(max_iter=5000)      0.0100      l2  lbfgs     0.0982\n",
       "21  LogisticRegression(max_iter=5000)      0.1000      l2  lbfgs     0.0982\n",
       "22  LogisticRegression(max_iter=5000)      1.0000      l2  lbfgs     0.0000\n",
       "23  LogisticRegression(max_iter=5000)     10.0000      l2  lbfgs     0.0000\n",
       "24  LogisticRegression(max_iter=5000)    100.0000      l2  lbfgs     0.0000\n",
       "25  LogisticRegression(max_iter=5000)   1000.0000      l2  lbfgs     0.0000\n",
       "26  LogisticRegression(max_iter=5000)  10000.0000      l2  lbfgs     0.0000\n",
       "27  LogisticRegression(max_iter=5000)         NaN    none  lbfgs     0.0002\n",
       "28  LogisticRegression(max_iter=5000)         NaN    none   saga     0.0000"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = pd.DataFrame( best_model.cv_results_['params'] )\n",
    "\n",
    "results['score_acc'] = 1 - best_model.cv_results_['mean_test_accuracy']\n",
    "\n",
    "cols = results.columns.to_series().str.split('__').apply(lambda x: x[-1])\n",
    "results.columns = cols\n",
    "\n",
    "# Heat map\n",
    "sns.heatmap( results.query('solver==\"saga\"').pivot('C','penalty','score_acc'),\n",
    "             annot=True, fmt='.3f')\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diverse-agency",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
